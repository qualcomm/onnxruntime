diff --git a/CMakeLists.txt b/CMakeLists.txt
index ea7b992..578d9b2 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -237,6 +237,25 @@ set(KLEIDIAI_FILES_SME
     kai/ukernels/matmul/pack/kai_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme.c
     kai/ukernels/matmul/pack/kai_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme.c
     kai/ukernels/matmul/pack/kai_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme.c
+	kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/kai_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.c
+	kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/helper_macros_matmul_clamp_qai8_qai8p_qsi8cxp.S
+
+	kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/kai_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.c
+	kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/helper_macros_imatmul_clamp_qai8_qai8p_qsi8cxp.S
+
+    kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/kai_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.c
+    kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/helper_macros_matmul_clamp_f16_f16p_f16p.S
+
+    kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/kai_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.c
+    kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/helper_macros_imatmul_clamp_f16_f16p_f16p.S
+
+    kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/kai_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.c
+    kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/helper_macros_matmul_clamp_f32_f32p_f32p.S
+
+    kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/kai_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.c
+    kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/helper_macros_imatmul_clamp_f32_f32p_f32p.S
+
+
 )
 
 set(KLEIDIAI_FILES_SME2
@@ -288,7 +307,7 @@ if(NOT MSVC)
     set_source_files_properties(${KLEIDIAI_FILES_NEON_I8MM}         PROPERTIES COMPILE_OPTIONS -march=armv8.2-a+i8mm${KLEIDIAI_INTERNAL_EXTRA_ARCH})
 
     # Use -fno-tree-vectorize option to disable compiler based vectorization
-    set_source_files_properties(${KLEIDIAI_FILES_SME}          PROPERTIES COMPILE_OPTIONS "-fno-tree-vectorize;-march=armv8.2-a+sve+sve2${KLEIDIAI_INTERNAL_EXTRA_ARCH}")
+    set_source_files_properties(${KLEIDIAI_FILES_SME}          PROPERTIES COMPILE_OPTIONS "-fno-tree-vectorize;-march=armv8.2-a+sve+sve2+sme${KLEIDIAI_INTERNAL_EXTRA_ARCH}")
     set_source_files_properties(${KLEIDIAI_FILES_SME2}         PROPERTIES COMPILE_OPTIONS "-fno-tree-vectorize;-march=armv8.2-a+sve+sve2${KLEIDIAI_INTERNAL_EXTRA_ARCH}")
 else()
     target_sources(kleidiai PRIVATE ${KLEIDIAI_FILES_NEON_DOTPROD_ASM})
@@ -309,6 +328,13 @@ endif()
 target_include_directories(kleidiai PUBLIC
     $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}>
     $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>
+	$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/>
+	$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/>
+	$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/>
+	$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/>
+	$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/>
+	$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/>
+
 )
 
 target_compile_options(kleidiai
diff --git a/cmake/toolchains/aarch64-none-linux-gnu.toolchain.cmake b/cmake/toolchains/aarch64-none-linux-gnu.toolchain.cmake
index 8384308..d4c8968 100644
--- a/cmake/toolchains/aarch64-none-linux-gnu.toolchain.cmake
+++ b/cmake/toolchains/aarch64-none-linux-gnu.toolchain.cmake
@@ -1,15 +1,21 @@
-#
-# SPDX-FileCopyrightText: Copyright 2024 Arm Limited and/or its affiliates <open-source-office@arm.com>
-#
-# SPDX-License-Identifier: Apache-2.0
-#
+set(CMAKE_SYSTEM_NAME Linux)
+set(CMAKE_SYSTEM_PROCESSOR arm)
 
-# The Arm GNU Toolchain is available for download from Arm Developer.
-# https://developer.arm.com/downloads/-/arm-gnu-toolchain-downloads
+set(triple aarch64-linux-gnu)
+set(TOOLS_PATH /prj/qct/chips/swarch/tools)
+set(CROSS_COMPILE_LLVM_PATH ${TOOLS_PATH}/clang-16.0.0)
 
-set(CMAKE_SYSTEM_NAME      Linux)
-set(CMAKE_SYSTEM_PROCESSOR aarch64)
-set(CMAKE_CROSSCOMPILING   TRUE)
+set(CMAKE_C_COMPILER "${CROSS_COMPILE_LLVM_PATH}/bin/clang")
+set(CMAKE_C_COMPILER_TARGET ${triple})
+set(CMAKE_ASM_COMPILER_TARGET ${triple})
+set(CMAKE_C_FLAGS "-march=armv8.5-a+sme+sve2")
+set(CMAKE_ASM_FLAGS "-march=armv8.5-a+sme+sve2")
 
-set(CMAKE_C_COMPILER   aarch64-none-linux-gnu-gcc)
-set(CMAKE_CXX_COMPILER aarch64-none-linux-gnu-g++)
+set(CMAKE_CXX_COMPILER "${CROSS_COMPILE_LLVM_PATH}/bin/clang++")
+set(CMAKE_ASM_COMPILER "${CROSS_COMPILE_LLVM_PATH}/bin/clang++")
+set(CMAKE_CXX_COMPILER_TARGET ${triple})
+set(CMAKE_CXX_FLAGS "-march=armv8.5-a+sve2+sme")
+
+set(CMAKE_SHARED_LINKER_FLAGS "-static")
+set(CMAKE_MODULE_LINKER_FLAGS "-static")
+set(CMAKE_EXE_LINKER_FLAGS "-static")
\ No newline at end of file
diff --git a/kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/helper_macros_imatmul_clamp_f16_f16p_f16p.S b/kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/helper_macros_imatmul_clamp_f16_f16p_f16p.S
new file mode 100644
index 0000000..ee2e643
--- /dev/null
+++ b/kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/helper_macros_imatmul_clamp_f16_f16p_f16p.S
@@ -0,0 +1,11 @@
+
+.macro ld1h_data_2, reg1, reg2, pred, addr
+ld1h \reg1, \pred/Z, [\addr]
+ld1h \reg2, \pred/Z, [\addr, #1, MUL VL]
+addvl \addr, \addr, #2
+.endm
+
+.macro clamp_float reg, min_val, max_val, pred
+FMIN \reg, \pred/M, \reg, \min_val
+FMAX \reg, \pred/M, \reg, \max_val
+.endm
diff --git a/kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/kai_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.c b/kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/kai_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.c
new file mode 100644
index 0000000..2d8a4e8
--- /dev/null
+++ b/kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/kai_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.c
@@ -0,0 +1,250 @@
+//
+// SPDX-FileCopyrightText: Copyright 2025 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+// Do not flag up inline assembly blocks
+#pragma GCC diagnostic ignored "-Woverlength-strings"
+
+#if !defined(__aarch64__) || !defined(__ARM_FEATURE_SVE2)
+#error This file must be compiled for AArch64, FEAT_SVE2.
+#else  // Architectural features check.
+
+#include "kai_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.h"
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include "kai/kai_common.h"
+__asm__(".include \"helper_macros_imatmul_clamp_f16_f16p_f16p.S\"");
+
+static const size_t kai_mr = 2;
+static const size_t kai_nr = 2;
+static const size_t kai_kr = 2;
+
+size_t kai_get_m_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void) {
+    return kai_mr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_n_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void) {
+    return kai_nr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_lhs_packed_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t k_chunk_count, size_t k_chunk_length) {
+    KAI_ASSUME(m_idx % kai_get_m_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa() == 0);
+    const size_t indirect_k = k_chunk_count * kai_roundup(k_chunk_length, kai_kr);
+    return m_idx * indirect_k * sizeof(uint16_t);
+}
+
+static size_t kai_get_rhs_packed_stride_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t k_chunk_count, size_t k_chunk_length) {
+    const size_t indirect_k = k_chunk_count * kai_roundup(k_chunk_length, kai_kr);
+    return kai_get_n_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa() *
+        (sizeof(uint16_t) + indirect_k * sizeof(uint16_t));
+}
+
+size_t kai_get_rhs_packed_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t n_idx, size_t k_chunk_count, size_t k_chunk_length) {
+    KAI_ASSUME(n_idx % kai_get_n_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa() == 0);
+    const size_t block_idx = n_idx / kai_get_n_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa();
+    return block_idx *
+        kai_get_rhs_packed_stride_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+               k_chunk_count, k_chunk_length);
+}
+
+size_t kai_get_dst_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_row_stride) {
+    KAI_ASSUME(m_idx % kai_get_m_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa() == 0);
+    KAI_ASSUME(n_idx % kai_get_n_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa() == 0);
+
+    return m_idx * dst_row_stride + n_idx * sizeof(uint16_t);
+}
+
+size_t kai_get_dst_size_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(size_t m, size_t n) {
+    return m * n * sizeof(uint16_t);
+}
+
+void kai_run_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t m, size_t n, size_t k_chunk_count, size_t k_chunk_length, const void* lhs_packed, const void* rhs_packed,
+    void* dst, size_t dst_row_stride, float clamp_min, float clamp_max) {
+    typedef struct {
+        const void* A;
+        const void* B;
+        void* C;
+        uint64_t ldcb;
+        uint64_t M;
+        uint64_t N;
+        uint64_t K;
+        float16_t min;
+        float16_t max;
+        void* accumulator_buffer;
+        uint64_t flags;
+    } KernelArgs;
+
+    KernelArgs args;
+
+    args.A = lhs_packed;
+    args.B = rhs_packed;
+
+    size_t indirect_k = k_chunk_count * kai_roundup(k_chunk_length, kai_kr);
+
+    args.C = dst;
+    args.ldcb = dst_row_stride;
+    args.M = m;
+    args.N = n;
+    args.K = indirect_k;
+    args.min = (float16_t)clamp_min;
+    args.max = (float16_t)clamp_max;
+
+    args.accumulator_buffer = NULL;
+    args.flags = 0;
+
+    __asm__ __volatile__(
+    "SMSTART \n"
+        "ldr w13, [%x[args], %[offsetof_M]]\n"
+        "mov x11, #0x0\n"
+        "mov x10, #0x0\n"
+        "ptrue p1.b\n"
+        " ptrue p2.b\n"
+        "ldr w9, [%x[args], %[offsetof_N]]\n"
+        "ldr x28, [%x[args], %[offsetof_A]]\n"
+        "1:"  // M loop
+        "ldr x27, [%x[args], %[offsetof_B]]\n"
+        "2:"  // N loop
+        "fmov z24.h, #0.0\n"
+        "ld1h { z5.h }, p1/Z, [x27]\n"
+        "fmov z27.h, #1.0\n"
+        "mov x26, x28\n"
+        "zero { za }\n"
+        "inch x27, ALL, MUL #2\n"
+        "zip1 z30.h, z5.h, z24.h\n"
+        "zip2 z20.h, z5.h, z24.h\n"
+        "fmopa za0.s, p1/M, p1/M, z27.h, z30.h\n"
+        "fmopa za1.s, p1/M, p1/M, z27.h, z20.h\n"
+        "fmopa za2.s, p1/M, p1/M, z27.h, z30.h\n"
+        "fmopa za3.s, p1/M, p1/M, z27.h, z20.h\n"
+        "ldr x20, [%x[args], %[offsetof_K]]\n"
+        "add x20, x20, #0x1\n"
+        "lsr x20, x20, #0x1\n"
+        "lsr x21, x20, #0x2\n"
+        "and x20, x20, #0x3\n"
+        "cbz x21, 6f\n"
+        "subs x21, x21, #0x1\n"	
+        "ld1h_data_2  z18.h,z19.h , p2, x26 \n"
+        "ld1h_data_2  z16.h,z17.h , p2, x27 \n"
+        "ld1h_data_2  z2.h,z10.h , p2, x26 \n"
+        "ld1h_data_2  z30.h,z31.h , p2, x27 \n"
+        "ld1h_data_2  z28.h,z29.h , p2, x26 \n"
+        "ld1h_data_2  z6.h,z14.h , p2, x27 \n"
+        "ld1h_data_2  z5.h, z13.h , p2, x26 \n"
+        "ld1h_data_2  z7.h, z15.h , p2, x27 \n"				  
+        "ble 5f\n"
+        "4:"  // K loop
+        " fmopa za0.s, p1/M, p1/M, z18.h, z16.h\n"
+        " fmopa za1.s, p1/M, p1/M, z18.h, z17.h\n"
+        " fmopa za2.s, p1/M, p1/M, z19.h, z16.h\n"
+        " fmopa za3.s, p1/M, p1/M, z19.h, z17.h\n"
+        " ld1h_data_2  z18.h,z19.h , p2, x26 \n"
+        " fmopa za0.s, p1/M, p1/M, z2.h, z30.h\n"
+        " ld1h_data_2  z16.h,z17.h , p2, x27 \n"
+        " fmopa za1.s, p1/M, p1/M, z2.h, z31.h\n"
+        " fmopa za2.s, p1/M, p1/M, z10.h, z30.h\n"
+        " fmopa za3.s, p1/M, p1/M, z10.h, z31.h\n"
+        " ld1h_data_2  z2.h, z10.h , p2, x26 \n"
+        " fmopa za0.s, p1/M, p1/M, z28.h, z6.h\n"
+        " ld1h_data_2  z30.h,z31.h , p2, x27 \n"
+        " fmopa za1.s, p1/M, p1/M, z28.h, z14.h\n"
+        " fmopa za2.s, p1/M, p1/M, z29.h, z6.h\n"
+        " fmopa za3.s, p1/M, p1/M, z29.h, z14.h\n"
+        " ld1h_data_2  z28.h,z29.h , p2, x26 \n"
+        " ld1h_data_2  z6.h, z14.h , p2, x27 \n"
+        " fmopa za0.s, p1/M, p1/M, z5.h, z7.h\n"
+        " fmopa za1.s, p1/M, p1/M, z5.h, z15.h\n"
+        " fmopa za2.s, p1/M, p1/M, z13.h, z7.h\n"
+        " fmopa za3.s, p1/M, p1/M, z13.h, z15.h\n"
+        " ld1h_data_2  z5.h, z13.h , p2, x26 \n"
+        " ld1h_data_2  z7.h, z15.h , p2, x27 \n"
+        "subs x21, x21, #0x1\n"							  
+        "bgt 4b\n"
+        "5:"  // K loop tail
+        " fmopa za0.s, p1/M, p1/M, z18.h, z16.h\n"
+        " fmopa za1.s, p1/M, p1/M, z18.h, z17.h\n"
+        " fmopa za2.s, p1/M, p1/M, z19.h, z16.h\n"
+        " fmopa za3.s, p1/M, p1/M, z19.h, z17.h\n"
+        " fmopa za0.s, p1/M, p1/M, z2.h, z30.h\n"
+        " fmopa za1.s, p1/M, p1/M, z2.h, z31.h\n"
+        " fmopa za2.s, p1/M, p1/M, z10.h, z30.h\n"
+        " fmopa za3.s, p1/M, p1/M, z10.h, z31.h\n"
+        " fmopa za0.s, p1/M, p1/M, z28.h, z6.h\n"
+        " fmopa za1.s, p1/M, p1/M, z28.h, z14.h\n"
+        " fmopa za2.s, p1/M, p1/M, z29.h, z6.h\n"
+        " fmopa za3.s, p1/M, p1/M, z29.h, z14.h\n"
+        " fmopa za0.s, p1/M, p1/M, z5.h, z7.h\n"
+        " fmopa za1.s, p1/M, p1/M, z5.h, z15.h\n"
+        " fmopa za2.s, p1/M, p1/M, z13.h, z7.h\n"
+        " fmopa za3.s, p1/M, p1/M, z13.h, z15.h\n"
+        "6:"  // K oddments
+        "cbz x20, 8f\n"
+        "7:"  // K oddments: Loop
+        " ld1h_data_2  z5.h, z13.h , p2, x26\n"
+		"subs x20, x20, #0x1\n"
+        " ld1h_data_2  z14.h,z15.h , p2, x27\n"	  
+        " fmopa za0.s, p1/M, p1/M, z5.h, z14.h\n"
+        " fmopa za1.s, p1/M, p1/M, z5.h, z15.h\n"
+        " fmopa za2.s, p1/M, p1/M, z13.h, z14.h\n"
+        " fmopa za3.s, p1/M, p1/M, z13.h, z15.h\n"
+        "bgt 7b\n"
+        "8:"  // K oddments: End
+        "ldr x25, [%x[args], %[offsetof_C]]\n"
+        "sub x24, x13, x11\n"
+        "cntw x23, ALL, MUL #2\n"
+        "ld1rh { z17.h }, p1/Z, [%x[args], %[offsetof_KernelArgs_min]]\n"
+        "ldr x22, [%x[args], %[offsetof_ldcb]]\n"
+        "whilelt p0.h, x10, x9\n"
+        "cmp x24, x23\n"
+        "ld1rh { z16.h }, p1/Z, [%x[args], %[offsetof_KernelArgs_max]]\n"
+        "mov x12, #0x0\n"
+        "mov x21, #0x0\n"
+        "add x25, x25, x10, LSL #1\n"  // C += n
+        "mov x20, #0x2\n"
+        "madd x25, x11, x22, x25\n"  // C += m * ldc
+        "csel x24, x24, x23, LT\n"
+        "10:"  // Store to output array: Accumulator loop
+        "mova z14.b,p1/M, za0h.b[w12, 0]\n"
+        "mova z15.b,p1/M, za0h.b[w12, 1]\n"
+		"add x12, x12, #0x4\n"
+        "cmp x12, x23, LSL #1\n"
+        "add x21, x21, #0x1\n"
+        "fcvt z0.h, p1/M,   z14.s\n"
+        "fcvt z1.h, p1/M,   z15.s\n"
+        "uzp1 z12.h ,z0.h,  z1.h\n"
+        "csel x12, x12, x20, LT\n"
+        "clamp_float z12.h, z17.h, z16.h, p1 \n"
+        "st1h { z12.h }, p0, [x25]\n"
+        "add x25, x25, x22\n"
+        "cmp x21, x24\n"
+        "blt 10b\n"
+        "incw x10, ALL, MUL #2\n"
+        "cmp x10, x9\n"
+        "blt 2b\n"
+        "incw x11, ALL, MUL #2\n"
+        "mov x10, #0x0\n"
+		"cmp x11, x13\n"
+        "mov x28, x26\n"
+        "blt 1b\n"
+        "SMSTOP\n"
+        :
+        : [args] "r"(&args), [offsetof_A] "I"(offsetof(KernelArgs, A)), [offsetof_B] "I"(offsetof(KernelArgs, B)),
+          [offsetof_C] "I"(offsetof(KernelArgs, C)), [offsetof_K] "I"(offsetof(KernelArgs, K)),
+          [offsetof_KernelArgs_max] "I"(offsetof(KernelArgs, max)),
+          [offsetof_KernelArgs_min] "I"(offsetof(KernelArgs, min)), [offsetof_M] "I"(offsetof(KernelArgs, M)),
+          [offsetof_N] "I"(offsetof(KernelArgs, N)), [offsetof_ldcb] "I"(offsetof(KernelArgs, ldcb))
+        : "cc", "memory", "p0", "p1", "p10", "p11", "p12", "p13", "p14", "p15", "p2", "p3", "p4", "p5", "p6", "p7",
+          "p8", "p9", "x10", "x11", "x12", "x13", "x20", "x21", "x22", "x23", "x24", "x25", "x26", "x27", "x28", "x9",
+          "z0", "z1", "z10", "z11", "z12", "z13", "z14", "z15", "z16", "z17", "z18", "z19", "z2", "z20", "z21", "z22",
+          "z23", "z24", "z25", "z26", "z27", "z28", "z29", "z3", "z30", "z31", "z4", "z5", "z6", "z7", "z8", "z9");
+}
+
+#endif  // Architectural features check.
diff --git a/kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/kai_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.h b/kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/kai_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.h
new file mode 100644
index 0000000..3b957bc
--- /dev/null
+++ b/kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/kai_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.h
@@ -0,0 +1,97 @@
+//
+// SPDX-FileCopyrightText: Copyright 2025 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+#pragma once
+
+#include <stddef.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif  // __cplusplus
+
+/// Micro-kernel dependencies
+///
+/// -# kai_lhs_imatmul_pack_x16p2vlx2_x16p_sme to pack the LHS matrix.
+/// -# kai_rhs_imatmul_pack_kxn_x16p2vlx2b_x16_x16_sme to pack the RHS matrix.
+
+/// Gets m step value.
+///
+/// The starting row index must be divisible by `m_step`.
+///
+/// @return The m step value.
+size_t kai_get_m_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void);
+
+/// Gets n step value.
+///
+/// The starting column index must be divisible by `n_step`.
+///
+/// @return The n step value.
+size_t kai_get_n_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void);
+
+/// Gets the offset in bytes to the data element in the packed LHS matrix buffer.
+///
+/// @param[in] m_idx Row index in the unpacked LHS matrix. Must be a multiple of `m_step`.
+/// @param[in] k_chunk_count Number of LHS column splits.
+/// @param[in] k_chunk_length Length of a LHS column split.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_lhs_packed_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t k_chunk_count, size_t k_chunk_length);
+
+/// Gets the offset in bytes to the data element in the packed RHS matrix buffer.
+///
+/// @param[in] n_idx Column index in the unpacked RHS matrix. Must be a multiple of `n_step`.
+/// @param[in] k_chunk_count Number of LHS column splits.
+/// @param[in] k_chunk_length Length of a LHS column split.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_rhs_packed_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t n_idx, size_t k_chunk_count, size_t k_chunk_length);
+
+/// Gets the offset in bytes to the data element in the destination matrix buffer.
+///
+/// @param[in] m_idx Row index. Must be a multiple of `m_step`.
+/// @param[in] n_idx Column index. Must be a multiple of `n_step`.
+/// @param[in] dst_row_stride. Distance between start of two rows in the output buffer.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_dst_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_row_stride);
+
+/// Gets the size in bytes of the destination matrix buffer.
+///
+/// @param[in] m Number of rows.
+/// @param[in] n Number of columns.
+///
+/// @return The size in bytes of the destination matrix buffer.
+size_t kai_get_dst_size_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(size_t m, size_t n);
+
+/// Runs the matrix multiplication microkernel followed by a clamp operation.
+///
+/// The pointer of each buffers (packed LHS, packed RHS and output) needs to be added with offset
+/// calculated using the following functions:
+///
+///   * Packed LHS: @ref kai_get_lhs_packed_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.
+///   * Packed RHS: @ref kai_get_rhs_packed_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.
+///   * Output: @ref kai_get_dst_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.
+///
+/// @param[in] m Number of output rows to be computed.
+/// @param[in] n Number of output columns to be computed.
+/// @param[in] k_chunk_count Number of LHS column splits.
+/// @param[in] k_chunk_length Length of a LHS column split
+/// @param[in] lhs_packed Packed LHS matrix buffer.
+/// @param[in] rhs_packed Packed RHS matrix buffer.
+/// @param[out] dst Output matrix buffer.
+/// @param[in] dst_row_stride Row stride in bytes of the output matrix.
+/// @param[in] clamp_min Minimum value to clamp the final result.
+/// @param[in] clamp_max Maximum value to clamp the final result.
+void kai_run_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t m, size_t n, size_t k_chunk_count, size_t k_chunk_length, const void* lhs_packed, const void* rhs_packed,
+    void* dst, size_t dst_row_stride, float clamp_min, float clamp_max);
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif  // __cplusplus
diff --git a/kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/helper_macros_imatmul_clamp_f32_f32p_f32p.S b/kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/helper_macros_imatmul_clamp_f32_f32p_f32p.S
new file mode 100644
index 0000000..c359bf4
--- /dev/null
+++ b/kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/helper_macros_imatmul_clamp_f32_f32p_f32p.S
@@ -0,0 +1,67 @@
+.macro load_data, reg1, reg2, reg3, reg4, pred, addr
+ld1w \reg1, \pred/Z, [\addr]
+ld1w \reg2, \pred/Z, [\addr, #1, MUL VL]
+ld1w \reg3, \pred/Z, [\addr, #2, MUL VL]
+ld1w \reg4, \pred/Z, [\addr, #3, MUL VL]
+addvl \addr, \addr, #4
+.endm
+
+.macro load_data_2, reg1, reg2, pred, addr
+ld1w \reg1, \pred/Z, [\addr]
+ld1w \reg2, \pred/Z, [\addr, #1, MUL VL]
+addvl \addr, \addr, #2
+.endm
+
+.macro store_data, reg1, reg2, reg3, reg4, pred, addr
+st1w \reg1, \pred, [\addr]
+st1w \reg2, \pred, [\addr, #1, MUL VL]
+st1w \reg3, \pred, [\addr, #2, MUL VL]
+st1w \reg4, \pred, [\addr, #3, MUL VL]
+addvl \addr, \addr, #4
+.endm
+
+.macro move_vector_tile, tile, reg1, reg2, reg3, reg4, pred, addr
+mova \tile[\addr, 0], \pred/M, \reg1
+mova \tile[\addr, 1], \pred/M, \reg2
+mova \tile[\addr, 2], \pred/M, \reg3
+mova \tile[\addr, 3], \pred/M, \reg4
+.endm
+
+.macro move_tile_vector, tile, reg1, reg2, reg3, reg4, pred, addr
+mova \reg1, \pred/M, \tile[\addr, 0] 
+mova \reg2, \pred/M, \tile[\addr, 1] 
+mova \reg3, \pred/M, \tile[\addr, 2] 
+mova \reg4, \pred/M, \tile[\addr, 3] 
+.endm
+
+.macro clamp_float reg, max_val, min_val, pred
+FMIN \reg, \pred/M, \reg, \max_val
+FMAX \reg, \pred/M, \reg, \min_val
+.endm
+
+
+
+
+.macro load_data_pred_index_counter_2, reg1, reg2, predr, predtype, start_idx, end_idx, addr, word_length
+cntw \word_length
+whilelt \predtype, \start_idx, \end_idx
+ld1w \reg1, \predr/Z, [\addr]
+add \start_idx, \start_idx, \word_length
+whilelt \predtype, \start_idx, \end_idx
+ld1w \reg2, \predr/Z, [\addr, #1, MUL VL]
+neg \word_length, \word_length
+add \start_idx, \start_idx, \word_length
+neg \word_length, \word_length
+.endm
+
+.macro store_data_pred_index_counter_2, reg1, reg2, predr, predtype, start_idx, end_idx, addr, word_length
+cntw \word_length
+whilelt \predtype, \start_idx, \end_idx
+st1w \reg1, \predr, [\addr]
+add \start_idx, \start_idx, \word_length
+whilelt \predtype, \start_idx, \end_idx
+st1w \reg2, \predr, [\addr, #1, MUL VL]
+neg \word_length, \word_length
+add \start_idx, \start_idx, \word_length
+neg \word_length, \word_length
+.endm
diff --git a/kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/kai_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.c b/kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/kai_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.c
new file mode 100644
index 0000000..3240843
--- /dev/null
+++ b/kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/kai_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.c
@@ -0,0 +1,330 @@
+//
+// SPDX-FileCopyrightText: Copyright 2025 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+// Do not flag up inline assembly blocks
+#pragma GCC diagnostic ignored "-Woverlength-strings"
+
+#if !defined(__aarch64__) || !defined(__ARM_FEATURE_SVE2)
+#error This file must be compiled for AArch64, FEAT_SVE2.
+#else  // Architectural features check.
+
+#include "kai_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.h"
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include "kai/kai_common.h"
+__asm__(".include \"helper_macros_imatmul_clamp_f32_f32p_f32p.S\"");
+
+static const size_t kai_mr = 2;
+static const size_t kai_nr = 2;
+static const size_t kai_kr = 1;
+
+size_t kai_get_m_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(void) {
+    return kai_mr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_n_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(void) {
+    return kai_nr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_lhs_packed_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t k_chunk_count, size_t k_chunk_length) {
+    KAI_ASSUME(m_idx % kai_get_m_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa() == 0);
+    const size_t indirect_k = k_chunk_count * kai_roundup(k_chunk_length, kai_kr);
+    return m_idx * indirect_k * sizeof(float);
+}
+
+static size_t kai_get_rhs_packed_stride_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(
+    size_t k_chunk_count, size_t k_chunk_length) {
+    const size_t indirect_k = k_chunk_count * kai_roundup(k_chunk_length, kai_kr);
+    return kai_get_n_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa() *
+        (sizeof(float) + indirect_k * sizeof(float));
+}
+
+size_t kai_get_rhs_packed_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(
+    size_t n_idx, size_t k_chunk_count, size_t k_chunk_length) {
+    KAI_ASSUME(n_idx % kai_get_n_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa() == 0);
+    const size_t block_idx = n_idx / kai_get_n_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa();
+    return block_idx *
+        kai_get_rhs_packed_stride_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(
+               k_chunk_count, k_chunk_length);
+}
+
+size_t kai_get_dst_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_row_stride) {
+    KAI_ASSUME(m_idx % kai_get_m_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa() == 0);
+    KAI_ASSUME(n_idx % kai_get_n_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa() == 0);
+
+    return m_idx * dst_row_stride + n_idx * sizeof(float);
+}
+
+size_t kai_get_dst_size_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(size_t m, size_t n) {
+    return m * n * sizeof(float);
+}
+
+void kai_run_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(
+    size_t m, size_t n, size_t k_chunk_count, size_t k_chunk_length, const void* lhs_packed, const void* rhs_packed,
+    void* dst, size_t dst_row_stride, float clamp_min, float clamp_max) {
+    typedef struct {
+        const void* A;
+        const void* B;
+        void* C;
+        uint64_t ldcb;
+        uint64_t M;
+        uint64_t N;
+        uint64_t K;
+        float min;
+        float max;
+        void* accumulator_buffer;
+        uint64_t flags;
+    } KernelArgs;
+
+    KernelArgs args;
+
+    args.A = lhs_packed;
+    args.B = rhs_packed;
+
+    const size_t indirect_k = k_chunk_count * kai_roundup(k_chunk_length, kai_kr);
+
+    args.C = dst;
+    args.ldcb = dst_row_stride;
+    args.M = m;
+    args.N = n;
+    args.K = indirect_k;
+    args.min = clamp_min;
+    args.max = clamp_max;
+
+    args.accumulator_buffer = NULL;
+    args.flags = 0;
+
+    __asm__ __volatile__(
+        "SMSTART\n"
+        "ldr w14, [%x[args], %[offsetof_M]]\n"
+        "mov x13, #0x0\n"
+        "mov x11, #0x0\n"
+        "ptrue p0.b\n"
+        "ptrue p5.b\n"
+        "ldr w10, [%x[args], %[offsetof_N]]\n"
+        "ldr x9, [%x[args], %[offsetof_A]]\n"
+        "1:"  // M loop
+        "ldr x28, [%x[args], %[offsetof_B]]\n"
+        "2:"  // N loop
+        "whilelt p4.s, x11, x10\n"
+        "fmov z13.s, #1.0\n"
+        "zero { za }\n"
+        "mov x27, x9\n"
+	"load_data_pred_index_counter_2 z14.s, z15.s, p4, p4.s, x11, x10, x28, x15\n" // Load bias
+        "addvl x28, x28, #2\n"
+        "fmopa za0.s, p0/M, p0/M, z13.s, z14.s\n"
+        "fmopa za1.s, p0/M, p0/M, z13.s, z15.s\n"
+        "fmopa za2.s, p0/M, p0/M, z13.s, z14.s\n"
+        "fmopa za3.s, p0/M, p0/M, z13.s, z15.s\n"
+        "ldr x20, [%x[args], %[offsetof_K]]\n"
+        "lsr x21, x20, #0x2\n"
+        "and x20, x20, #0x3\n"
+        "cbz x21, 6f\n"
+        "subs x21, x21, #0x1\n"
+	"load_data_2 z18.s, z26.s, p5, x27\n"
+	"load_data_2 z20.s, z21.s, p5, x28\n"
+	"load_data_2 z4.s, z12.s, p5, x27\n"
+	"load_data_2 z10.s, z11.s, p5, x28\n"
+	"load_data_2 z19.s, z27.s, p5, x27\n"
+	"load_data_2 z24.s, z25.s, p5, x28\n"
+	"load_data_2 z14.s, z15.s, p5, x27\n"
+	"load_data_2 z22.s, z30.s, p5, x28\n"
+        "ble 5f\n"
+        "4:"  // K loop
+        "fmopa za0.s, p0/M, p0/M, z18.s, z20.s\n"
+        "subs x21, x21, #0x1\n"
+        "fmopa za1.s, p0/M, p0/M, z18.s, z21.s\n"
+        "fmopa za2.s, p0/M, p0/M, z26.s, z20.s\n"
+        "fmopa za3.s, p0/M, p0/M, z26.s, z21.s\n"
+	"load_data_2 z18.s, z26.s, p5, x27\n"
+        "fmopa za0.s, p0/M, p0/M, z4.s, z10.s\n"
+	"load_data_2 z20.s, z21.s, p5, x28\n"
+        "fmopa za1.s, p0/M, p0/M, z4.s, z11.s\n"
+        "fmopa za2.s, p0/M, p0/M, z12.s, z10.s\n"
+        "fmopa za3.s, p0/M, p0/M, z12.s, z11.s\n"
+	"load_data_2 z4.s, z12.s, p5, x27\n"
+        "fmopa za0.s, p0/M, p0/M, z19.s, z24.s\n"
+	"load_data_2 z10.s, z11.s, p5, x28\n"
+        "fmopa za1.s, p0/M, p0/M, z19.s, z25.s\n"
+        "fmopa za2.s, p0/M, p0/M, z27.s, z24.s\n"
+        "fmopa za3.s, p0/M, p0/M, z27.s, z25.s\n"
+	"load_data_2 z19.s, z27.s, p5, x27\n"
+	"load_data_2 z24.s, z25.s, p5, x28\n"
+        "fmopa za0.s, p0/M, p0/M, z14.s, z22.s\n"
+        "fmopa za1.s, p0/M, p0/M, z14.s, z30.s\n"
+        "fmopa za2.s, p0/M, p0/M, z15.s, z22.s\n"
+        "fmopa za3.s, p0/M, p0/M, z15.s, z30.s\n"
+	"load_data_2 z14.s, z15.s, p5, x27\n"
+	"load_data_2 z22.s, z30.s, p5, x28\n"
+        "bgt 4b\n"
+        "5:"  // K loop tail
+        "fmopa za0.s, p0/M, p0/M, z18.s, z20.s\n"
+        "fmopa za1.s, p0/M, p0/M, z18.s, z21.s\n"
+        "fmopa za2.s, p0/M, p0/M, z26.s, z20.s\n"
+        "fmopa za3.s, p0/M, p0/M, z26.s, z21.s\n"
+        "fmopa za0.s, p0/M, p0/M, z4.s, z10.s\n"
+        "fmopa za1.s, p0/M, p0/M, z4.s, z11.s\n"
+        "fmopa za2.s, p0/M, p0/M, z12.s, z10.s\n"
+        "fmopa za3.s, p0/M, p0/M, z12.s, z11.s\n"
+        "fmopa za0.s, p0/M, p0/M, z19.s, z24.s\n"
+        "fmopa za1.s, p0/M, p0/M, z19.s, z25.s\n"
+        "fmopa za2.s, p0/M, p0/M, z27.s, z24.s\n"
+        "fmopa za3.s, p0/M, p0/M, z27.s, z25.s\n"
+        "fmopa za0.s, p0/M, p0/M, z14.s, z22.s\n"
+        "fmopa za1.s, p0/M, p0/M, z14.s, z30.s\n"
+        "fmopa za2.s, p0/M, p0/M, z15.s, z22.s\n"
+        "fmopa za3.s, p0/M, p0/M, z15.s, z30.s\n"
+        "6:"  // K oddments
+        "cbz x20, 8f\n"
+        "7:"  // K oddments: Loop
+	"load_data_2 z28.s, z29.s, p5, x27\n"
+        "subs x20, x20, #0x1\n"
+	"load_data_2 z7.s, z15.s, p5, x28\n"
+        "fmopa za0.s, p0/M, p0/M, z28.s, z7.s\n"
+        "fmopa za1.s, p0/M, p0/M, z28.s, z15.s\n"
+        "fmopa za2.s, p0/M, p0/M, z29.s, z7.s\n"
+        "fmopa za3.s, p0/M, p0/M, z29.s, z15.s\n"
+        "bgt 7b\n"
+        "8:"  // K oddments: End
+        "ldr x26, [%x[args], %[offsetof_C]]\n"
+        "sub x25, x14, x13\n"
+        "cntw x24\n"
+        "ld1rw { z19.s }, p0/Z, [%x[args], %[offsetof_KernelArgs_min]]\n"
+        "ldr x23, [%x[args], %[offsetof_ldcb]]\n"
+        "cmp x25, x24\n"
+        "ld1rw { z26.s }, p0/Z, [%x[args], %[offsetof_KernelArgs_max]]\n"
+        "mov x12, #0x0\n"
+        "csel x22, x25, x24, LT\n"
+        "add x26, x26, x11, LSL #2\n"  // C += n
+        "lsr x21, x22, #0x2\n"
+        "madd x26, x13, x23, x26\n"  // C += m * ldc
+        "and x20, x22, #0x3\n"
+        "cbz x21, 11f\n"
+        "10:"  // Store to output array: Accumulator row 0 loop
+	"move_tile_vector za0h.s, z4.s, z5.s, z6.s, z7.s, p5, w12\n"
+	"move_tile_vector za1h.s, z12.s, z13.s, z14.s, z15.s, p5, w12\n"
+	"clamp_float z4.s, z26.s, z19.s, p5\n"
+	"clamp_float z5.s, z26.s, z19.s, p5\n"
+	"clamp_float z6.s, z26.s, z19.s, p5\n"
+	"clamp_float z7.s, z26.s, z19.s, p5\n"
+	"clamp_float z12.s, z26.s, z19.s, p5\n"
+	"clamp_float z13.s, z26.s, z19.s, p5\n"
+	"clamp_float z14.s, z26.s, z19.s, p5\n"
+	"clamp_float z15.s, z26.s, z19.s, p5\n"
+        "add x12, x12, #0x4\n"
+	"store_data_pred_index_counter_2 z4.s, z12.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+	"store_data_pred_index_counter_2 z5.s, z13.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+	"store_data_pred_index_counter_2 z6.s, z14.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+	"store_data_pred_index_counter_2 z7.s, z15.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+        "cmp x12, x21, LSL #2\n"
+        "blt 10b\n"
+        "11:"  // Store to output array: Accumulator row 0 oddments
+        "cbz x20, 12f\n"
+	"move_tile_vector za0h.s, z0.s, z1.s, z2.s, z3.s, p5, w12\n"
+	"move_tile_vector za1h.s, z8.s, z9.s, z10.s, z11.s, p5, w12\n"
+	"clamp_float z0.s, z26.s, z19.s, p5\n"
+	"clamp_float z1.s, z26.s, z19.s, p5\n"
+	"clamp_float z2.s, z26.s, z19.s, p5\n"
+	"clamp_float z3.s, z26.s, z19.s, p5\n"
+	"clamp_float z8.s, z26.s, z19.s, p5\n"
+	"clamp_float z9.s, z26.s, z19.s, p5\n"
+	"clamp_float z10.s, z26.s, z19.s, p5\n"
+	"clamp_float z11.s, z26.s, z19.s, p5\n"
+	"store_data_pred_index_counter_2 z0.s, z8.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+        "subs x20, x20, #0x1\n"
+        "beq 12f\n"
+	"store_data_pred_index_counter_2 z1.s, z9.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+        "subs x20, x20, #0x1\n"
+        "beq 12f\n"
+	"store_data_pred_index_counter_2 z2.s, z10.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+        "12:"  // Store to output array: Accumulator row 0 oddments: End
+        "subs x25, x25, x22\n"
+        "beq 16f\n"
+        "cmp x25, x24\n"
+        "mov x12, #0x0\n"
+        "csel x20, x25, x24, LT\n"
+        "lsr x21, x20, #0x2\n"
+        "and x20, x20, #0x3\n"
+        "cbz x21, 14f\n"
+        "13:"  // Store to output array: Accumulator row 1 loop
+	"move_tile_vector za2h.s, z20.s, z21.s, z22.s, z23.s, p5, w12\n"
+	"move_tile_vector za3h.s, z28.s, z29.s, z30.s, z31.s, p5, w12\n"
+	"clamp_float z20.s, z26.s, z19.s, p5\n"
+	"clamp_float z21.s, z26.s, z19.s, p5\n"
+	"clamp_float z22.s, z26.s, z19.s, p5\n"
+	"clamp_float z23.s, z26.s, z19.s, p5\n"
+	"clamp_float z28.s, z26.s, z19.s, p5\n"
+	"clamp_float z29.s, z26.s, z19.s, p5\n"
+	"clamp_float z30.s, z26.s, z19.s, p5\n"
+	"clamp_float z31.s, z26.s, z19.s, p5\n"
+        "add x12, x12, #0x4\n"
+	"store_data_pred_index_counter_2 z20.s, z28.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+	"store_data_pred_index_counter_2 z21.s, z29.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+	"store_data_pred_index_counter_2 z22.s, z30.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+	"store_data_pred_index_counter_2 z23.s, z31.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+        "cmp x12, x21, LSL #2\n"
+        "blt 13b\n"
+        "14:"  // Store to output array: Accumulator row 1 oddments
+        "cbz x20, 15f\n"
+	"move_tile_vector za2h.s, z4.s, z5.s, z6.s, z7.s, p5, w12\n"
+	"move_tile_vector za3h.s, z12.s, z13.s, z14.s, z15.s, p5, w12\n"
+	"clamp_float z4.s, z26.s, z19.s, p5\n"
+	"clamp_float z5.s, z26.s, z19.s, p5\n"
+	"clamp_float z6.s, z26.s, z19.s, p5\n"
+	"clamp_float z7.s, z26.s, z19.s, p5\n"
+	"clamp_float z12.s, z26.s, z19.s, p5\n"
+	"clamp_float z13.s, z26.s, z19.s, p5\n"
+	"clamp_float z14.s, z26.s, z19.s, p5\n"
+	"clamp_float z15.s, z26.s, z19.s, p5\n"
+	"store_data_pred_index_counter_2 z4.s, z12.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+	"subs x20, x20, #0x1\n"
+        "beq 15f\n"
+	"store_data_pred_index_counter_2 z5.s, z13.s, p4, p4.s, x11, x10, x26, x15\n"
+        "add x26, x26, x23\n"
+	"subs x20, x20, #0x1\n"
+        "beq 15f\n"
+	"store_data_pred_index_counter_2 z6.s, z14.s, p4, p4.s, x11, x10, x26, x15\n"
+        "15:"  // Store to output array: Accumulator row 1 oddments: End
+        "16:"  // Store to output array: End
+        "incw x11, ALL, MUL #2\n"
+        "cmp x11, x10\n"
+        "blt 2b\n"
+        "incw x13, ALL, MUL #2\n"
+        "mov x11, #0x0\n"
+        "cmp x13, x14\n"
+        "mov x9, x27\n"
+        "blt 1b\n"
+        "SMSTOP\n"
+        :
+        : [args] "r"(&args), [offsetof_A] "I"(offsetof(KernelArgs, A)), [offsetof_B] "I"(offsetof(KernelArgs, B)),
+          [offsetof_C] "I"(offsetof(KernelArgs, C)), [offsetof_K] "I"(offsetof(KernelArgs, K)),
+          [offsetof_KernelArgs_max] "I"(offsetof(KernelArgs, max)),
+          [offsetof_KernelArgs_min] "I"(offsetof(KernelArgs, min)), [offsetof_M] "I"(offsetof(KernelArgs, M)),
+          [offsetof_N] "I"(offsetof(KernelArgs, N)), [offsetof_ldcb] "I"(offsetof(KernelArgs, ldcb))
+        : "cc", "memory", "p0", "p1", "p10", "p11", "p12", "p13", "p14", "p15", "p2", "p3", "p4", "p5", "p6", "p7",
+          "p4", "p9", "x10", "x11", "x12", "x13", "x14", "x20", "x21", "x22", "x23", "x24", "x25", "x26", "x27", "x28",
+          "x9", "z0", "z1", "z10", "z11", "z12", "z13", "z14", "z15", "z16", "z17", "z18", "z19", "z2", "z20", "z21",
+          "z22", "z23", "z24", "z25", "z26", "z27", "z28", "z29", "z3", "z30", "z31", "z4", "z5", "z6", "z7", "z8",
+          "z9", "x15");
+}
+
+#endif  // Architectural features check.
diff --git a/kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/kai_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.h b/kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/kai_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.h
new file mode 100644
index 0000000..6a83c9d
--- /dev/null
+++ b/kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/kai_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.h
@@ -0,0 +1,97 @@
+//
+// SPDX-FileCopyrightText: Copyright 2025 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+#pragma once
+
+#include <stddef.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif  // __cplusplus
+
+/// Micro-kernel dependencies
+///
+/// -# kai_lhs_imatmul_pack_x32p2vlx1_x32p_sme to pack the LHS matrix.
+/// -# kai_rhs_imatmul_pack_kxn_x32p2vlx1b_x32_x32_sme to pack the RHS matrix.
+
+/// Gets m step value.
+///
+/// The starting row index must be divisible by `m_step`.
+///
+/// @return The m step value.
+size_t kai_get_m_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(void);
+
+/// Gets n step value.
+///
+/// The starting column index must be divisible by `n_step`.
+///
+/// @return The n step value.
+size_t kai_get_n_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(void);
+
+/// Gets the offset in bytes to the data element in the packed LHS matrix buffer.
+///
+/// @param[in] m_idx Row index in the unpacked LHS matrix. Must be a multiple of `m_step`.
+/// @param[in] k_chunk_count Number of LHS column splits.
+/// @param[in] k_chunk_length Length of a LHS column split.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_lhs_packed_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t k_chunk_count, size_t k_chunk_length);
+
+/// Gets the offset in bytes to the data element in the packed RHS matrix buffer.
+///
+/// @param[in] n_idx Column index in the unpacked RHS matrix. Must be a multiple of `n_step`.
+/// @param[in] k_chunk_count Number of LHS column splits.
+/// @param[in] k_chunk_length Length of a LHS column split.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_rhs_packed_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(
+    size_t n_idx, size_t k_chunk_count, size_t k_chunk_length);
+
+/// Gets the offset in bytes to the data element in the destination matrix buffer.
+///
+/// @param[in] m_idx Row index. Must be a multiple of `m_step`.
+/// @param[in] n_idx Column index. Must be a multiple of `n_step`.
+/// @param[in] dst_row_stride. Distance between start of two rows in the output buffer.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_dst_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_row_stride);
+
+/// Gets the size in bytes of the destination matrix buffer.
+///
+/// @param[in] m Number of rows.
+/// @param[in] n Number of columns.
+///
+/// @return The size in bytes of the destination matrix buffer.
+size_t kai_get_dst_size_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(size_t m, size_t n);
+
+/// Runs the matrix multiplication microkernel followed by a clamp operation.
+///
+/// The pointer of each buffers (packed LHS, packed RHS and output) needs to be added with offset
+/// calculated using the following functions:
+///
+///   * Packed LHS: @ref kai_get_lhs_packed_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.
+///   * Packed RHS: @ref kai_get_rhs_packed_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.
+///   * Output: @ref kai_get_dst_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.
+///
+/// @param[in] m Number of output rows to be computed.
+/// @param[in] n Number of output columns to be computed.
+/// @param[in] k_chunk_count Number of LHS column splits.
+/// @param[in] k_chunk_length Length of a LHS column split
+/// @param[in] lhs_packed Packed LHS matrix buffer.
+/// @param[in] rhs_packed Packed RHS matrix buffer.
+/// @param[out] dst Output matrix buffer.
+/// @param[in] dst_row_stride Row stride in bytes of the output matrix.
+/// @param[in] clamp_min Minimum value to clamp the final result.
+/// @param[in] clamp_max Maximum value to clamp the final result.
+void kai_run_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa(
+    size_t m, size_t n, size_t k_chunk_count, size_t k_chunk_length, const void* lhs_packed, const void* rhs_packed,
+    void* dst, size_t dst_row_stride, float clamp_min, float clamp_max);
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif  // __cplusplus
diff --git a/kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/helper_macros_imatmul_clamp_qai8_qai8p_qsi8cxp.S b/kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/helper_macros_imatmul_clamp_qai8_qai8p_qsi8cxp.S
new file mode 100644
index 0000000..6c456a5
--- /dev/null
+++ b/kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/helper_macros_imatmul_clamp_qai8_qai8p_qsi8cxp.S
@@ -0,0 +1,74 @@
+.macro frintn_convert, reg1, reg2, reg3, reg4, pred
+frintn \reg1, \pred/M, \reg1
+frintn \reg2, \pred/M, \reg2
+frintn \reg3, \pred/M, \reg3
+frintn \reg4, \pred/M, \reg4
+.endm
+
+.macro fcvtzs_convert, reg1, reg2, reg3, reg4, pred
+fcvtzs \reg1, \pred/M, \reg1
+fcvtzs \reg2, \pred/M, \reg2
+fcvtzs \reg3, \pred/M, \reg3
+fcvtzs \reg4, \pred/M, \reg4
+.endm
+
+.macro add____convert, reg1, reg2, reg3, reg4, reg5
+add \reg1, \reg1, \reg5
+add \reg2, \reg2, \reg5
+add \reg3, \reg3, \reg5
+add \reg4, \reg4, \reg5
+.endm
+ 
+.macro sclamp_convert2, reg1, reg2, reg3, reg4, min_val, max_val, pred
+SMIN \reg1, \pred/M, \reg1, \min_val
+SMIN \reg2, \pred/M, \reg2, \min_val
+SMIN \reg3, \pred/M, \reg3, \min_val
+SMIN \reg4, \pred/M, \reg4, \min_val
+SMAX \reg1, \pred/M, \reg1, \max_val
+SMAX \reg2, \pred/M, \reg2, \max_val
+SMAX \reg3, \pred/M, \reg3, \max_val
+SMAX \reg4, \pred/M, \reg4, \max_val
+.endm
+
+
+
+
+.macro sclamp_convert, reg1, reg2, reg3, reg4, min_val, max_val, pred
+SCLAMP \reg1,  \min_val, \max_val
+SCLAMP \reg2,  \min_val, \max_val
+SCLAMP \reg3,  \min_val, \max_val
+SCLAMP \reg4,  \min_val, \max_val
+.endm
+
+
+.macro scvtf_convert, reg1, reg2, reg3, reg4, pred
+scvtf \reg1, \pred/M, \reg1
+scvtf \reg2, \pred/M, \reg2
+scvtf \reg3, \pred/M, \reg3
+scvtf \reg4, \pred/M, \reg4
+.endm
+
+.macro move_tile_vector, tile, reg1, reg2, reg3, reg4, pred, addr
+mova \reg1, \pred/M,  \tile[\addr, 0]
+mova \reg2, \pred/M,  \tile[\addr, 1]
+mova \reg3, \pred/M,  \tile[\addr, 2]
+mova \reg4, \pred/M,  \tile[\addr, 3]
+.endm
+
+.macro load_data_2, reg1, reg2, pred, addr
+ld1b \reg1, \pred/Z, [\addr]
+ld1b \reg2, \pred/Z, [\addr, #1, MUL VL]
+addvl \addr, \addr, #2
+.endm
+
+.macro load_data_pred_index_counter_2, reg1, reg2, predr, predtype, start_idx, end_idx, addr, word_length
+cntw \word_length
+whilelt \predtype, \start_idx, \end_idx
+ld1w \reg1, \predr/Z, [\addr]
+add \start_idx, \start_idx, \word_length
+whilelt \predtype, \start_idx, \end_idx
+ld1w \reg2, \predr/Z, [\addr, #1, MUL VL]
+neg \word_length, \word_length
+add \start_idx, \start_idx, \word_length
+neg \word_length, \word_length
+.endm
diff --git a/kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/kai_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.c b/kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/kai_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.c
new file mode 100644
index 0000000..0a08d80
--- /dev/null
+++ b/kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/kai_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.c
@@ -0,0 +1,395 @@
+//
+// SPDX-FileCopyrightText: Copyright 2025 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+// Do not flag up inline assembly blocks
+#pragma GCC diagnostic ignored "-Woverlength-strings"
+
+#if !defined(__aarch64__) || !defined(__ARM_FEATURE_SVE2)
+#error This file must be compiled for AArch64, FEAT_SVE2.
+#else  // Architectural features check.
+
+#include "kai_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.h"
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include "kai/kai_common.h"
+__asm__(".include \"helper_macros_imatmul_clamp_qai8_qai8p_qsi8cxp.S\"");
+
+static const size_t kai_mr = 2;
+static const size_t kai_nr = 2;
+static const size_t kai_kr = 4;
+
+size_t kai_get_m_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void) {
+    return kai_mr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_n_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void) {
+    return kai_nr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_lhs_packed_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t k_chunk_count, size_t k_chunk_length) {
+    KAI_ASSUME(m_idx % kai_get_m_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa() == 0);
+    const size_t indirect_k = k_chunk_count * kai_roundup(k_chunk_length, kai_kr);
+    return m_idx * indirect_k * sizeof(int8_t);
+}
+
+static size_t kai_get_rhs_packed_stride_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t k_chunk_count, size_t k_chunk_length) {
+    const size_t indirect_k = k_chunk_count * kai_roundup(k_chunk_length, kai_kr);
+    return kai_get_n_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa() *
+        (sizeof(int32_t) + indirect_k * sizeof(int8_t) + sizeof(float));
+}
+
+size_t kai_get_rhs_packed_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t n_idx, size_t k_chunk_count, size_t k_chunk_length) {
+    KAI_ASSUME(n_idx % kai_get_n_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa() == 0);
+    const size_t block_idx = n_idx / kai_get_n_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa();
+    return block_idx *
+        kai_get_rhs_packed_stride_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+               k_chunk_count, k_chunk_length);
+}
+
+size_t kai_get_dst_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_row_stride) {
+    KAI_ASSUME(m_idx % kai_get_m_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa() == 0);
+    KAI_ASSUME(n_idx % kai_get_n_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa() == 0);
+
+    return m_idx * dst_row_stride + n_idx * sizeof(int8_t);
+}
+
+size_t kai_get_dst_size_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(size_t m, size_t n) {
+    return m * n * sizeof(int8_t);
+}
+
+void kai_run_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t m, size_t n, size_t k_chunk_count, size_t k_chunk_length, const void* lhs_packed, const void* rhs_packed,
+    void* dst, size_t dst_row_stride, const struct kai_matmul_requantize32_params* params) {
+    typedef struct {
+        const void* A;
+        const void* B;
+        void* C;
+        uint64_t ldcb;
+        uint64_t M;
+        uint64_t N;
+        uint64_t K;
+        int32_t min;
+        int32_t max;
+        int32_t result_zero_point;
+        const int n_0;
+        void* accumulator_buffer;
+        uint64_t flags;
+    } KernelArgs;
+
+    KernelArgs args;
+
+    args.A = lhs_packed;
+    args.B = rhs_packed;
+
+    size_t indirect_k = k_chunk_count * kai_roundup(k_chunk_length, kai_kr);
+
+    args.C = dst;
+    args.ldcb = dst_row_stride;
+    args.M = m;
+    args.N = n;
+    args.K = indirect_k;
+    args.min = params->min_value;
+    args.max = params->max_value;
+    args.result_zero_point = params->output_zero_point;
+
+    args.accumulator_buffer = NULL;
+    args.flags = 0;
+
+    __asm__ __volatile__(
+        "SMSTART \n"
+        "ldr w14, [%x[args], %[offsetof_M]] \n"
+        "mov x13, #0x0\n"
+        "mov x11, #0x0\n"
+        "ptrue p1.b\n"
+        "ptrue p7.b\n"
+        "ldr w10, [%x[args], %[offsetof_N]]\n"
+        "ldr x9, [%x[args], %[offsetof_A]]\n"
+        "1:"  // M loop
+        "ldr x28, [%x[args], %[offsetof_B]]\n"
+        "2:"  // N loop
+        " whilelt p4.s, x11, x10 \n"
+        "zero { za }\n"
+        "mov x27, x9\n"
+        "load_data_pred_index_counter_2  z14.s, z15.s, p4, p4.s, x11, x10, x28, x15 \n"  // Load bias
+        "addvl x28, x28, #2\n"
+        "addha za0.s, p1/M, p1/M, z14.s\n"
+        "addha za1.s, p1/M, p1/M, z15.s\n"
+        "addha za2.s, p1/M, p1/M, z14.s\n"
+        "addha za3.s, p1/M, p1/M, z15.s\n"
+        "ldr x20, [%x[args], %[offsetof_K]]\n"
+        "add x20, x20, #0x3\n"
+        "lsr x20, x20, #0x2\n"
+        "lsr x21, x20, #0x2\n"
+        "and x20, x20, #0x3\n"
+        "cbz x21, 6f\n"
+        "subs x21, x21, #0x1\n"
+        "load_data_2   z2.b  , z3.b   , p7,  x27 \n"
+        "load_data_2   z0.b  , z8.b   , p7,  x28 \n"
+        "load_data_2   z18.b , z19.b  , p7,  x27 \n"
+        "load_data_2   z20.b , z21.b  , p7,  x28 \n"
+        "load_data_2   z26.b , z27.b  , p7,  x27 \n"
+        "load_data_2   z22.b , z23.b  , p7,  x28 \n"
+        "load_data_2   z24.b , z25.b  , p7,  x27 \n"
+        "load_data_2   z4.b  , z5.b   , p7,  x28 \n"
+        "ble 5f\n"
+        "4:"  // K loop
+        " smopa za0.s, p1/M, p1/M, z2.b, z0.b\n"
+        "subs x21, x21, #0x1\n"
+        " smopa za1.s, p1/M, p1/M, z2.b, z8.b\n"
+        " smopa za2.s, p1/M, p1/M, z3.b, z0.b\n"
+        " smopa za3.s, p1/M, p1/M, z3.b, z8.b\n"
+        " load_data_2  z2.b, z3.b , p7, x27  \n"
+        " smopa za0.s, p1/M, p1/M, z18.b, z20.b\n"
+        " load_data_2  z0.b, z8.b , p7, x28  \n"
+        " smopa za1.s, p1/M, p1/M, z18.b, z21.b\n"
+        " smopa za2.s, p1/M, p1/M, z19.b, z20.b\n"
+        " smopa za3.s, p1/M, p1/M, z19.b, z21.b\n"
+        " load_data_2  z18.b, z19.b , p7, x27   \n"
+        " smopa za0.s, p1/M, p1/M, z26.b, z22.b\n"
+        " load_data_2  z20.b, z21.b , p7, x28  \n"
+        " smopa za1.s, p1/M, p1/M, z26.b, z23.b\n"
+        " smopa za2.s, p1/M, p1/M, z27.b, z22.b\n"
+        " smopa za3.s, p1/M, p1/M, z27.b, z23.b\n"
+        " load_data_2  z26.b, z27.b , p7, x27  \n"
+        " load_data_2  z22.b, z23.b , p7, x28  \n"
+        " smopa za0.s, p1/M, p1/M, z24.b, z4.b\n"
+        " smopa za1.s, p1/M, p1/M, z24.b, z5.b\n"
+        " smopa za2.s, p1/M, p1/M, z25.b, z4.b\n"
+        " smopa za3.s, p1/M, p1/M, z25.b, z5.b\n"
+        " load_data_2  z24.b, z25.b , p7, x27 \n"
+        " load_data_2  z4.b, z5.b  , p7, x28  \n"
+        "bgt 4b\n"
+        "5:"  // K loop tail
+        " smopa za0.s, p1/M, p1/M, z2.b, z0.b\n"
+        " smopa za1.s, p1/M, p1/M, z2.b, z8.b\n"
+        " smopa za2.s, p1/M, p1/M, z3.b, z0.b\n"
+        " smopa za3.s, p1/M, p1/M, z3.b, z8.b\n"
+        " smopa za0.s, p1/M, p1/M, z18.b, z20.b\n"
+        " smopa za1.s, p1/M, p1/M, z18.b, z21.b\n"
+        " smopa za2.s, p1/M, p1/M, z19.b, z20.b\n"
+        " smopa za3.s, p1/M, p1/M, z19.b, z21.b\n"
+        " smopa za0.s, p1/M, p1/M, z26.b, z22.b\n"
+        " smopa za1.s, p1/M, p1/M, z26.b, z23.b\n"
+        " smopa za2.s, p1/M, p1/M, z27.b, z22.b\n"
+        " smopa za3.s, p1/M, p1/M, z27.b, z23.b\n"
+        " smopa za0.s, p1/M, p1/M, z24.b, z4.b\n"
+        " smopa za1.s, p1/M, p1/M, z24.b, z5.b\n"
+        " smopa za2.s, p1/M, p1/M, z25.b, z4.b\n"
+        " smopa za3.s, p1/M, p1/M, z25.b, z5.b\n"
+        "6:"  // K oddments
+        "cbz x20, 8f\n"
+        "7:"  // K oddments: Loop
+        "load_data_2  z16.b, z17.b , p7, x27 \n"
+        "subs x20, x20, #0x1\n"
+        "load_data_2  z8.b, z9.b   , p7, x28  \n"
+        "smopa za0.s, p1/M, p1/M, z16.b, z8.b\n"
+        "smopa za1.s, p1/M, p1/M, z16.b, z9.b\n"
+        "smopa za2.s, p1/M, p1/M, z17.b, z8.b\n"
+        "smopa za3.s, p1/M, p1/M, z17.b, z9.b\n"
+        "bgt 7b\n"
+        "8:"  // K oddments: End
+        "ldr x26, [%x[args], %[offsetof_C]]\n"
+        "sub x25, x14, x13\n"
+        "cntw x24\n"
+        "ld1rw { z27.s }, p1/Z, [%x[args], %[offsetof_KernelArgs_min]]\n"
+        "ldr x23, [%x[args], %[offsetof_ldcb]]\n"
+        "whilelt p0.h, x11, x10\n"
+        "cmp x25, x24\n"
+        "ld1rw { z1.s }, p1/Z, [%x[args], %[offsetof_KernelArgs_max]]\n"
+        "csel x22, x25, x24, LT\n"
+        "ld1rw { z0.s }, p1/Z, [%x[args], %[offsetof_KernelArgs_result_zero_point]]\n"
+        "mov x12, #0x0\n"
+        "add x26, x26, x11\n"  // C += n
+        "lsr x21, x22, #0x2\n"
+        "ld1w { z22.s }, p1/Z, [x28]\n"
+        "madd x26, x13, x23, x26\n"  // C += m * ldc
+        "ld1w { z26.s }, p1/Z, [x28, #1, MUL VL]\n"
+        "and x20, x22, #0x3\n"
+        "addvl x28, x28, #2\n"
+        "cbz x21, 11f\n"
+        "10:"  // Store to output array: Accumulator row 0 loop
+        "move_tile_vector za0h.s, z16.s, z17.s, z18.s, z19.s, p7, w12 \n"
+        "move_tile_vector za1h.s, z28.s, z29.s, z30.s, z31.s, p7, w12 \n"
+        "scvtf_convert  z16.s, z17.s, z18.s, z19.s, p7 \n"
+        "scvtf_convert  z28.s, z29.s, z30.s, z31.s, p7 \n"
+        "fmul z16.s, z16.s, z22.s\n"
+        "fmul z17.s, z17.s, z22.s\n"
+        "add x12, x12, #0x4\n"
+        "fmul z18.s, z18.s, z22.s\n"
+        "fmul z19.s, z19.s, z22.s\n"
+        "cmp x12, x21, LSL #2\n"
+        "fmul z28.s, z28.s, z26.s\n"
+        "fmul z29.s, z29.s, z26.s\n"
+        "fmul z30.s, z30.s, z26.s\n"
+        "fmul z31.s, z31.s, z26.s\n"
+        "frintn_convert z16.s, z17.s, z18.s, z19.s, p7  \n"
+        "fcvtzs_convert z16.s, z17.s, z18.s, z19.s, p7  \n"
+        "add____convert z16.s, z17.s, z18.s, z19.s , z0.s \n"
+        "sclamp_convert z16.s, z17.s, z18.s, z19.s , z27.s, z1.s, p7 \n"
+        "frintn_convert z28.s, z29.s, z30.s, z31.s, p7  \n"
+        "fcvtzs_convert z28.s, z29.s, z30.s, z31.s, p7  \n"
+        "add____convert z28.s, z29.s, z30.s, z31.s,  z0.s \n"
+        "sclamp_convert z28.s, z29.s, z30.s, z31.s, z27.s, z1.s, p7 \n"
+        "uzp1 z5.h, z16.h, z28.h\n"
+        "uzp1 z20.h, z17.h, z29.h\n"
+        "uzp1 z17.h, z18.h, z30.h\n"
+        "uzp1 z16.h, z19.h, z31.h\n"
+        "st1b { z5.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z20.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z17.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "blt 10b\n"
+        "11:"  // Store to output array: Accumulator row 0 oddments
+        "cbz x20, 12f\n"
+        "move_tile_vector za0h.s, z4.s, z5.s, z6.s, z7.s, p7, w12 \n"
+        "move_tile_vector za1h.s, z12.s, z13.s, z14.s, z15.s, p7, w12 \n"
+        "scvtf_convert  z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "scvtf_convert  z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "fmul z4.s, z4.s, z22.s\n"
+        "fmul z5.s, z5.s, z22.s\n"
+        "subs x20, x20, #0x1\n"
+        "fmul z6.s, z6.s, z22.s\n"
+        "fmul z7.s, z7.s, z22.s\n"
+        "fmul z12.s, z12.s, z26.s\n"
+        "fmul z13.s, z13.s, z26.s\n"
+        "fmul z14.s, z14.s, z26.s\n"
+        "fmul z15.s, z15.s, z26.s\n"
+        "frintn_convert z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "fcvtzs_convert z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "add____convert z4.s, z5.s, z6.s, z7.s , z0.s \n"
+        "sclamp_convert z4.s, z5.s, z6.s, z7.s , z27.s, z1.s, p7 \n"
+        "frintn_convert z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "fcvtzs_convert z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "add____convert z12.s, z13.s, z14.s, z15.s,  z0.s \n"
+        "sclamp_convert z12.s, z13.s, z14.s, z15.s, z27.s, z1.s, p7 \n"
+        "uzp1 z16.h, z4.h, z12.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "beq 12f\n"
+        "subs x20, x20, #0x1\n"
+        "uzp1 z16.h, z5.h, z13.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "beq 12f\n"
+        "uzp1 z16.h, z6.h, z14.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "12:"  // Store to output array: Accumulator row 0 oddments: End
+        "subs x25, x25, x22\n"
+        "beq 16f\n"
+        "cmp x25, x24\n"
+        "mov x12, #0x0\n"
+        "csel x20, x25, x24, LT\n"
+        "lsr x21, x20, #0x2\n"
+        "and x20, x20, #0x3\n"
+        "cbz x21, 14f\n"
+        "13:"  // Store to output array: Accumulator row 1 loop
+        "move_tile_vector za2h.s, z8.s, z9.s, z10.s, z11.s, p7, w12\n"
+        "move_tile_vector za3h.s, z16.s, z17.s, z18.s, z19.s, p7, w12\n"
+        "scvtf_convert  z8.s, z9.s, z10.s, z11.s, p7  \n"
+        "scvtf_convert  z16.s, z17.s, z18.s, z19.s, p7   \n"
+        "fmul z8.s, z8.s, z22.s\n"
+        "fmul z9.s, z9.s, z22.s\n"
+        "add x12, x12, #0x4\n"
+        "fmul z10.s, z10.s, z22.s\n"
+        "fmul z11.s, z11.s, z22.s\n"
+        "cmp x12, x21, LSL #2\n"
+        "fmul z16.s, z16.s, z26.s\n"
+        "fmul z17.s, z17.s, z26.s\n"
+        "fmul z18.s, z18.s, z26.s\n"
+        "fmul z19.s, z19.s, z26.s\n"
+        "frintn_convert z8.s, z9.s, z10.s, z11.s, p7   \n"
+        "fcvtzs_convert z8.s, z9.s, z10.s, z11.s, p7   \n"
+        "add____convert z8.s, z9.s, z10.s, z11.s , z0.s \n"
+        "sclamp_convert z8.s, z9.s, z10.s, z11.s , z27.s, z1.s, p7 \n"
+        "frintn_convert z16.s, z17.s, z18.s, z19.s, p7   \n"
+        "fcvtzs_convert z16.s, z17.s, z18.s, z19.s, p7   \n"
+        "add____convert z16.s, z17.s, z18.s, z19.s,  z0.s \n"
+        "sclamp_convert z16.s, z17.s, z18.s, z19.s, z27.s, z1.s, p7 \n"
+        "uzp1 z21.h, z8.h, z16.h\n"
+        "uzp1 z20.h, z9.h, z17.h\n"
+        "uzp1 z17.h, z10.h, z18.h\n"
+        "uzp1 z16.h, z11.h, z19.h\n"
+        "st1b { z21.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z20.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z17.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "blt 13b\n"
+        "14:"  // Store to output array: Accumulator row 1 oddments
+        "cbz x20, 15f\n"
+        "move_tile_vector za2h.s, z12.s, z13.s, z14.s, z15.s, p7, w12 \n"
+        "move_tile_vector za3h.s, z4.s, z5.s, z6.s, z7.s, p7, w12 \n"
+        "scvtf_convert  z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "scvtf_convert  z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "fmul z12.s, z12.s, z22.s\n"
+        "fmul z13.s, z13.s, z22.s\n"
+        "subs x20, x20, #0x1\n"
+        "fmul z14.s, z14.s, z22.s\n"
+        "fmul z15.s, z15.s, z22.s\n"
+        "fmul z4.s, z4.s, z26.s\n"
+        "fmul z5.s, z5.s, z26.s\n"
+        "fmul z6.s, z6.s, z26.s\n"
+        "fmul z7.s, z7.s, z26.s\n"
+        "frintn_convert z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "fcvtzs_convert z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "add____convert z12.s, z13.s, z14.s, z15.s , z0.s \n"
+        "sclamp_convert z12.s, z13.s, z14.s, z15.s , z27.s, z1.s, p7 \n"
+        "frintn_convert z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "fcvtzs_convert z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "add____convert z4.s, z5.s, z6.s, z7.s,  z0.s \n"
+        "sclamp_convert z4.s, z5.s, z6.s, z7.s, z27.s, z1.s, p7 \n"
+        "uzp1 z16.h, z12.h, z4.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "beq 15f\n"
+        "subs x20, x20, #0x1\n"
+        "uzp1 z16.h, z13.h, z5.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "beq 15f\n"
+        "uzp1 z16.h, z14.h, z6.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "15:"  // Store to output array: Accumulator row 1 oddments: End
+        "16:"  // Store to output array: End
+        "incw x11, ALL, MUL #2\n"
+        "cmp x11, x10\n"
+        "blt 2b\n"
+        "incw x13, ALL, MUL #2\n"
+        "mov x11, #0x0\n"
+        "cmp x13, x14\n"
+        "mov x9, x27\n"
+        "blt 1b\n"
+        "SMSTOP\n"
+        :
+        : [args] "r"(&args), [offsetof_A] "I"(offsetof(KernelArgs, A)), [offsetof_B] "I"(offsetof(KernelArgs, B)),
+          [offsetof_C] "I"(offsetof(KernelArgs, C)), [offsetof_K] "I"(offsetof(KernelArgs, K)),
+          [offsetof_KernelArgs_max] "I"(offsetof(KernelArgs, max)),
+          [offsetof_KernelArgs_min] "I"(offsetof(KernelArgs, min)),
+          [offsetof_KernelArgs_result_zero_point] "I"(offsetof(KernelArgs, result_zero_point)),
+          [offsetof_M] "I"(offsetof(KernelArgs, M)), [offsetof_N] "I"(offsetof(KernelArgs, N)),
+          [offsetof_ldcb] "I"(offsetof(KernelArgs, ldcb))
+        : "cc", "memory", "p0", "p1", "p10", "p11", "p12", "p13", "p14", "p15", "p2", "p3", "p4", "p5", "p6", "p7",
+          "p8", "p9", "x10", "x11", "x12", "x13", "x14","x15", "x20", "x21", "x22", "x23", "x24", "x25", "x26", "x27", "x28",
+          "x9", "z0", "z1", "z10", "z11", "z12", "z13", "z14", "z15", "z16", "z17", "z18", "z19", "z2", "z20", "z21",
+          "z22", "z23", "z24", "z25", "z26", "z27", "z28", "z29", "z3", "z30", "z31", "z4", "z5", "z6", "z7", "z8",
+          "z9");
+}
+
+#endif  // Architectural features check.
diff --git a/kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/kai_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.h b/kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/kai_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.h
new file mode 100644
index 0000000..abd0121
--- /dev/null
+++ b/kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/kai_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.h
@@ -0,0 +1,100 @@
+//
+// SPDX-FileCopyrightText: Copyright 2025 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+#pragma once
+
+#include <stddef.h>
+
+#include "kai/kai_common.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif  // __cplusplus
+
+/// Micro-kernel dependencies
+/// -# kai_lhs_imatmul_pack_x8p2vlx4_x8p_sme to pack the LHS matrix.
+/// -# kai_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme to pack the RHS matrix.
+
+/// Gets m step value.
+///
+/// The starting row index must be divisible by `m_step`.
+///
+/// @return The m step value.
+size_t kai_get_m_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void);
+
+/// Gets n step value.
+///
+/// The starting column index must be divisible by `n_step`.
+///
+/// @return The n step value.
+size_t kai_get_n_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void);
+
+/// Gets the offset in bytes to the data element in the packed LHS matrix buffer.
+///
+/// @param[in] m_idx Row index in the unpacked LHS matrix. Must be a multiple of `m_step`.
+/// @param[in] k_chunk_count Number of LHS column splits.
+/// @param[in] k_chunk_length Length of a LHS column split.
+/// @param[in] k Number of columns in the unpacked LHS matrix.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_lhs_packed_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t k_chunk_count, size_t k_chunk_length);
+
+/// Gets the offset in bytes to the data element in the packed RHS matrix buffer.
+///
+/// @param[in] n_idx Column index in the unpacked RHS matrix. Must be a multiple of `n_step`.
+/// @param[in] k_chunk_count Number of LHS column splits.
+/// @param[in] k_chunk_length Length of a LHS column split.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_rhs_packed_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t n_idx, size_t k_chunk_count, size_t k_chunk_length);
+
+/// Gets the offset in bytes to the data element in the destination matrix buffer.
+///
+/// @param[in] m_idx Row index. Must be a multiple of `m_step`.
+/// @param[in] n_idx Column index. Must be a multiple of `n_step`.
+/// @param[in] dst_row_stride. Distance between start of two rows in the output buffer.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_dst_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_row_stride);
+
+/// Gets the size in bytes of the destination matrix buffer.
+///
+/// @param[in] m Number of rows.
+/// @param[in] n Number of columns.
+///
+/// @return The size in bytes of the destination matrix buffer.
+size_t kai_get_dst_size_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(size_t m, size_t n);
+
+/// Runs the matrix multiplication microkernel followed by a clamp operation.
+///
+/// The pointer of each buffers (packed LHS, packed RHS and output) needs to be added with offset
+/// calculated using the following functions:
+///
+///   * Packed LHS: @ref kai_get_lhs_packed_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.
+///   * Packed RHS: @ref kai_get_rhs_packed_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.
+///   * Output: @ref kai_get_dst_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.
+///
+/// @param[in] m Number of output rows to be computed.
+/// @param[in] n Number of output columns to be computed.
+/// @param[in] k_chunk_count Number of LHS column splits.
+/// @param[in] k_chunk_length Length of a LHS column split
+/// @param[in] lhs_packed Packed LHS matrix buffer.
+/// @param[in] rhs_packed Packed RHS matrix buffer.
+/// @param[out] dst Output matrix buffer.
+/// @param[in] dst_row_stride Row stride in bytes of the output matrix.
+
+/// @param[in] params Requantization and clamp parameters.
+
+void kai_run_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t m, size_t n, size_t k_chunk_count, size_t k_chunk_length, const void* lhs_packed, const void* rhs_packed,
+    void* dst, size_t dst_row_stride, const struct kai_matmul_requantize32_params* params);
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif  // __cplusplus
diff --git a/kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/helper_macros_matmul_clamp_f16_f16p_f16p.S b/kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/helper_macros_matmul_clamp_f16_f16p_f16p.S
new file mode 100644
index 0000000..ee2e643
--- /dev/null
+++ b/kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/helper_macros_matmul_clamp_f16_f16p_f16p.S
@@ -0,0 +1,11 @@
+
+.macro ld1h_data_2, reg1, reg2, pred, addr
+ld1h \reg1, \pred/Z, [\addr]
+ld1h \reg2, \pred/Z, [\addr, #1, MUL VL]
+addvl \addr, \addr, #2
+.endm
+
+.macro clamp_float reg, min_val, max_val, pred
+FMIN \reg, \pred/M, \reg, \min_val
+FMAX \reg, \pred/M, \reg, \max_val
+.endm
diff --git a/kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/kai_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.c b/kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/kai_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.c
new file mode 100644
index 0000000..e04a4a9
--- /dev/null
+++ b/kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/kai_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.c
@@ -0,0 +1,262 @@
+//
+// SPDX-FileCopyrightText: Copyright 2024-2025 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+// Do not flag up inline assembly blocks
+#pragma GCC diagnostic ignored "-Woverlength-strings"
+
+#if !defined(__aarch64__) || !defined(__ARM_FEATURE_SVE2)
+#error This file must be compiled for AArch64, FEAT_SVE2.
+#else  // Architectural features check.
+
+#include "kai_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.h"
+
+#include <arm_neon.h>
+#include <stddef.h>
+#include <stdint.h>
+
+#include "kai/kai_common.h"
+__asm__(".include \"helper_macros_matmul_clamp_f16_f16p_f16p.S\"");
+	
+
+static const size_t kai_mr = 2;
+static const size_t kai_nr = 2;
+static const size_t kai_kr = 2;
+static const size_t kai_sr = 1;
+
+size_t kai_get_m_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void) {
+    return kai_mr * kai_get_sme_vector_length_u16() / kai_kr;
+}
+
+size_t kai_get_n_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void) {
+    return kai_nr * kai_get_sme_vector_length_u16() / kai_kr;
+}
+
+size_t kai_get_mr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void) {
+    return kai_mr * kai_get_sme_vector_length_u16() / kai_kr;
+}
+
+size_t kai_get_nr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void) {
+    return kai_nr * kai_get_sme_vector_length_u16() / kai_kr;
+}
+
+size_t kai_get_kr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void) {
+    return kai_kr;
+}
+
+size_t kai_get_sr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void) {
+    return kai_sr;
+}
+
+size_t kai_get_lhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(size_t m_idx, size_t k) {
+    KAI_ASSUME(m_idx % kai_get_m_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa() == 0);
+    return m_idx * kai_roundup(k, kai_kr) * sizeof(uint16_t);
+}
+
+static size_t kai_get_rhs_packed_stride_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(size_t k) {
+    return kai_get_n_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa() *
+        (sizeof(uint16_t) + kai_roundup(k, kai_kr) * sizeof(uint16_t));
+}
+
+size_t kai_get_rhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(size_t n_idx, size_t k) {
+    KAI_ASSUME(n_idx % kai_get_n_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa() == 0);
+    const size_t block_idx = n_idx / kai_get_n_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa();
+    return block_idx * kai_get_rhs_packed_stride_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(k);
+}
+
+size_t kai_get_dst_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_stride) {
+    KAI_ASSUME(m_idx % kai_get_m_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa() == 0);
+    KAI_ASSUME(n_idx % kai_get_n_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa() == 0);
+
+    return m_idx * dst_stride + n_idx * sizeof(uint16_t);
+}
+
+size_t kai_get_dst_size_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(size_t m, size_t n) {
+    return m * n * sizeof(uint16_t);
+}
+
+void kai_run_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t m, size_t n, size_t k, const void* lhs_packed, const void* rhs_packed, void* dst, size_t dst_stride_row,
+    size_t dst_stride_col, float clamp_min, float clamp_max) {
+    KAI_ASSUME(dst_stride_col == sizeof(uint16_t));
+
+    typedef struct {
+        const void* A;
+        const void* B;
+
+        void* C;
+        uint64_t ldcb;
+        uint64_t M, N, K;
+        float16_t min;
+        float16_t max;
+
+        void* accumulator_buffer;
+        uint64_t flags;
+    } KernelArgs;
+
+    KernelArgs args;
+
+    args.A = lhs_packed;
+    args.B = rhs_packed;
+
+    args.C = dst;
+    args.ldcb = dst_stride_row;
+    args.M = m;
+    args.N = n;
+    args.K = k;
+    args.min = (float16_t)clamp_min;
+    args.max = (float16_t)clamp_max;
+
+    args.accumulator_buffer = NULL;
+    args.flags = 0;
+
+    __asm__ __volatile__(
+        "SMSTART \n"
+        "ldr w13, [%x[args], %[offsetof_M]]\n"
+        "mov x11, #0x0\n"
+        "mov x10, #0x0\n"
+        "ptrue p1.b\n"
+        " ptrue p2.b\n"
+        "ldr w9, [%x[args], %[offsetof_N]]\n"
+        "ldr x28, [%x[args], %[offsetof_A]]\n"
+        "1:"  // M loop
+        "ldr x27, [%x[args], %[offsetof_B]]\n"
+        "2:"  // N loop
+        "fmov z24.h, #0.0\n"
+        "ld1h { z5.h }, p1/Z, [x27]\n"
+        "fmov z27.h, #1.0\n"
+        "mov x26, x28\n"
+        "zero { za }\n"
+        "inch x27, ALL, MUL #2\n"
+        "zip1 z30.h, z5.h, z24.h\n"
+        "zip2 z20.h, z5.h, z24.h\n"
+        "fmopa za0.s, p1/M, p1/M, z27.h, z30.h\n"
+        "fmopa za1.s, p1/M, p1/M, z27.h, z20.h\n"
+        "fmopa za2.s, p1/M, p1/M, z27.h, z30.h\n"
+        "fmopa za3.s, p1/M, p1/M, z27.h, z20.h\n"
+        "ldr x20, [%x[args], %[offsetof_K]]\n"
+        "add x20, x20, #0x1\n"
+        "lsr x20, x20, #0x1\n"
+        "lsr x21, x20, #0x2\n"
+        "and x20, x20, #0x3\n"
+        "cbz x21, 6f\n"
+        "subs x21, x21, #0x1\n"	
+        "ld1h_data_2  z18.h,z19.h , p2, x26 \n"
+        "ld1h_data_2  z16.h,z17.h , p2, x27 \n"
+        "ld1h_data_2  z2.h,z10.h , p2, x26 \n"
+        "ld1h_data_2  z30.h,z31.h , p2, x27 \n"
+        "ld1h_data_2  z28.h,z29.h , p2, x26 \n"
+        "ld1h_data_2  z6.h,z14.h , p2, x27 \n"
+        "ld1h_data_2  z5.h, z13.h , p2, x26 \n"
+        "ld1h_data_2  z7.h, z15.h , p2, x27 \n"				  
+        "ble 5f\n"
+        "4:"  // K loop
+        " fmopa za0.s, p1/M, p1/M, z18.h, z16.h\n"
+        " fmopa za1.s, p1/M, p1/M, z18.h, z17.h\n"
+        " fmopa za2.s, p1/M, p1/M, z19.h, z16.h\n"
+        " fmopa za3.s, p1/M, p1/M, z19.h, z17.h\n"
+        " ld1h_data_2  z18.h,z19.h , p2, x26 \n"
+        " fmopa za0.s, p1/M, p1/M, z2.h, z30.h\n"
+        " ld1h_data_2  z16.h,z17.h , p2, x27 \n"
+        " fmopa za1.s, p1/M, p1/M, z2.h, z31.h\n"
+        " fmopa za2.s, p1/M, p1/M, z10.h, z30.h\n"
+        " fmopa za3.s, p1/M, p1/M, z10.h, z31.h\n"
+        " ld1h_data_2  z2.h, z10.h , p2, x26 \n"
+        " fmopa za0.s, p1/M, p1/M, z28.h, z6.h\n"
+        " ld1h_data_2  z30.h,z31.h , p2, x27 \n"
+        " fmopa za1.s, p1/M, p1/M, z28.h, z14.h\n"
+        " fmopa za2.s, p1/M, p1/M, z29.h, z6.h\n"
+        " fmopa za3.s, p1/M, p1/M, z29.h, z14.h\n"
+        " ld1h_data_2  z28.h,z29.h , p2, x26 \n"
+        " ld1h_data_2  z6.h, z14.h , p2, x27 \n"
+        " fmopa za0.s, p1/M, p1/M, z5.h, z7.h\n"
+        " fmopa za1.s, p1/M, p1/M, z5.h, z15.h\n"
+        " fmopa za2.s, p1/M, p1/M, z13.h, z7.h\n"
+        " fmopa za3.s, p1/M, p1/M, z13.h, z15.h\n"
+        " ld1h_data_2  z5.h, z13.h , p2, x26 \n"
+        " ld1h_data_2  z7.h, z15.h , p2, x27 \n"
+        "subs x21, x21, #0x1\n"							  
+        "bgt 4b\n"
+        "5:"  // K loop tail
+        " fmopa za0.s, p1/M, p1/M, z18.h, z16.h\n"
+        " fmopa za1.s, p1/M, p1/M, z18.h, z17.h\n"
+        " fmopa za2.s, p1/M, p1/M, z19.h, z16.h\n"
+        " fmopa za3.s, p1/M, p1/M, z19.h, z17.h\n"
+        " fmopa za0.s, p1/M, p1/M, z2.h, z30.h\n"
+        " fmopa za1.s, p1/M, p1/M, z2.h, z31.h\n"
+        " fmopa za2.s, p1/M, p1/M, z10.h, z30.h\n"
+        " fmopa za3.s, p1/M, p1/M, z10.h, z31.h\n"
+        " fmopa za0.s, p1/M, p1/M, z28.h, z6.h\n"
+        " fmopa za1.s, p1/M, p1/M, z28.h, z14.h\n"
+        " fmopa za2.s, p1/M, p1/M, z29.h, z6.h\n"
+        " fmopa za3.s, p1/M, p1/M, z29.h, z14.h\n"
+        " fmopa za0.s, p1/M, p1/M, z5.h, z7.h\n"
+        " fmopa za1.s, p1/M, p1/M, z5.h, z15.h\n"
+        " fmopa za2.s, p1/M, p1/M, z13.h, z7.h\n"
+        " fmopa za3.s, p1/M, p1/M, z13.h, z15.h\n"
+        "6:"  // K oddments
+        "cbz x20, 8f\n"
+        "7:"  // K oddments: Loop
+        " ld1h_data_2  z5.h, z13.h , p2, x26\n"
+		"subs x20, x20, #0x1\n"
+        " ld1h_data_2  z14.h,z15.h , p2, x27\n"	  
+        " fmopa za0.s, p1/M, p1/M, z5.h, z14.h\n"
+        " fmopa za1.s, p1/M, p1/M, z5.h, z15.h\n"
+        " fmopa za2.s, p1/M, p1/M, z13.h, z14.h\n"
+        " fmopa za3.s, p1/M, p1/M, z13.h, z15.h\n"
+        "bgt 7b\n"
+        "8:"  // K oddments: End
+        "ldr x25, [%x[args], %[offsetof_C]]\n"
+        "sub x24, x13, x11\n"
+        "cntw x23, ALL, MUL #2\n"
+        "ld1rh { z17.h }, p1/Z, [%x[args], %[offsetof_KernelArgs_min]]\n"
+        "ldr x22, [%x[args], %[offsetof_ldcb]]\n"
+        "whilelt p0.h, x10, x9\n"
+        "cmp x24, x23\n"
+        "ld1rh { z16.h }, p1/Z, [%x[args], %[offsetof_KernelArgs_max]]\n"
+        "mov x12, #0x0\n"
+        "mov x21, #0x0\n"
+        "add x25, x25, x10, LSL #1\n"  // C += n
+        "mov x20, #0x2\n"
+        "madd x25, x11, x22, x25\n"  // C += m * ldc
+        "csel x24, x24, x23, LT\n"
+        "10:"  // Store to output array: Accumulator loop
+        "mova z14.b,p1/M, za0h.b[w12, 0]\n"
+        "mova z15.b,p1/M, za0h.b[w12, 1]\n"
+		"add x12, x12, #0x4\n"
+        "cmp x12, x23, LSL #1\n"
+        "add x21, x21, #0x1\n"
+        "fcvt z0.h, p1/M,   z14.s\n"
+        "fcvt z1.h, p1/M,   z15.s\n"
+        "uzp1 z12.h ,z0.h,  z1.h\n"
+        "csel x12, x12, x20, LT\n"
+        "clamp_float z12.h, z17.h, z16.h, p1 \n"
+        "st1h { z12.h }, p0, [x25]\n"
+        "add x25, x25, x22\n"
+        "cmp x21, x24\n"
+        "blt 10b\n"
+        "incw x10, ALL, MUL #2\n"
+        "cmp x10, x9\n"
+        "blt 2b\n"
+        "incw x11, ALL, MUL #2\n"
+        "mov x10, #0x0\n"
+		"cmp x11, x13\n"
+        "mov x28, x26\n"
+        "blt 1b\n"
+        "SMSTOP\n"
+        :
+        : [args] "r"(&args), [offsetof_A] "I"(offsetof(KernelArgs, A)), [offsetof_B] "I"(offsetof(KernelArgs, B)),
+          [offsetof_C] "I"(offsetof(KernelArgs, C)), [offsetof_K] "I"(offsetof(KernelArgs, K)),
+          [offsetof_KernelArgs_max] "I"(offsetof(KernelArgs, max)),
+          [offsetof_KernelArgs_min] "I"(offsetof(KernelArgs, min)), [offsetof_M] "I"(offsetof(KernelArgs, M)),
+          [offsetof_N] "I"(offsetof(KernelArgs, N)), [offsetof_ldcb] "I"(offsetof(KernelArgs, ldcb))
+        : "cc", "memory", "p0", "p1", "p10", "p11", "p12", "p13", "p14", "p15", "p2", "p3", "p4", "p5", "p6", "p7",
+          "p8", "p9", "x10", "x11", "x12", "x13", "x20", "x21", "x22", "x23", "x24", "x25", "x26", "x27", "x28", "x9",
+          "z0", "z1", "z10", "z11", "z12", "z13", "z14", "z15", "z16", "z17", "z18", "z19", "z2", "z20", "z21", "z22",
+          "z23", "z24", "z25", "z26", "z27", "z28", "z29", "z3", "z30", "z31", "z4", "z5", "z6", "z7", "z8", "z9");
+}
+
+#endif  // Architectural features check.
diff --git a/kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/kai_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.h b/kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/kai_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.h
new file mode 100644
index 0000000..e357b43
--- /dev/null
+++ b/kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/kai_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.h
@@ -0,0 +1,125 @@
+//
+// SPDX-FileCopyrightText: Copyright 2024 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+#pragma once
+
+#include <stddef.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif  // __cplusplus
+
+/// Micro-kernel dependencies
+///
+/// -# kai_lhs_pack_f16p2vlx2_f16_sme to pack the LHS matrix.
+/// -# kai_rhs_pack_kxn_f16p2vlx2b_f16_f16_sme to pack the RHS matrix.
+
+/// Gets m step value.
+///
+/// The starting row index must be divisible by `m_step`.
+///
+/// @return The m step value.
+size_t kai_get_m_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void);
+
+/// Gets n step value.
+///
+/// The starting column index must be divisible by `n_step`.
+///
+/// @return The n step value.
+size_t kai_get_n_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void);
+
+/// Gets mr value.
+///
+/// This is the packing parameter which must be used to pack the LHS matrix.
+///
+/// @return The mr value.
+size_t kai_get_mr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void);
+
+/// Gets nr value.
+///
+/// This is the packing parameter which must be used to pack the RHS matrix.
+///
+/// @return The nr value.
+size_t kai_get_nr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void);
+
+/// Gets kr value.
+///
+/// This is the packing parameter which must be used to pack the LHS and RHS matrix.
+///
+/// @return The kr value.
+size_t kai_get_kr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void);
+
+/// Gets sr value.
+///
+/// This is the packing parameter which must be used to pack the LHS and RHS matrix.
+///
+/// @return The sr value.
+size_t kai_get_sr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(void);
+
+/// Gets the offset in bytes to the data element in the packed LHS matrix buffer.
+///
+/// @param[in] m_idx Row index in the unpacked LHS matrix. Must be a multiple of `m_step`
+/// @param[in] k Number of columns in the unpacked LHS matrix.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_lhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(size_t m_idx, size_t k);
+
+/// Gets the offset in bytes to the data element in the packed RHS matrix buffer.
+///
+/// @param[in] n_idx Column index in the unpacked RHS matrix. Must be a multiple of `n_step`
+/// @param[in] k Number of rows in the unpacked RHS matrix.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_rhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(size_t n_idx, size_t k);
+
+/// Gets the offset in bytes to the data element in the destination matrix buffer.
+///
+/// @param[in] m_idx Row index. Must be a multiple of `m_step`
+/// @param[in] n_idx Column index. Must be a multiple of `n_step`
+/// @param[in] stride Row stride in bytes.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_dst_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_stride);
+
+/// Gets the size in bytes of the destination matrix buffer.
+///
+/// @param[in] m Number of rows.
+/// @param[in] n Number of columns.
+///
+/// @return The size in bytes of the destination matrix buffer.
+size_t kai_get_dst_size_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(size_t m, size_t n);
+
+/// Runs the matrix multiplication microkernel followed by a clamp operation.
+///
+/// The pointer of each buffers (packed LHS, packed RHS and output) needs to be added with offset
+/// calculated using the following functions:
+///
+///   * Packed LHS: @ref kai_get_lhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.
+///   * Packed RHS: @ref kai_get_rhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.
+///   * Output: @ref kai_get_dst_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.
+///
+/// @param[in] m Number of output rows to be computed.
+/// @param[in] n Number of output columns to be computed.
+/// @param[in] k Common dimension of the LHS and RHS operands.
+/// @param[in] lhs_packed Packed LHS matrix buffer.
+/// @param[in] rhs_packed Packed RHS matrix buffer.
+/// @param[out] dst Output matrix buffer.
+/// @param[in] dst_stride_row Row stride in bytes of the output matrix.
+/// @param[in] dst_stride_col Column stride in bytes of the output matrix. Must be 2
+/// @param[in] clamp_min Minimum value to clamp the final result.
+/// @param[in] clamp_max Maximum value to clamp the final result.
+///
+/// @note Clamp minimum and maximum values are cast internally to the destination type before clamping the computed
+/// values.
+///
+void kai_run_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa(
+    size_t m, size_t n, size_t k, const void* lhs_packed, const void* rhs_packed, void* dst, size_t dst_stride_row,
+    size_t dst_stride_col, float clamp_min, float clamp_max);
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif  // __cplusplus
diff --git a/kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/helper_macros_matmul_clamp_f32_f32p_f32p.S b/kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/helper_macros_matmul_clamp_f32_f32p_f32p.S
new file mode 100644
index 0000000..8e45142
--- /dev/null
+++ b/kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/helper_macros_matmul_clamp_f32_f32p_f32p.S
@@ -0,0 +1,68 @@
+.macro load_data, reg1, reg2, reg3, reg4, pred, addr
+ld1w \reg1, \pred/Z, [\addr]
+ld1w \reg2, \pred/Z, [\addr, #1, MUL VL]
+ld1w \reg3, \pred/Z, [\addr, #2, MUL VL]
+ld1w \reg4, \pred/Z, [\addr, #3, MUL VL]
+addvl \addr, \addr, #4
+.endm
+
+.macro load_data_2, reg1, reg2, pred, addr
+ld1w \reg1, \pred/Z, [\addr]
+ld1w \reg2, \pred/Z, [\addr, #1, MUL VL]
+addvl \addr, \addr, #2
+.endm
+
+.macro store_data, reg1, reg2, reg3, reg4, pred, addr
+st1w \reg1, \pred, [\addr]
+st1w \reg2, \pred, [\addr, #1, MUL VL]
+st1w \reg3, \pred, [\addr, #2, MUL VL]
+st1w \reg4, \pred, [\addr, #3, MUL VL]
+addvl \addr, \addr, #4
+.endm
+
+
+.macro move_vector_tile, tile, reg1, reg2, reg3, reg4, pred, addr
+mova \tile[\addr, 0], \pred/M, \reg1
+mova \tile[\addr, 1], \pred/M, \reg2
+mova \tile[\addr, 2], \pred/M, \reg3
+mova \tile[\addr, 3], \pred/M, \reg4
+.endm
+
+.macro move_tile_vector, tile, reg1, reg2, reg3, reg4, pred, addr
+mova \reg1, \pred/M, \tile[\addr, 0] 
+mova \reg2, \pred/M, \tile[\addr, 1] 
+mova \reg3, \pred/M, \tile[\addr, 2] 
+mova \reg4, \pred/M, \tile[\addr, 3] 
+.endm
+
+.macro clamp_float reg, max_val, min_val, pred
+FMIN \reg, \pred/M, \reg, \max_val
+FMAX \reg, \pred/M, \reg, \min_val
+.endm
+
+
+
+
+.macro load_data_pred_index_counter_2, reg1, reg2, predr, predtype, start_idx, end_idx, addr, word_length
+cntw \word_length
+whilelt \predtype, \start_idx, \end_idx
+ld1w \reg1, \predr/Z, [\addr]
+add \start_idx, \start_idx, \word_length
+whilelt \predtype, \start_idx, \end_idx
+ld1w \reg2, \predr/Z, [\addr, #1, MUL VL]
+neg \word_length, \word_length
+add \start_idx, \start_idx, \word_length
+neg \word_length, \word_length
+.endm
+
+.macro store_data_pred_index_counter_2, reg1, reg2, predr, predtype, start_idx, end_idx, addr, word_length
+cntw \word_length
+whilelt \predtype, \start_idx, \end_idx
+st1w \reg1, \predr, [\addr]
+add \start_idx, \start_idx, \word_length
+whilelt \predtype, \start_idx, \end_idx
+st1w \reg2, \predr, [\addr, #1, MUL VL]
+neg \word_length, \word_length
+add \start_idx, \start_idx, \word_length
+neg \word_length, \word_length
+.endm
diff --git a/kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/kai_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.c b/kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/kai_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.c
new file mode 100644
index 0000000..32a28d0
--- /dev/null
+++ b/kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/kai_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.c
@@ -0,0 +1,503 @@
+//
+// SPDX-FileCopyrightText: Copyright 2024-2025 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+// Do not flag up inline assembly blocks
+#pragma GCC diagnostic ignored "-Woverlength-strings"
+
+#if !defined(__aarch64__) || !defined(__ARM_FEATURE_SVE2)
+#error This file must be compiled for AArch64, FEAT_SVE2.
+#else  // Architectural features check.
+
+#include "kai_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.h"
+__asm__(".include \"helper_macros_matmul_clamp_f32_f32p_f32p.S\"");
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include "kai/kai_common.h"
+
+static const size_t kai_mr = 2;
+static const size_t kai_nr = 2;
+static const size_t kai_kr = 1;
+static const size_t kai_sr = 1;
+
+size_t kai_get_m_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void) {
+    return kai_mr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_n_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void) {
+    return kai_nr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_mr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void) {
+    return kai_mr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_nr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void) {
+    return kai_nr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_kr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void) {
+    return kai_kr;
+}
+
+size_t kai_get_sr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void) {
+    return kai_sr;
+}
+
+size_t kai_get_lhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(size_t m_idx, size_t k) {
+    KAI_ASSUME(m_idx % kai_get_m_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa() == 0);
+    return m_idx * k * sizeof(float);
+}
+
+size_t kai_get_rhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(size_t n_idx, size_t k) {
+    KAI_ASSUME(n_idx % kai_get_n_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa() == 0);
+    return n_idx * (k * sizeof(float) + sizeof(float));
+}
+
+size_t kai_get_dst_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_stride) {
+    KAI_ASSUME(m_idx % kai_get_m_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa() == 0);
+    KAI_ASSUME(n_idx % kai_get_n_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa() == 0);
+
+    return m_idx * dst_stride + n_idx * sizeof(float);
+}
+
+size_t kai_get_dst_size_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(size_t m, size_t n) {
+    return m * n * sizeof(float);
+}
+
+void kai_run_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(
+    size_t m, size_t n, size_t k, const void* lhs_packed, const void* rhs_packed, void* dst, size_t dst_stride_row,
+    size_t dst_stride_col, float clamp_min, float clamp_max) {
+    KAI_ASSUME(dst_stride_col == sizeof(float));
+
+    typedef struct {
+        const void* A;
+        const void* B;
+
+        void* C;
+        uint64_t ldcb;
+        uint64_t M, N, K;
+        float min;
+        float max;
+
+        void* accumulator_buffer;
+        uint64_t flags;
+    } KernelArgs;
+
+    KernelArgs args;
+
+    args.A = lhs_packed;
+    args.B = rhs_packed;
+
+    args.C = dst;
+    args.ldcb = dst_stride_row;
+    args.M = m;
+    args.N = n;
+    args.K = k;
+    args.min = clamp_min;
+    args.max = clamp_max;
+
+    args.accumulator_buffer = NULL;
+    args.flags = 0;
+
+    __asm__ __volatile__(
+        "ldr x17, [%x[args], %[offsetof_flags]]\n"
+        "SMSTART\n"
+        "ptrue p0.b\n"
+        "ptrue p7.b\n"
+        "ldr x16, [%x[args], %[offsetof_accumulator_buffer]]\n"
+        "ldr x15, [%x[args], %[offsetof_accumulator_buffer]]\n"
+        "tbz x17, #0, 2f\n"
+        "mov x12, #0x0\n"
+        "cntw x20\n"
+        "1:"  // Initial accumulator load from buffer: Loop
+        "load_data z24.s, z25.s, z26.s, z27.s, p7, x16\n"
+        "load_data z12.s, z13.s, z14.s, z15.s, p7, x16\n"
+        "load_data z0.s, z1.s, z2.s, z3.s, p7, x16\n"
+        "load_data z16.s, z17.s, z18.s, z19.s, p7, x16\n"
+        "move_vector_tile za0h.s, z24.s, z25.s, z26.s, z27.s, p7, w12\n"
+        "move_vector_tile za1h.s, z12.s, z13.s, z14.s, z15.s, p7, w12\n"
+        "move_vector_tile za2h.s, z0.s, z1.s, z2.s, z3.s, p7, w12\n"
+        "move_vector_tile za3h.s, z16.s, z17.s, z18.s, z19.s, p7, w12\n"
+        "add x12, x12, #0x4\n"
+        "cmp x12, x20\n"
+        "blt 1b\n"
+        "2:"  // Initial accumulator load from buffer: End
+        "ldr w14, [%x[args], %[offsetof_M]]\n"
+        "mov x13, #0x0\n"
+        "mov x11, #0x0\n"
+        "ldr w10, [%x[args], %[offsetof_N]]\n"
+        "ldr x9, [%x[args], %[offsetof_A]]\n"
+        "3:"  // M loop
+        "ldr x28, [%x[args], %[offsetof_B]]\n"
+        "4:"  // N loop
+        "mov x27, x9\n"
+        "whilelt p4.s, x11, x10\n"
+        "tbnz x17, #0, 5f\n"
+        "fmov z17.s, #1.0\n"
+        "load_data_pred_index_counter_2 z10.s, z11.s, p4, p4.s, x11, x10, x28, x8 \n"  // Load bias
+        "zero { za }\n"
+        "addvl x28, x28, #2\n"
+        "fmopa za0.s, p0/M, p0/M, z17.s, z10.s\n"
+        "fmopa za1.s, p0/M, p0/M, z17.s, z11.s\n"
+        "fmopa za2.s, p0/M, p0/M, z17.s, z10.s\n"
+        "fmopa za3.s, p0/M, p0/M, z17.s, z11.s\n"
+        "5:"  // Prepare accumulators: Test for last block
+        "mov x20, x11\n"
+        "mov x21, x13\n"
+        "incw x20, ALL, MUL #2\n"
+        "incw x21, ALL, MUL #2\n"
+        "cmp x20, x10\n"
+        "mov x20, x17\n"
+        "csel x21, x13, x21, LT\n"
+        "bfm x17, XZR, #0x0, #0x0  // bfc x17, #0x0, #0x1\n"
+        "cmp x21, x14\n"
+        "csel x17, x20, x17, LT\n"
+        "ldr x20, [%x[args], %[offsetof_K]]\n"
+        "lsr x21, x20, #0x2\n"
+        "and x20, x20, #0x3\n"
+        "cbz x21, 9f\n"
+        "subs x21, x21, #0x1\n"
+        "load_data_2 z22.s, z23.s, p7, x27\n"
+        "load_data_2 z7.s, z15.s, p7, x28\n"
+        "load_data_2 z6.s, z14.s, p7, x27\n"
+        "load_data_2 z20.s, z21.s, p7, x28\n"
+        "load_data_2 z2.s, z10.s, p7, x27\n"
+        "load_data_2 z3.s, z11.s, p7, x28\n"
+        "load_data_2 z1.s, z9.s, p7, x27\n"
+        "load_data_2 z4.s, z5.s, p7, x28\n"
+        "ble 8f\n"
+        "7:"  // K loop
+        "fmopa za0.s, p0/M, p0/M, z22.s, z7.s\n"
+        "subs x21, x21, #0x1\n"
+        "fmopa za1.s, p0/M, p0/M, z22.s, z15.s\n"
+        "fmopa za2.s, p0/M, p0/M, z23.s, z7.s\n"
+        "fmopa za3.s, p0/M, p0/M, z23.s, z15.s\n"
+        "load_data_2 z22.s, z23.s, p7, x27\n"
+        "fmopa za0.s, p0/M, p0/M, z6.s, z20.s\n"
+        "load_data_2 z7.s, z15.s, p7, x28\n"
+        "fmopa za1.s, p0/M, p0/M, z6.s, z21.s\n"
+        "fmopa za2.s, p0/M, p0/M, z14.s, z20.s\n"
+        "fmopa za3.s, p0/M, p0/M, z14.s, z21.s\n"
+        "load_data_2 z6.s, z14.s, p7, x27\n"
+        "fmopa za0.s, p0/M, p0/M, z2.s, z3.s\n"
+        "load_data_2 z20.s, z21.s, p7, x28\n"
+        "fmopa za1.s, p0/M, p0/M, z2.s, z11.s\n"
+        "fmopa za2.s, p0/M, p0/M, z10.s, z3.s\n"
+        "fmopa za3.s, p0/M, p0/M, z10.s, z11.s\n"
+        "load_data_2 z2.s, z10.s, p7, x27\n"
+        "load_data_2 z3.s, z11.s, p7, x28\n"
+        "fmopa za0.s, p0/M, p0/M, z1.s, z4.s\n"
+        "fmopa za1.s, p0/M, p0/M, z1.s, z5.s\n"
+        "fmopa za2.s, p0/M, p0/M, z9.s, z4.s\n"
+        "fmopa za3.s, p0/M, p0/M, z9.s, z5.s\n"
+        "load_data_2 z1.s, z9.s, p7, x27\n"
+        "load_data_2 z4.s, z5.s, p7, x28\n"
+        "bgt 7b\n"
+        "8:"  // K loop tail
+        "fmopa za0.s, p0/M, p0/M, z22.s, z7.s\n"
+        "fmopa za1.s, p0/M, p0/M, z22.s, z15.s\n"
+        "fmopa za2.s, p0/M, p0/M, z23.s, z7.s\n"
+        "fmopa za3.s, p0/M, p0/M, z23.s, z15.s\n"
+        "fmopa za0.s, p0/M, p0/M, z6.s, z20.s\n"
+        "fmopa za1.s, p0/M, p0/M, z6.s, z21.s\n"
+        "fmopa za2.s, p0/M, p0/M, z14.s, z20.s\n"
+        "fmopa za3.s, p0/M, p0/M, z14.s, z21.s\n"
+        "fmopa za0.s, p0/M, p0/M, z2.s, z3.s\n"
+        "fmopa za1.s, p0/M, p0/M, z2.s, z11.s\n"
+        "fmopa za2.s, p0/M, p0/M, z10.s, z3.s\n"
+        "fmopa za3.s, p0/M, p0/M, z10.s, z11.s\n"
+        "fmopa za0.s, p0/M, p0/M, z1.s, z4.s\n"
+        "fmopa za1.s, p0/M, p0/M, z1.s, z5.s\n"
+        "fmopa za2.s, p0/M, p0/M, z9.s, z4.s\n"
+        "fmopa za3.s, p0/M, p0/M, z9.s, z5.s\n"
+        "9:"  // K oddments
+        "cbz x20, 11f\n"
+        "10:"  // K oddments: Loop
+        "load_data_2 z10.s, z11.s, p7, x27\n"
+        "subs x20, x20, #0x1\n"
+        "load_data_2 z14.s, z15.s, p7, x28\n"
+        "fmopa za0.s, p0/M, p0/M, z10.s, z14.s\n"
+        "fmopa za1.s, p0/M, p0/M, z10.s, z15.s\n"
+        "fmopa za2.s, p0/M, p0/M, z11.s, z14.s\n"
+        "fmopa za3.s, p0/M, p0/M, z11.s, z15.s\n"
+        "bgt 10b\n"
+        "11:"  // K oddments: End
+        "tbz x17, #1, 15f\n"
+        "tbz x17, #0, 13f\n"
+        "mov x12, #0x0\n"
+        "cntw x20\n"
+        "12:"  // Store to partial result buffer: Store and refill: Loop
+        "load_data z0.s, z1.s, z2.s, z3.s, p7, x16\n"
+        "move_tile_vector za0h.s, z20.s, z21.s, z22.s, z23.s, p7, w12\n"
+        "move_tile_vector za1h.s, z28.s, z29.s, z30.s, z31.s, p7, w12\n"
+        "load_data z4.s, z5.s, z6.s, z7.s, p7, x16\n"
+        "move_tile_vector za2h.s, z8.s, z9.s, z10.s, z11.s, p7, w12\n"
+        "move_tile_vector za3h.s, z12.s, z13.s, z14.s, z15.s, p7, w12\n"
+        "load_data z16.s, z17.s, z18.s, z19.s, p7, x16\n"
+        "load_data z24.s, z25.s, z26.s, z27.s, p7, x16\n"
+        "move_vector_tile za0h.s, z0.s, z1.s, z2.s, z3.s, p7, w12\n"
+        "move_vector_tile za1h.s, z4.s, z5.s, z6.s, z7.s, p7, w12\n"
+        "store_data z20.s, z21.s, z22.s, z23.s, p7, x15\n"
+        "move_vector_tile za2h.s, z16.s, z17.s, z18.s, z19.s, p7, w12\n"
+        "store_data z28.s, z29.s, z30.s, z31.s, p7, x15\n"
+        "move_vector_tile za3h.s, z24.s, z25.s, z26.s, z27.s, p7, w12\n"
+        "add x12, x12, #0x4\n"
+        "store_data z8.s, z9.s, z10.s, z11.s, p7, x15\n"
+        "cmp x12, x20\n"
+        "store_data z12.s, z13.s, z14.s, z15.s, p7, x15\n"
+        "blt 12b\n"
+        "b 31f\n"
+        "13:"  // Store to partial result buffer: Store only
+        "mov x12, #0x0\n"
+        "cntw x20\n"
+        "14:"  // Store to partial result buffer: Store only: Loop
+        "move_tile_vector za0h.s, z0.s, z1.s, z2.s, z3.s, p7, w12\n"
+        "move_tile_vector za1h.s, z16.s, z17.s, z18.s, z19.s, p7, w12\n"
+        "move_tile_vector za2h.s, z28.s, z29.s, z30.s, z31.s, p7, w12\n"
+        "move_tile_vector za3h.s, z20.s, z21.s, z22.s, z23.s, p7, w12\n"
+        "store_data z0.s, z1.s, z2.s, z3.s, p7, x15\n"
+        "add x12, x12, #0x4\n"
+        "store_data z16.s, z17.s, z18.s, z19.s, p7, x15\n"
+        "cmp x12, x20\n"
+        "store_data z28.s, z29.s, z30.s, z31.s, p7, x15\n"
+        "store_data z20.s, z21.s, z22.s, z23.s, p7, x15\n"
+        "blt 14b\n"
+        "b 31f\n"
+        "15:"  // Store to output array
+        "ldr x26, [%x[args], %[offsetof_C]]\n"
+        "sub x25, x14, x13\n"
+        "ldr x24, [%x[args], %[offsetof_ldcb]]\n"
+        "add x26, x26, x11, LSL #2\n"  // C += n
+        "madd x26, x13, x24, x26\n"    // C += m * ldc
+        "tbz x17, #2, 22f\n"
+        "cntw x23\n"
+        "mov x12, #0x0\n"
+        "cmp x25, x23\n"
+        "csel x22, x25, x23, LT\n"
+        "lsr x21, x22, #0x2\n"
+        "and x20, x22, #0x3\n"
+        "cbz x21, 17f\n"
+        "16:"  // Store to output array: Skip activation: Accumulator row 0 loop
+        "move_tile_vector za0h.s, z4.s, z5.s, z6.s, z7.s, p7, w12\n"
+        "move_tile_vector za1h.s, z12.s, z13.s, z14.s, z15.s, p7, w12\n"
+        "store_data_pred_index_counter_2 z4.s, z12.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "add x12, x12, #0x4\n"
+        "store_data_pred_index_counter_2 z5.s, z13.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "store_data_pred_index_counter_2 z6.s, z14.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "store_data_pred_index_counter_2 z7.s, z15.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "cmp x12, x21, LSL #2\n"
+        "blt 16b\n"
+        "17:"  // Store to output array: Skip activation: Accumulator row 0 oddments
+        "cbz x20, 18f\n"
+        "move_tile_vector za0h.s, z0.s, z1.s, z2.s, z3.s, p7, w12\n"
+        "move_tile_vector za1h.s, z8.s, z9.s, z10.s, z11.s, p7, w12\n"
+        "store_data_pred_index_counter_2 z0.s, z8.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "subs x20, x20, #0x1\n"
+        "add x26, x26, x24\n"
+        "beq 18f\n"
+        "store_data_pred_index_counter_2 z1.s, z9.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "subs x20, x20, #0x1\n"
+        "add x26, x26, x24\n"
+        "beq 18f\n"
+        "store_data_pred_index_counter_2 z2.s, z10.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "18:"  // Store to output array: Skip activation: Accumulator row 0 oddments: End
+        "subs x25, x25, x22\n"
+        "beq 22f\n"
+        "cmp x25, x23\n"
+        "mov x12, #0x0\n"
+        "csel x22, x25, x23, LT\n"
+        "lsr x21, x22, #0x2\n"
+        "and x20, x22, #0x3\n"
+        "cbz x21, 20f\n"
+        "19:"  // Store to output array: Skip activation: Accumulator row 1 loop
+        "move_tile_vector za2h.s, z4.s, z5.s, z6.s, z7.s, p7, w12\n"
+        "move_tile_vector za3h.s, z12.s, z13.s, z14.s, z15.s, p7, w12\n"
+        "store_data_pred_index_counter_2 z4.s, z12.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "add x12, x12, #0x4\n"
+        "store_data_pred_index_counter_2 z5.s, z13.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "store_data_pred_index_counter_2 z6.s, z14.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "store_data_pred_index_counter_2 z7.s, z15.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "cmp x12, x21, LSL #2\n"
+        "blt 19b\n"
+        "20:"  // Store to output array: Skip activation: Accumulator row 1 oddments
+        "cbz x20, 21f\n"
+        "move_tile_vector za2h.s, z4.s, z5.s, z6.s, z7.s, p7, w12\n"
+        "move_tile_vector za3h.s, z12.s, z13.s, z14.s, z15.s, p7, w12\n"
+        "store_data_pred_index_counter_2 z4.s, z12.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "subs x20, x20, #0x1\n"
+        "add x26, x26, x24\n"
+        "beq 21f\n"
+        "store_data_pred_index_counter_2 z5.s, z13.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "subs x20, x20, #0x1\n"
+        "add x26, x26, x24\n"
+        "beq 21f\n"
+        "store_data_pred_index_counter_2 z6.s, z14.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "21:"  // Store to output array: Skip activation: Accumulator row 1 oddments: End
+        "subs x25, x25, x22\n"
+        "beq 22f\n"
+        "b 29f\n"
+        "22:"  // Store to output array: Skip activation: End
+        "cntw x23\n"
+        "ld1rw { z21.s }, p0/Z, [%x[args], %[offsetof_KernelArgs_min]]\n"
+        "mov x12, #0x0\n"
+        "cmp x25, x23\n"
+        "ld1rw { z20.s }, p0/Z, [%x[args], %[offsetof_KernelArgs_max]]\n"
+        "csel x22, x25, x23, LT\n"
+        "lsr x21, x22, #0x2\n"
+        "and x20, x22, #0x3\n"
+        "cbz x21, 24f\n"
+        "23:"  // Store to output array: Accumulator row 0 loop
+        "move_tile_vector za0h.s, z16.s, z17.s, z18.s, z19.s, p7, w12\n"
+        "move_tile_vector za1h.s, z24.s, z25.s, z26.s, z27.s, p7, w12\n"
+        "clamp_float z16.s, z20.s, z21.s, p7\n"
+        "clamp_float z17.s, z20.s, z21.s, p7\n"
+        "clamp_float z18.s, z20.s, z21.s, p7\n"
+        "clamp_float z19.s, z20.s, z21.s, p7\n"
+        "clamp_float z24.s, z20.s, z21.s, p7\n"
+        "clamp_float z25.s, z20.s, z21.s, p7\n"
+        "clamp_float z26.s, z20.s, z21.s, p7\n"
+        "clamp_float z27.s, z20.s, z21.s, p7\n"
+        "add x12, x12, #0x4\n"
+        "store_data_pred_index_counter_2 z16.s, z24.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "store_data_pred_index_counter_2 z17.s, z25.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "store_data_pred_index_counter_2 z18.s, z26.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "store_data_pred_index_counter_2 z19.s, z27.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "cmp x12, x21, LSL #2\n"
+        "blt 23b\n"
+        "24:"  // Store to output array: Accumulator row 0 oddments
+        "cbz x20, 25f\n"
+        "move_tile_vector za0h.s, z16.s, z17.s, z18.s, z19.s, p7, w12\n"
+        "move_tile_vector za1h.s, z24.s, z25.s, z26.s, z27.s, p7, w12\n"
+        "clamp_float z16.s, z20.s, z21.s, p7\n"
+        "clamp_float z17.s, z20.s, z21.s, p7\n"
+        "clamp_float z18.s, z20.s, z21.s, p7\n"
+        "clamp_float z19.s, z20.s, z21.s, p7\n"
+        "clamp_float z24.s, z20.s, z21.s, p7\n"
+        "clamp_float z25.s, z20.s, z21.s, p7\n"
+        "clamp_float z26.s, z20.s, z21.s, p7\n"
+        "clamp_float z27.s, z20.s, z21.s, p7\n"
+        "store_data_pred_index_counter_2 z16.s, z24.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "subs x20, x20, #0x1\n"
+        "add x26, x26, x24\n"
+        "beq 25f\n"
+        "store_data_pred_index_counter_2 z17.s, z25.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "subs x20, x20, #0x1\n"
+        "add x26, x26, x24\n"
+        "beq 25f\n"
+        "store_data_pred_index_counter_2 z18.s, z26.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "25:"  // Store to output array: Accumulator row 0 oddments: End
+        "subs x25, x25, x22\n"
+        "beq 29f\n"
+        "cmp x25, x23\n"
+        "mov x12, #0x0\n"
+        "csel x20, x25, x23, LT\n"
+        "lsr x21, x20, #0x2\n"
+        "and x20, x20, #0x3\n"
+        "cbz x21, 27f\n"
+        "26:"  // Store to output array: Accumulator row 1 loop
+        "move_tile_vector za2h.s, z0.s, z1.s, z2.s, z3.s, p7, w12\n"
+        "move_tile_vector za3h.s, z8.s, z9.s, z10.s, z11.s, p7, w12\n"
+        "clamp_float z0.s, z20.s, z21.s, p7\n"
+        "clamp_float z1.s, z20.s, z21.s, p7\n"
+        "clamp_float z2.s, z20.s, z21.s, p7\n"
+        "clamp_float z3.s, z20.s, z21.s, p7\n"
+        "clamp_float z8.s, z20.s, z21.s, p7\n"
+        "clamp_float z9.s, z20.s, z21.s, p7\n"
+        "clamp_float z10.s, z20.s, z21.s, p7\n"
+        "clamp_float z11.s, z20.s, z21.s, p7\n"
+        "add x12, x12, #0x4\n"
+        "store_data_pred_index_counter_2 z0.s, z8.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "store_data_pred_index_counter_2 z1.s, z9.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "store_data_pred_index_counter_2 z2.s, z10.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "store_data_pred_index_counter_2 z3.s, z11.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "add x26, x26, x24\n"
+        "cmp x12, x21, LSL #2\n"
+        "blt 26b\n"
+        "27:"  // Store to output array: Accumulator row 1 oddments
+        "cbz x20, 28f\n"
+        "move_tile_vector za2h.s, z16.s, z17.s, z18.s, z19.s, p7, w12\n"
+        "move_tile_vector za3h.s, z24.s, z25.s, z26.s, z27.s, p7, w12\n"
+        "clamp_float z16.s, z20.s, z21.s, p7\n"
+        "clamp_float z17.s, z20.s, z21.s, p7\n"
+        "clamp_float z18.s, z20.s, z21.s, p7\n"
+        "clamp_float z19.s, z20.s, z21.s, p7\n"
+        "clamp_float z24.s, z20.s, z21.s, p7\n"
+        "clamp_float z25.s, z20.s, z21.s, p7\n"
+        "clamp_float z26.s, z20.s, z21.s, p7\n"
+        "clamp_float z27.s, z20.s, z21.s, p7\n"
+        "store_data_pred_index_counter_2 z16.s, z24.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "subs x20, x20, #0x1\n"
+        "add x26, x26, x24\n"
+        "beq 28f\n"
+        "store_data_pred_index_counter_2 z17.s, z25.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "subs x20, x20, #0x1\n"
+        "add x26, x26, x24\n"
+        "beq 28f\n"
+        "store_data_pred_index_counter_2 z18.s, z26.s, p4, p4.s, x11, x10, x26, x8 \n"
+        "28:"  // Store to output array: Accumulator row 1 oddments: End
+        "29:"  // Store to output array: End
+        "tbz x17, #0, 31f\n"
+        "mov x12, #0x0\n"
+        "cntw x20\n"
+        "30:"  // Store to output array: Refill accumulators: Loop
+        "load_data z8.s, z9.s, z10.s, z11.s, p7, x16\n"
+        "load_data z0.s, z1.s, z2.s, z3.s, p7, x16\n"
+        "load_data z4.s, z5.s, z6.s, z7.s, p7, x16\n"
+        "load_data z12.s, z13.s, z14.s, z15.s, p7, x16\n"
+        "move_vector_tile za0h.s, z8.s, z9.s, z10.s, z11.s, p7, w12\n"
+        "move_vector_tile za1h.s, z0.s, z1.s, z2.s, z3.s, p7, w12\n"
+        "move_vector_tile za2h.s, z4.s, z5.s, z6.s, z7.s, p7, w12\n"
+        "move_vector_tile za3h.s, z12.s, z13.s, z14.s, z15.s, p7, w12\n"
+        "add x12, x12, #0x4\n"
+        "cmp x12, x20\n"
+        "blt 30b\n"
+        "31:"  // End block
+        "incw x11, ALL, MUL #2\n"
+        "cmp x11, x10\n"
+        "blt 4b\n"
+        "incw x13, ALL, MUL #2\n"
+        "mov x11, #0x0\n"
+        "cmp x13, x14\n"
+        "mov x9, x27\n"
+        "blt 3b\n"
+        "SMSTOP\n"
+        :
+        : [args] "r"(&args), [offsetof_A] "I"(offsetof(KernelArgs, A)), [offsetof_B] "I"(offsetof(KernelArgs, B)),
+          [offsetof_C] "I"(offsetof(KernelArgs, C)), [offsetof_K] "I"(offsetof(KernelArgs, K)),
+          [offsetof_KernelArgs_max] "I"(offsetof(KernelArgs, max)),
+          [offsetof_KernelArgs_min] "I"(offsetof(KernelArgs, min)), [offsetof_M] "I"(offsetof(KernelArgs, M)),
+          [offsetof_N] "I"(offsetof(KernelArgs, N)),
+          [offsetof_accumulator_buffer] "I"(offsetof(KernelArgs, accumulator_buffer)),
+          [offsetof_flags] "I"(offsetof(KernelArgs, flags)), [offsetof_ldcb] "I"(offsetof(KernelArgs, ldcb))
+        : "cc", "memory", "p0", "p1", "p2", "p3", "p4", "p5", "p6", "p7", "p8", "p9", "p10", "p11", "p12", "p13", "p14",
+          "p15","x8", "x9", "x10", "x11", "x12", "x13", "x14", "x15", "x16", "x17", "x20", "x21", "x22", "x23", "x24", "x25",
+          "x26", "x27", "x28", "z0", "z1", "z2", "z3", "z4", "z5", "z6", "z7", "z8", "z9", "z10", "z11", "z12", "z13",
+          "z14", "z15", "z16", "z17", "z18", "z19", "z20", "z21", "z22", "z23", "z24", "z25", "z26", "z27", "z28",
+          "z29", "z30", "z31");
+}
+
+#endif  // Architectural features check.
diff --git a/kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/kai_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.h b/kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/kai_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.h
new file mode 100644
index 0000000..e805df2
--- /dev/null
+++ b/kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/kai_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.h
@@ -0,0 +1,121 @@
+//
+// SPDX-FileCopyrightText: Copyright 2024 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+#pragma once
+
+#include <stddef.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif  // __cplusplus
+
+/// Micro-kernel dependencies
+///
+/// -# kai_lhs_pack_f32p2vlx1_f32_sme to pack the LHS matrix.
+/// -# kai_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme to pack the RHS matrix.
+
+/// Gets m step value.
+///
+/// The starting row index must be divisible by `m_step`.
+///
+/// @return The m step value.
+size_t kai_get_m_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void);
+
+/// Gets n step value.
+///
+/// The starting column index must be divisible by `n_step`.
+///
+/// @return The n step value.
+size_t kai_get_n_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void);
+
+/// Gets mr value.
+///
+/// This is the packing parameter which must be used to pack the LHS matrix.
+///
+/// @return The mr value.
+size_t kai_get_mr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void);
+
+/// Gets nr value.
+///
+/// This is the packing parameter which must be used to pack the RHS matrix.
+///
+/// @return The nr value.
+size_t kai_get_nr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void);
+
+/// Gets kr value.
+///
+/// This is the packing parameter which must be used to pack the LHS and RHS matrix.
+///
+/// @return The kr value.
+size_t kai_get_kr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void);
+
+/// Gets sr value.
+///
+/// This is the packing parameter which must be used to pack the LHS and RHS matrix.
+///
+/// @return The sr value.
+size_t kai_get_sr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(void);
+
+/// Gets the offset in bytes to the data element in the packed LHS matrix buffer.
+///
+/// @param[in] m_idx Row index in the unpacked LHS matrix.
+/// @param[in] k Number of columns in the unpacked LHS matrix.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_lhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(size_t m_idx, size_t k);
+
+/// Gets the offset in bytes to the data element in the packed RHS matrix buffer.
+///
+/// @param[in] n_idx Column index in the unpacked RHS matrix.
+/// @param[in] k Number of rows in the unpacked RHS matrix.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_rhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(size_t n_idx, size_t k);
+
+/// Gets the offset in bytes to the data element in the destination matrix buffer.
+///
+/// @param[in] m_idx Row index.
+/// @param[in] n_idx Column index.
+/// @param[in] stride Row stride in bytes.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_dst_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_stride);
+
+/// Gets the size in bytes of the destination matrix buffer.
+///
+/// @param[in] m Number of rows.
+/// @param[in] n Number of columns.
+///
+/// @return The size in bytes of the destination matrix buffer.
+size_t kai_get_dst_size_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(size_t m, size_t n);
+
+/// Runs the matrix multiplication microkernel followed by a clamp operation.
+///
+/// The pointer of each buffers (packed LHS, packed RHS and output) needs to be added with offset
+/// calculated using the following functions:
+///
+///   * Packed LHS: @ref kai_get_lhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.
+///   * Packed RHS: @ref kai_get_rhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.
+///   * Output: @ref kai_get_dst_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.
+///
+/// @param[in] m Number of output rows to be computed.
+/// @param[in] n Number of output columns to be computed.
+/// @param[in] k Common dimension of the LHS and RHS operands.
+/// @param[in] packed_lhs Packed LHS matrix buffer.
+/// @param[in] packed_rhs Packed RHS matrix buffer.
+/// @param[out] dst Output matrix buffer.
+/// @param[in] dst_stride_row Row stride in bytes of the output matrix.
+/// @param[in] dst_stride_col Column stride in bytes of the output matrix.
+/// @param[in] clamp_min Minimum value to clamp the final result.
+/// @param[in] clamp_max Maximum value to clamp the final result.
+void kai_run_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa(
+    size_t m, size_t n, size_t k, const void* lhs_packed, const void* rhs_packed, void* dst, size_t dst_stride_row,
+    size_t dst_stride_col, float clamp_min, float clamp_max);
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif  // __cplusplus
diff --git a/kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/helper_macros_matmul_clamp_qai8_qai8p_qsi8cxp.S b/kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/helper_macros_matmul_clamp_qai8_qai8p_qsi8cxp.S
new file mode 100644
index 0000000..691a754
--- /dev/null
+++ b/kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/helper_macros_matmul_clamp_qai8_qai8p_qsi8cxp.S
@@ -0,0 +1,75 @@
+
+.macro frintn_convert, reg1, reg2, reg3, reg4, pred
+frintn \reg1, \pred/M, \reg1
+frintn \reg2, \pred/M, \reg2
+frintn \reg3, \pred/M, \reg3
+frintn \reg4, \pred/M, \reg4
+.endm
+
+.macro fcvtzs_convert, reg1, reg2, reg3, reg4, pred
+fcvtzs \reg1, \pred/M, \reg1
+fcvtzs \reg2, \pred/M, \reg2
+fcvtzs \reg3, \pred/M, \reg3
+fcvtzs \reg4, \pred/M, \reg4
+.endm
+
+.macro add____convert, reg1, reg2, reg3, reg4, reg5
+add \reg1, \reg1, \reg5
+add \reg2, \reg2, \reg5
+add \reg3, \reg3, \reg5
+add \reg4, \reg4, \reg5
+.endm
+ 
+.macro sclamp_convert2, reg1, reg2, reg3, reg4, min_val, max_val, pred
+SMIN \reg1, \pred/M, \reg1, \min_val
+SMIN \reg2, \pred/M, \reg2, \min_val
+SMIN \reg3, \pred/M, \reg3, \min_val
+SMIN \reg4, \pred/M, \reg4, \min_val
+SMAX \reg1, \pred/M, \reg1, \max_val
+SMAX \reg2, \pred/M, \reg2, \max_val
+SMAX \reg3, \pred/M, \reg3, \max_val
+SMAX \reg4, \pred/M, \reg4, \max_val
+.endm
+
+
+
+
+.macro sclamp_convert, reg1, reg2, reg3, reg4, min_val, max_val, pred
+SCLAMP \reg1,  \min_val, \max_val
+SCLAMP \reg2,  \min_val, \max_val
+SCLAMP \reg3,  \min_val, \max_val
+SCLAMP \reg4,  \min_val, \max_val
+.endm
+
+
+.macro scvtf_convert, reg1, reg2, reg3, reg4, pred
+scvtf \reg1, \pred/M, \reg1
+scvtf \reg2, \pred/M, \reg2
+scvtf \reg3, \pred/M, \reg3
+scvtf \reg4, \pred/M, \reg4
+.endm
+
+.macro move_tile_vector, tile, reg1, reg2, reg3, reg4, pred, addr
+mova \reg1, \pred/M,  \tile[\addr, 0]
+mova \reg2, \pred/M,  \tile[\addr, 1]
+mova \reg3, \pred/M,  \tile[\addr, 2]
+mova \reg4, \pred/M,  \tile[\addr, 3]
+.endm
+
+.macro load_data_2, reg1, reg2, pred, addr
+ld1b \reg1, \pred/Z, [\addr]
+ld1b \reg2, \pred/Z, [\addr, #1, MUL VL]
+addvl \addr, \addr, #2
+.endm
+
+.macro load_data_pred_index_counter_2, reg1, reg2, predr, predtype, start_idx, end_idx, addr, word_length
+cntw \word_length
+whilelt \predtype, \start_idx, \end_idx
+ld1w \reg1, \predr/Z, [\addr]
+add \start_idx, \start_idx, \word_length
+whilelt \predtype, \start_idx, \end_idx
+ld1w \reg2, \predr/Z, [\addr, #1, MUL VL]
+neg \word_length, \word_length
+add \start_idx, \start_idx, \word_length
+neg \word_length, \word_length
+.endm
diff --git a/kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/kai_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.c b/kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/kai_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.c
new file mode 100644
index 0000000..c6c2cb6
--- /dev/null
+++ b/kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/kai_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.c
@@ -0,0 +1,397 @@
+//
+// SPDX-FileCopyrightText: Copyright 2024-2025 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+// Do not flag up inline assembly blocks
+#pragma GCC diagnostic ignored "-Woverlength-strings"
+
+#if !defined(__aarch64__) || !defined(__ARM_FEATURE_SVE2)
+#error This file must be compiled for AArch64, FEAT_SVE2.
+#else  // Architectural features check.
+
+#include "kai_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.h"
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include "kai/kai_common.h"
+__asm__(".include \"helper_macros_matmul_clamp_qai8_qai8p_qsi8cxp.S\"");
+
+static const size_t kai_mr = 2;
+static const size_t kai_nr = 2;
+static const size_t kai_kr = 4;
+static const size_t kai_sr = 1;
+
+size_t kai_get_m_step_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void) {
+    return kai_mr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_n_step_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void) {
+    return kai_nr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_mr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void) {
+    return kai_mr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_nr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void) {
+    return kai_nr * kai_get_sme_vector_length_u32();
+}
+
+size_t kai_get_kr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void) {
+    return kai_kr;
+}
+
+size_t kai_get_sr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void) {
+    return kai_sr;
+}
+
+size_t kai_get_lhs_packed_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(size_t m_idx, size_t k) {
+    KAI_ASSUME(m_idx % kai_get_m_step_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa() == 0);
+    return m_idx * kai_roundup(k, kai_kr) * sizeof(int8_t);
+}
+
+size_t kai_get_rhs_packed_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(size_t n_idx, size_t k) {
+    KAI_ASSUME(n_idx % kai_get_n_step_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa() == 0);
+    return n_idx * (sizeof(int32_t) + kai_roundup(k, kai_kr) * sizeof(int8_t) + sizeof(float));
+}
+
+size_t kai_get_dst_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_stride) {
+    KAI_ASSUME(m_idx % kai_get_m_step_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa() == 0);
+    KAI_ASSUME(n_idx % kai_get_n_step_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa() == 0);
+
+    return m_idx * dst_stride + n_idx * sizeof(int8_t);
+}
+
+size_t kai_get_dst_size_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(size_t m, size_t n) {
+    return m * n * sizeof(int8_t);
+}
+
+void kai_run_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t m, size_t n, size_t k, const void* lhs_packed, const void* rhs_packed, void* dst, size_t dst_stride_row,
+    size_t dst_stride_col, const struct kai_matmul_requantize32_params* params) {
+    KAI_ASSUME(dst_stride_col == sizeof(int8_t));
+
+    typedef struct {
+        const void* A;
+        const void* B;
+
+        void* C;
+        uint64_t ldcb;
+        uint64_t M, N, K;
+        int32_t min;
+        int32_t max;
+        int32_t result_zero_point;
+
+        void* accumulator_buffer;
+        uint64_t flags;
+    } KernelArgs;
+
+    KernelArgs args;
+
+    args.A = lhs_packed;
+    args.B = rhs_packed;
+
+    args.C = dst;
+    args.ldcb = dst_stride_row;
+    args.M = m;
+    args.N = n;
+    args.K = k;
+    args.min = params->min_value;
+    args.max = params->max_value;
+    args.result_zero_point = params->output_zero_point;
+
+    args.accumulator_buffer = NULL;
+    args.flags = 0;
+
+    __asm__ __volatile__(
+        "SMSTART \n"
+        "ldr w14, [%x[args], %[offsetof_M]] \n"
+        "mov x13, #0x0\n"
+        "mov x11, #0x0\n"
+        "ptrue p1.b\n"
+        "ptrue p7.b\n"
+        "ldr w10, [%x[args], %[offsetof_N]]\n"
+        "ldr x9, [%x[args], %[offsetof_A]]\n"
+        "1:"  // M loop
+        "ldr x28, [%x[args], %[offsetof_B]]\n"
+        "2:"  // N loop
+        " whilelt p4.s, x11, x10 \n"
+        "zero { za }\n"
+        "mov x27, x9\n"
+        "load_data_pred_index_counter_2  z14.s, z15.s, p4, p4.s, x11, x10, x28, x15 \n"  // Load bias
+        "addvl x28, x28, #2\n"
+        "addha za0.s, p1/M, p1/M, z14.s\n"
+        "addha za1.s, p1/M, p1/M, z15.s\n"
+        "addha za2.s, p1/M, p1/M, z14.s\n"
+        "addha za3.s, p1/M, p1/M, z15.s\n"
+        "ldr x20, [%x[args], %[offsetof_K]]\n"
+        "add x20, x20, #0x3\n"
+        "lsr x20, x20, #0x2\n"
+        "lsr x21, x20, #0x2\n"
+        "and x20, x20, #0x3\n"
+        "cbz x21, 6f\n"
+        "subs x21, x21, #0x1\n"
+        "load_data_2   z2.b  , z3.b   , p7,  x27 \n"
+        "load_data_2   z0.b  , z8.b   , p7,  x28 \n"
+        "load_data_2   z18.b , z19.b  , p7,  x27 \n"
+        "load_data_2   z20.b , z21.b  , p7,  x28 \n"
+        "load_data_2   z26.b , z27.b  , p7,  x27 \n"
+        "load_data_2   z22.b , z23.b  , p7,  x28 \n"
+        "load_data_2   z24.b , z25.b  , p7,  x27 \n"
+        "load_data_2   z4.b  , z5.b   , p7,  x28 \n"
+        "ble 5f\n"
+        "4:"  // K loop
+        " smopa za0.s, p1/M, p1/M, z2.b, z0.b\n"
+        "subs x21, x21, #0x1\n"
+        " smopa za1.s, p1/M, p1/M, z2.b, z8.b\n"
+        " smopa za2.s, p1/M, p1/M, z3.b, z0.b\n"
+        " smopa za3.s, p1/M, p1/M, z3.b, z8.b\n"
+        " load_data_2  z2.b, z3.b , p7, x27  \n"
+        " smopa za0.s, p1/M, p1/M, z18.b, z20.b\n"
+        " load_data_2  z0.b, z8.b , p7, x28  \n"
+        " smopa za1.s, p1/M, p1/M, z18.b, z21.b\n"
+        " smopa za2.s, p1/M, p1/M, z19.b, z20.b\n"
+        " smopa za3.s, p1/M, p1/M, z19.b, z21.b\n"
+        " load_data_2  z18.b, z19.b , p7, x27   \n"
+        " smopa za0.s, p1/M, p1/M, z26.b, z22.b\n"
+        " load_data_2  z20.b, z21.b , p7, x28  \n"
+        " smopa za1.s, p1/M, p1/M, z26.b, z23.b\n"
+        " smopa za2.s, p1/M, p1/M, z27.b, z22.b\n"
+        " smopa za3.s, p1/M, p1/M, z27.b, z23.b\n"
+        " load_data_2  z26.b, z27.b , p7, x27  \n"
+        " load_data_2  z22.b, z23.b , p7, x28  \n"
+        " smopa za0.s, p1/M, p1/M, z24.b, z4.b\n"
+        " smopa za1.s, p1/M, p1/M, z24.b, z5.b\n"
+        " smopa za2.s, p1/M, p1/M, z25.b, z4.b\n"
+        " smopa za3.s, p1/M, p1/M, z25.b, z5.b\n"
+        " load_data_2  z24.b, z25.b , p7, x27 \n"
+        " load_data_2  z4.b, z5.b  , p7, x28  \n"
+        "bgt 4b\n"
+        "5:"  // K loop tail
+        " smopa za0.s, p1/M, p1/M, z2.b, z0.b\n"
+        " smopa za1.s, p1/M, p1/M, z2.b, z8.b\n"
+        " smopa za2.s, p1/M, p1/M, z3.b, z0.b\n"
+        " smopa za3.s, p1/M, p1/M, z3.b, z8.b\n"
+        " smopa za0.s, p1/M, p1/M, z18.b, z20.b\n"
+        " smopa za1.s, p1/M, p1/M, z18.b, z21.b\n"
+        " smopa za2.s, p1/M, p1/M, z19.b, z20.b\n"
+        " smopa za3.s, p1/M, p1/M, z19.b, z21.b\n"
+        " smopa za0.s, p1/M, p1/M, z26.b, z22.b\n"
+        " smopa za1.s, p1/M, p1/M, z26.b, z23.b\n"
+        " smopa za2.s, p1/M, p1/M, z27.b, z22.b\n"
+        " smopa za3.s, p1/M, p1/M, z27.b, z23.b\n"
+        " smopa za0.s, p1/M, p1/M, z24.b, z4.b\n"
+        " smopa za1.s, p1/M, p1/M, z24.b, z5.b\n"
+        " smopa za2.s, p1/M, p1/M, z25.b, z4.b\n"
+        " smopa za3.s, p1/M, p1/M, z25.b, z5.b\n"
+        "6:"  // K oddments
+        "cbz x20, 8f\n"
+        "7:"  // K oddments: Loop
+        "load_data_2  z16.b, z17.b , p7, x27 \n"
+        "subs x20, x20, #0x1\n"
+        "load_data_2  z8.b, z9.b   , p7, x28  \n"
+        "smopa za0.s, p1/M, p1/M, z16.b, z8.b\n"
+        "smopa za1.s, p1/M, p1/M, z16.b, z9.b\n"
+        "smopa za2.s, p1/M, p1/M, z17.b, z8.b\n"
+        "smopa za3.s, p1/M, p1/M, z17.b, z9.b\n"
+        "bgt 7b\n"
+        "8:"  // K oddments: End
+        "ldr x26, [%x[args], %[offsetof_C]]\n"
+        "sub x25, x14, x13\n"
+        "cntw x24\n"
+        "ld1rw { z27.s }, p1/Z, [%x[args], %[offsetof_KernelArgs_min]]\n"
+        "ldr x23, [%x[args], %[offsetof_ldcb]]\n"
+        "whilelt p0.h, x11, x10\n"
+        "cmp x25, x24\n"
+        "ld1rw { z1.s }, p1/Z, [%x[args], %[offsetof_KernelArgs_max]]\n"
+        "csel x22, x25, x24, LT\n"
+        "ld1rw { z0.s }, p1/Z, [%x[args], %[offsetof_KernelArgs_result_zero_point]]\n"
+        "mov x12, #0x0\n"
+        "add x26, x26, x11\n"  // C += n
+        "lsr x21, x22, #0x2\n"
+        "ld1w { z22.s }, p1/Z, [x28]\n"
+        "madd x26, x13, x23, x26\n"  // C += m * ldc
+        "ld1w { z26.s }, p1/Z, [x28, #1, MUL VL]\n"
+        "and x20, x22, #0x3\n"
+        "addvl x28, x28, #2\n"
+        "cbz x21, 11f\n"
+        "10:"  // Store to output array: Accumulator row 0 loop
+        "move_tile_vector za0h.s, z16.s, z17.s, z18.s, z19.s, p7, w12 \n"
+        "move_tile_vector za1h.s, z28.s, z29.s, z30.s, z31.s, p7, w12 \n"
+        "scvtf_convert  z16.s, z17.s, z18.s, z19.s, p7 \n"
+        "scvtf_convert  z28.s, z29.s, z30.s, z31.s, p7 \n"
+        "fmul z16.s, z16.s, z22.s\n"
+        "fmul z17.s, z17.s, z22.s\n"
+        "add x12, x12, #0x4\n"
+        "fmul z18.s, z18.s, z22.s\n"
+        "fmul z19.s, z19.s, z22.s\n"
+        "cmp x12, x21, LSL #2\n"
+        "fmul z28.s, z28.s, z26.s\n"
+        "fmul z29.s, z29.s, z26.s\n"
+        "fmul z30.s, z30.s, z26.s\n"
+        "fmul z31.s, z31.s, z26.s\n"
+        "frintn_convert z16.s, z17.s, z18.s, z19.s, p7  \n"
+        "fcvtzs_convert z16.s, z17.s, z18.s, z19.s, p7  \n"
+        "add____convert z16.s, z17.s, z18.s, z19.s , z0.s \n"
+        "sclamp_convert z16.s, z17.s, z18.s, z19.s , z27.s, z1.s, p7 \n"
+        "frintn_convert z28.s, z29.s, z30.s, z31.s, p7  \n"
+        "fcvtzs_convert z28.s, z29.s, z30.s, z31.s, p7  \n"
+        "add____convert z28.s, z29.s, z30.s, z31.s,  z0.s \n"
+        "sclamp_convert z28.s, z29.s, z30.s, z31.s, z27.s, z1.s, p7 \n"
+        "uzp1 z5.h, z16.h, z28.h\n"
+        "uzp1 z20.h, z17.h, z29.h\n"
+        "uzp1 z17.h, z18.h, z30.h\n"
+        "uzp1 z16.h, z19.h, z31.h\n"
+        "st1b { z5.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z20.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z17.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "blt 10b\n"
+        "11:"  // Store to output array: Accumulator row 0 oddments
+        "cbz x20, 12f\n"
+        "move_tile_vector za0h.s, z4.s, z5.s, z6.s, z7.s, p7, w12 \n"
+        "move_tile_vector za1h.s, z12.s, z13.s, z14.s, z15.s, p7, w12 \n"
+        "scvtf_convert  z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "scvtf_convert  z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "fmul z4.s, z4.s, z22.s\n"
+        "fmul z5.s, z5.s, z22.s\n"
+        "subs x20, x20, #0x1\n"
+        "fmul z6.s, z6.s, z22.s\n"
+        "fmul z7.s, z7.s, z22.s\n"
+        "fmul z12.s, z12.s, z26.s\n"
+        "fmul z13.s, z13.s, z26.s\n"
+        "fmul z14.s, z14.s, z26.s\n"
+        "fmul z15.s, z15.s, z26.s\n"
+        "frintn_convert z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "fcvtzs_convert z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "add____convert z4.s, z5.s, z6.s, z7.s , z0.s \n"
+        "sclamp_convert z4.s, z5.s, z6.s, z7.s , z27.s, z1.s, p7 \n"
+        "frintn_convert z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "fcvtzs_convert z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "add____convert z12.s, z13.s, z14.s, z15.s,  z0.s \n"
+        "sclamp_convert z12.s, z13.s, z14.s, z15.s, z27.s, z1.s, p7 \n"
+        "uzp1 z16.h, z4.h, z12.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "beq 12f\n"
+        "subs x20, x20, #0x1\n"
+        "uzp1 z16.h, z5.h, z13.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "beq 12f\n"
+        "uzp1 z16.h, z6.h, z14.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "12:"  // Store to output array: Accumulator row 0 oddments: End
+        "subs x25, x25, x22\n"
+        "beq 16f\n"
+        "cmp x25, x24\n"
+        "mov x12, #0x0\n"
+        "csel x20, x25, x24, LT\n"
+        "lsr x21, x20, #0x2\n"
+        "and x20, x20, #0x3\n"
+        "cbz x21, 14f\n"
+        "13:"  // Store to output array: Accumulator row 1 loop
+        "move_tile_vector za2h.s, z8.s, z9.s, z10.s, z11.s, p7, w12\n"
+        "move_tile_vector za3h.s, z16.s, z17.s, z18.s, z19.s, p7, w12\n"
+        "scvtf_convert  z8.s, z9.s, z10.s, z11.s, p7  \n"
+        "scvtf_convert  z16.s, z17.s, z18.s, z19.s, p7   \n"
+        "fmul z8.s, z8.s, z22.s\n"
+        "fmul z9.s, z9.s, z22.s\n"
+        "add x12, x12, #0x4\n"
+        "fmul z10.s, z10.s, z22.s\n"
+        "fmul z11.s, z11.s, z22.s\n"
+        "cmp x12, x21, LSL #2\n"
+        "fmul z16.s, z16.s, z26.s\n"
+        "fmul z17.s, z17.s, z26.s\n"
+        "fmul z18.s, z18.s, z26.s\n"
+        "fmul z19.s, z19.s, z26.s\n"
+        "frintn_convert z8.s, z9.s, z10.s, z11.s, p7   \n"
+        "fcvtzs_convert z8.s, z9.s, z10.s, z11.s, p7   \n"
+        "add____convert z8.s, z9.s, z10.s, z11.s , z0.s \n"
+        "sclamp_convert z8.s, z9.s, z10.s, z11.s , z27.s, z1.s, p7 \n"
+        "frintn_convert z16.s, z17.s, z18.s, z19.s, p7   \n"
+        "fcvtzs_convert z16.s, z17.s, z18.s, z19.s, p7   \n"
+        "add____convert z16.s, z17.s, z18.s, z19.s,  z0.s \n"
+        "sclamp_convert z16.s, z17.s, z18.s, z19.s, z27.s, z1.s, p7 \n"
+        "uzp1 z21.h, z8.h, z16.h\n"
+        "uzp1 z20.h, z9.h, z17.h\n"
+        "uzp1 z17.h, z10.h, z18.h\n"
+        "uzp1 z16.h, z11.h, z19.h\n"
+        "st1b { z21.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z20.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z17.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "blt 13b\n"
+        "14:"  // Store to output array: Accumulator row 1 oddments
+        "cbz x20, 15f\n"
+        "move_tile_vector za2h.s, z12.s, z13.s, z14.s, z15.s, p7, w12 \n"
+        "move_tile_vector za3h.s, z4.s, z5.s, z6.s, z7.s, p7, w12 \n"
+        "scvtf_convert  z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "scvtf_convert  z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "fmul z12.s, z12.s, z22.s\n"
+        "fmul z13.s, z13.s, z22.s\n"
+        "subs x20, x20, #0x1\n"
+        "fmul z14.s, z14.s, z22.s\n"
+        "fmul z15.s, z15.s, z22.s\n"
+        "fmul z4.s, z4.s, z26.s\n"
+        "fmul z5.s, z5.s, z26.s\n"
+        "fmul z6.s, z6.s, z26.s\n"
+        "fmul z7.s, z7.s, z26.s\n"
+        "frintn_convert z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "fcvtzs_convert z12.s, z13.s, z14.s, z15.s, p7   \n"
+        "add____convert z12.s, z13.s, z14.s, z15.s , z0.s \n"
+        "sclamp_convert z12.s, z13.s, z14.s, z15.s , z27.s, z1.s, p7 \n"
+        "frintn_convert z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "fcvtzs_convert z4.s, z5.s, z6.s, z7.s, p7   \n"
+        "add____convert z4.s, z5.s, z6.s, z7.s,  z0.s \n"
+        "sclamp_convert z4.s, z5.s, z6.s, z7.s, z27.s, z1.s, p7 \n"
+        "uzp1 z16.h, z12.h, z4.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "beq 15f\n"
+        "subs x20, x20, #0x1\n"
+        "uzp1 z16.h, z13.h, z5.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "add x26, x26, x23\n"
+        "beq 15f\n"
+        "uzp1 z16.h, z14.h, z6.h\n"
+        "st1b { z16.h }, p0, [x26]\n"
+        "15:"  // Store to output array: Accumulator row 1 oddments: End
+        "16:"  // Store to output array: End
+        "incw x11, ALL, MUL #2\n"
+        "cmp x11, x10\n"
+        "blt 2b\n"
+        "incw x13, ALL, MUL #2\n"
+        "mov x11, #0x0\n"
+        "cmp x13, x14\n"
+        "mov x9, x27\n"
+        "blt 1b\n"
+        "SMSTOP\n"
+        :
+        : [args] "r"(&args), [offsetof_A] "I"(offsetof(KernelArgs, A)), [offsetof_B] "I"(offsetof(KernelArgs, B)),
+          [offsetof_C] "I"(offsetof(KernelArgs, C)), [offsetof_K] "I"(offsetof(KernelArgs, K)),
+          [offsetof_KernelArgs_max] "I"(offsetof(KernelArgs, max)),
+          [offsetof_KernelArgs_min] "I"(offsetof(KernelArgs, min)),
+          [offsetof_KernelArgs_result_zero_point] "I"(offsetof(KernelArgs, result_zero_point)),
+          [offsetof_M] "I"(offsetof(KernelArgs, M)), [offsetof_N] "I"(offsetof(KernelArgs, N)),
+          [offsetof_ldcb] "I"(offsetof(KernelArgs, ldcb))
+        : "cc", "memory", "p0", "p1", "p2", "p3", "p4", "p5", "p6", "p7", "p8", "p9", "p10", "p11", "p12", "p13", "p14",
+          "p15", "x9", "x10", "x11", "x12", "x13", "x14", "x15", "x20", "x21", "x22", "x23", "x24", "x25", "x26", "x27", "x28",
+          "z0", "z1", "z2", "z3", "z4", "z5", "z6", "z7", "z8", "z9", "z10", "z11", "z12", "z13", "z14", "z15", "z16",
+          "z17", "z18", "z19", "z20", "z21", "z22", "z23", "z24", "z25", "z26", "z27", "z28", "z29", "z30", "z31");
+}
+
+#endif  // Architectural features check.
diff --git a/kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/kai_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.h b/kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/kai_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.h
new file mode 100644
index 0000000..d2f6387
--- /dev/null
+++ b/kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/kai_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.h
@@ -0,0 +1,122 @@
+//
+// SPDX-FileCopyrightText: Copyright 2024 Arm Limited and/or its affiliates <open-source-office@arm.com>
+//
+// SPDX-License-Identifier: Apache-2.0
+//
+
+#pragma once
+
+#include <stddef.h>
+
+#include "kai/kai_common.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif  // __cplusplus
+
+/// Micro-kernel dependencies
+///
+/// -# kai_lhs_pack_x8p2vlx4_x8_sme to pack the LHS matrix.
+/// -# kai_rhs_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme to pack the RHS matrix.
+
+/// Gets m step value.
+///
+/// The starting row index must be divisible by `m_step`.
+///
+/// @return The m step value.
+size_t kai_get_m_step_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void);
+
+/// Gets n step value.
+///
+/// The starting column index must be divisible by `n_step`.
+///
+/// @return The n step value.
+size_t kai_get_n_step_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void);
+
+/// Gets mr value.
+///
+/// This is the packing parameter which must be used to pack the LHS matrix.
+///
+/// @return The mr value.
+size_t kai_get_mr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void);
+
+/// Gets nr value.
+///
+/// This is the packing parameter which must be used to pack the RHS matrix.
+///
+/// @return The nr value.
+size_t kai_get_nr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void);
+
+/// Gets kr value.
+///
+/// This is the packing parameter which must be used to pack the LHS and RHS matrix.
+///
+/// @return The kr value.
+size_t kai_get_kr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void);
+
+/// Gets sr value.
+///
+/// This is the packing parameter which must be used to pack the LHS and RHS matrix.
+///
+/// @return The sr value.
+size_t kai_get_sr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(void);
+
+/// Gets the offset in bytes to the data element in the packed LHS matrix buffer.
+///
+/// @param[in] m_idx Row index in the unpacked LHS matrix.
+/// @param[in] k Number of columns in the unpacked LHS matrix.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_lhs_packed_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(size_t m_idx, size_t k);
+
+/// Gets the offset in bytes to the data element in the packed RHS matrix buffer.
+///
+/// @param[in] n_idx Column index in the unpacked RHS matrix.
+/// @param[in] k Number of rows in the unpacked RHS matrix.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_rhs_packed_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(size_t n_idx, size_t k);
+
+/// Gets the offset in bytes to the data element in the destination matrix buffer.
+///
+/// @param[in] m_idx Row index.
+/// @param[in] n_idx Column index.
+/// @param[in] dst_stride Row stride in bytes.
+///
+/// @return The offset in bytes to the data element.
+size_t kai_get_dst_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t m_idx, size_t n_idx, size_t dst_stride);
+
+/// Gets the size in bytes of the destination matrix buffer.
+///
+/// @param[in] m Number of rows.
+/// @param[in] n Number of columns.
+///
+/// @return The size in bytes of the destination matrix buffer.
+size_t kai_get_dst_size_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(size_t m, size_t n);
+
+/// Runs the matrix multiplication microkernel followed by a clamp operation.
+///
+/// The pointer of each buffers (packed LHS, packed RHS and output) needs to be added with offset
+/// calculated using the following functions:
+///
+///   * Packed LHS: @ref kai_get_lhs_packed_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.
+///   * Packed RHS: @ref kai_get_rhs_packed_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.
+///   * Output: @ref kai_get_dst_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.
+///
+/// @param[in] m Number of output rows to be computed.
+/// @param[in] n Number of output columns to be computed.
+/// @param[in] k Common dimension of the LHS and RHS operands.
+/// @param[in] packed_lhs Packed LHS matrix buffer.
+/// @param[in] packed_rhs Packed RHS matrix buffer.
+/// @param[out] dst Output matrix buffer.
+/// @param[in] dst_stride_row Row stride in bytes of the output matrix.
+/// @param[in] dst_stride_col Column stride in bytes of the output matrix.
+/// @param[in] params Requantization and clamp parmaters.
+void kai_run_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa(
+    size_t m, size_t n, size_t k, const void* lhs_packed, const void* rhs_packed, void* dst, size_t dst_stride_row,
+    size_t dst_stride_col, const struct kai_matmul_requantize32_params* params);
+
+#ifdef __cplusplus
+}  // extern "C"
+#endif  // __cplusplus
diff --git a/kai/ukernels/matmul/pack/kai_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme.c b/kai/ukernels/matmul/pack/kai_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme.c
index 8cd1201..77a45bc 100644
--- a/kai/ukernels/matmul/pack/kai_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme.c
+++ b/kai/ukernels/matmul/pack/kai_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme.c
@@ -73,7 +73,7 @@ void kai_run_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme(
     const void* scale, void* rhs_packed, const struct kai_rhs_pack_qsi8cx_params* params) {
     KAI_ASSUME(rhs != NULL);
     KAI_ASSUME(bias != NULL);
-    KAI_ASSUME(scale != NULL);
+    //KAI_ASSUME(scale != NULL);
     KAI_ASSUME(rhs_packed != NULL);
     KAI_ASSUME(params != NULL);
 
@@ -205,6 +205,7 @@ void kai_run_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme(
         "mov x22, %x[out]\n"
         "mov x21, %x[width]\n"
         "dup z18.s, %w[scale_multiplier]\n"
+#if 0
         "cbz %x[scale], 11f\n"
         "10:"  // Scale: Full loop
         "mov x20, x21\n"
@@ -221,8 +222,9 @@ void kai_run_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme(
         "st1w { z17.s }, p2, [x22]\n"
         "st1w { z16.s }, p2, [x22, #1, MUL VL]\n"
         "add x22, x22, %x[out_stride]\n"
-        "bgt 10b\n"
+        "bgt 10b\n"w
         "11:"  // Scale: Done
+#endif
         "cbz %x[width], 14f\n"
         "cbz %x[height], 14f\n"
         "dup z21.s, %w[input_zero_point]\n"
diff --git a/run.sh b/run.sh
new file mode 100755
index 0000000..609d8a4
--- /dev/null
+++ b/run.sh
@@ -0,0 +1,6 @@
+#rm -rf build/
+cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_TOOLCHAIN_FILE=cmake/toolchains/aarch64-none-linux-gnu.toolchain.cmake -DCMAKE_C_FLAGS=-march=armv8.5a+sve2+sme -S . -B build/
+cd build/
+make
+cd ..
+cp build/kleidiai_test ../../../qemu/emulboot/binaries/ 
diff --git a/test/tests/imatmul_test.cpp b/test/tests/imatmul_test.cpp
index dd12fd4..08e0f04 100644
--- a/test/tests/imatmul_test.cpp
+++ b/test/tests/imatmul_test.cpp
@@ -13,8 +13,10 @@
 #include <unordered_map>
 
 #include "kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/kai_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa.h"
+#include "kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/kai_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.h"
 #include "kai/ukernels/matmul/imatmul_clamp_f16_f16p_f16p/kai_imatmul_clamp_f16_f16p_f16p_interface.h"
 #include "kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/kai_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme2_mopa.h"
+#include "kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/kai_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa.h"
 #include "kai/ukernels/matmul/imatmul_clamp_f32_f32p_f32p/kai_imatmul_clamp_f32_f32p_f32p_interface.h"
 #include "kai/ukernels/matmul/pack/kai_lhs_imatmul_pack_x16p2vlx2_x16p_sme.h"
 #include "kai/ukernels/matmul/pack/kai_lhs_imatmul_pack_x32p2vlx1_x32p_sme.h"
@@ -146,6 +148,18 @@ const kai_imatmul_clamp_f16_f16p_f16p_ukernel& get_imatmul_clamp_f16_f16p2vlx2_f
     return ukernel;
 }
 
+const kai_imatmul_clamp_f16_f16p_f16p_ukernel& get_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa() {
+    static kai_imatmul_clamp_f16_f16p_f16p_ukernel ukernel;
+    ukernel.get_m_step = kai_get_m_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    ukernel.get_n_step = kai_get_n_step_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    ukernel.get_lhs_packed_offset = kai_get_lhs_packed_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    ukernel.get_rhs_packed_offset = kai_get_rhs_packed_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    ukernel.get_dst_offset = kai_get_dst_offset_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    ukernel.get_dst_size = kai_get_dst_size_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    ukernel.run_imatmul = kai_run_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    return ukernel;
+}
+
 /// Use interface for matmul kernel
 const kai_imatmul_clamp_f32_f32p_f32p_ukernel& get_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme2_mopa() {
     static kai_imatmul_clamp_f32_f32p_f32p_ukernel ukernel;
@@ -159,8 +173,24 @@ const kai_imatmul_clamp_f32_f32p_f32p_ukernel& get_imatmul_clamp_f32_f32p2vlx1_f
     return ukernel;
 }
 
+
+/// Use interface for matmul kernel
+const kai_imatmul_clamp_f32_f32p_f32p_ukernel& get_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa() {
+    static kai_imatmul_clamp_f32_f32p_f32p_ukernel ukernel;
+    ukernel.get_m_step = kai_get_m_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa;
+    ukernel.get_n_step = kai_get_n_step_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa;
+    ukernel.get_lhs_packed_offset = kai_get_lhs_packed_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa;
+    ukernel.get_rhs_packed_offset = kai_get_rhs_packed_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa;
+    ukernel.get_dst_offset = kai_get_dst_offset_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa;
+    ukernel.get_dst_size = kai_get_dst_size_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa;
+    ukernel.run_imatmul = kai_run_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa;
+    return ukernel;
+}
+
+
+
 /// Retreive the test list
-const IndirectMatMulArray& get_indirect_matmul_methods() {
+const IndirectMatMulArray& get_fp16_indirect_matmul_methods() {
     static IndirectMatMulArray indirect_matmul_methods{};
 
     // F16 IMATMUL ////////////////////////////////////////////////////////////
@@ -202,9 +232,105 @@ const IndirectMatMulArray& get_indirect_matmul_methods() {
     indirect_matmul_methods[0].imatmul.get_dst_size = ukernel_f16.get_dst_size;
     indirect_matmul_methods[0].imatmul.imatmul = ukernel_f16.run_imatmul;
 
+
+
+    // F16 IMATMUL ////////////////////////////////////////////////////////////
+    indirect_matmul_methods[1].name = "indirect_matmul_f16_f16p_f16p_2vlx2vl_sme1_mopa";
+    indirect_matmul_methods[1].is_supported = cpu_has_sme;
+    indirect_matmul_methods[1].pack_shape.m = 2 * get_sme_vector_length<int32_t>();
+    indirect_matmul_methods[1].pack_shape.n = 2 * get_sme_vector_length<int32_t>();
+    indirect_matmul_methods[1].pack_shape.k = sizeof(int32_t);
+    indirect_matmul_methods[1].format.lhs = DataFormat(DataType::FP16);
+    indirect_matmul_methods[1].format.rhs = DataFormat(DataType::FP16);
+    indirect_matmul_methods[1].format.bias = DataFormat(DataType::FP16);
+    indirect_matmul_methods[1].format.out = DataFormat(DataType::FP16);
+
+    // LHS
+    indirect_matmul_methods[1].lhs.get_m_step = kai_get_m_step_lhs_imatmul_pack_x16p2vlx2_x16p_sme;
+    indirect_matmul_methods[1].lhs.get_lhs_packed_offset =
+        kai_get_lhs_packed_offset_lhs_imatmul_pack_x16p2vlx2_x16p_sme;
+    indirect_matmul_methods[1].lhs.get_lhs_packed_size = kai_get_lhs_packed_size_lhs_imatmul_pack_x16p2vlx2_x16p_sme;
+    indirect_matmul_methods[1].lhs.pack = kai_run_lhs_imatmul_pack_x16p2vlx2_x16p_sme;
+
+    // RHS
+    indirect_matmul_methods[1].rhs.get_n_step = kai_get_n_step_rhs_imatmul_pack_kxn_x16p2vlx2b_x16_x16_sme;
+    indirect_matmul_methods[1].rhs.get_rhs_offset = kai_get_rhs_offset_rhs_imatmul_pack_kxn_x16p2vlx2b_x16_x16_sme;
+    indirect_matmul_methods[1].rhs.get_bias_offset = kai_get_bias_offset_rhs_imatmul_pack_kxn_x16p2vlx2b_x16_x16_sme;
+    indirect_matmul_methods[1].rhs.get_rhs_packed_offset =
+        kai_get_rhs_packed_offset_rhs_imatmul_pack_kxn_x16p2vlx2b_x16_x16_sme;
+    indirect_matmul_methods[1].rhs.get_rhs_packed_size =
+        kai_get_rhs_packed_size_rhs_imatmul_pack_kxn_x16p2vlx2b_x16_x16_sme;
+    indirect_matmul_methods[1].rhs.pack = kai_run_rhs_imatmul_pack_kxn_x16p2vlx2b_x16_x16_sme;
+
+    // IMATMUL
+    const kai_imatmul_clamp_f16_f16p_f16p_ukernel& ukernel_f16_1 =
+        get_imatmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa();
+    indirect_matmul_methods[1].imatmul.get_m_step = ukernel_f16_1.get_m_step;
+    indirect_matmul_methods[1].imatmul.get_n_step = ukernel_f16_1.get_n_step;
+    indirect_matmul_methods[1].imatmul.get_lhs_packed_offset = ukernel_f16_1.get_lhs_packed_offset;
+    indirect_matmul_methods[1].imatmul.get_rhs_packed_offset = ukernel_f16_1.get_rhs_packed_offset;
+    indirect_matmul_methods[1].imatmul.get_dst_offset = ukernel_f16_1.get_dst_offset;
+    indirect_matmul_methods[1].imatmul.get_dst_size = ukernel_f16_1.get_dst_size;
+    indirect_matmul_methods[1].imatmul.imatmul = ukernel_f16_1.run_imatmul;
+
+
+
+ 
+
+    return indirect_matmul_methods;
+}
+
+/// Retreive the test list
+const IndirectMatMulArray& get_fp32_indirect_matmul_methods() {
+    static IndirectMatMulArray indirect_matmul_methods{};
+
+
+
+    // F32 IMATMUL ////////////////////////////////////////////////////////////
+    indirect_matmul_methods[0].name = "indirect_matmul_f32_f32p_f32p_2vlx2vl_sme2_mopa";
+    indirect_matmul_methods[0].is_supported = cpu_has_sme2;
+    indirect_matmul_methods[0].pack_shape.m = 2 * get_sme_vector_length<int32_t>();
+    indirect_matmul_methods[0].pack_shape.n = 2 * get_sme_vector_length<int32_t>();
+    indirect_matmul_methods[0].pack_shape.k = sizeof(int32_t);
+    indirect_matmul_methods[0].format.lhs = DataFormat(DataType::FP32);
+    indirect_matmul_methods[0].format.rhs = DataFormat(DataType::FP32);
+    indirect_matmul_methods[0].format.bias = DataFormat(DataType::FP32);
+    indirect_matmul_methods[0].format.out = DataFormat(DataType::FP32);
+
+    // LHS
+    indirect_matmul_methods[0].lhs.get_m_step = kai_get_m_step_lhs_imatmul_pack_x32p2vlx1_x32p_sme;
+    indirect_matmul_methods[0].lhs.get_lhs_packed_offset =
+        kai_get_lhs_packed_offset_lhs_imatmul_pack_x32p2vlx1_x32p_sme;
+    indirect_matmul_methods[0].lhs.get_lhs_packed_size = kai_get_lhs_packed_size_lhs_imatmul_pack_x32p2vlx1_x32p_sme;
+    indirect_matmul_methods[0].lhs.pack = kai_run_lhs_imatmul_pack_x32p2vlx1_x32p_sme;
+
+    // RHS
+    indirect_matmul_methods[0].rhs.get_n_step = kai_get_n_step_rhs_imatmul_pack_kxn_x32p2vlx1b_x32_x32_sme;
+    indirect_matmul_methods[0].rhs.get_rhs_offset = kai_get_rhs_offset_rhs_imatmul_pack_kxn_x32p2vlx1b_x32_x32_sme;
+    indirect_matmul_methods[0].rhs.get_bias_offset = kai_get_bias_offset_rhs_imatmul_pack_kxn_x32p2vlx1b_x32_x32_sme;
+    indirect_matmul_methods[0].rhs.get_rhs_packed_offset =
+        kai_get_rhs_packed_offset_rhs_imatmul_pack_kxn_x32p2vlx1b_x32_x32_sme;
+    indirect_matmul_methods[0].rhs.get_rhs_packed_size =
+        kai_get_rhs_packed_size_rhs_imatmul_pack_kxn_x32p2vlx1b_x32_x32_sme;
+    indirect_matmul_methods[0].rhs.pack = kai_run_rhs_imatmul_pack_kxn_x32p2vlx1b_x32_x32_sme;
+
+    // IMATMUL
+    const kai_imatmul_clamp_f32_f32p_f32p_ukernel& ukernel_f32 =
+        get_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme2_mopa();
+    indirect_matmul_methods[0].imatmul.get_m_step = ukernel_f32.get_m_step;
+    indirect_matmul_methods[0].imatmul.get_n_step = ukernel_f32.get_n_step;
+    indirect_matmul_methods[0].imatmul.get_lhs_packed_offset = ukernel_f32.get_lhs_packed_offset;
+    indirect_matmul_methods[0].imatmul.get_rhs_packed_offset = ukernel_f32.get_rhs_packed_offset;
+    indirect_matmul_methods[0].imatmul.get_dst_offset = ukernel_f32.get_dst_offset;
+    indirect_matmul_methods[0].imatmul.get_dst_size = ukernel_f32.get_dst_size;
+    indirect_matmul_methods[0].imatmul.imatmul = ukernel_f32.run_imatmul;
+	
+	
+	
+
     // F32 IMATMUL ////////////////////////////////////////////////////////////
-    indirect_matmul_methods[1].name = "indirect_matmul_f32_f32p_f32p_2vlx2vl_sme2_mopa";
-    indirect_matmul_methods[1].is_supported = cpu_has_sme2;
+    indirect_matmul_methods[1].name = "indirect_matmul_f32_f32p_f32p_2vlx2vl_sme1_mopa";
+    indirect_matmul_methods[1].is_supported = cpu_has_sme;
     indirect_matmul_methods[1].pack_shape.m = 2 * get_sme_vector_length<int32_t>();
     indirect_matmul_methods[1].pack_shape.n = 2 * get_sme_vector_length<int32_t>();
     indirect_matmul_methods[1].pack_shape.k = sizeof(int32_t);
@@ -231,19 +357,20 @@ const IndirectMatMulArray& get_indirect_matmul_methods() {
     indirect_matmul_methods[1].rhs.pack = kai_run_rhs_imatmul_pack_kxn_x32p2vlx1b_x32_x32_sme;
 
     // IMATMUL
-    const kai_imatmul_clamp_f32_f32p_f32p_ukernel& ukernel_f32 =
-        get_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme2_mopa();
-    indirect_matmul_methods[1].imatmul.get_m_step = ukernel_f32.get_m_step;
-    indirect_matmul_methods[1].imatmul.get_n_step = ukernel_f32.get_n_step;
-    indirect_matmul_methods[1].imatmul.get_lhs_packed_offset = ukernel_f32.get_lhs_packed_offset;
-    indirect_matmul_methods[1].imatmul.get_rhs_packed_offset = ukernel_f32.get_rhs_packed_offset;
-    indirect_matmul_methods[1].imatmul.get_dst_offset = ukernel_f32.get_dst_offset;
-    indirect_matmul_methods[1].imatmul.get_dst_size = ukernel_f32.get_dst_size;
-    indirect_matmul_methods[1].imatmul.imatmul = ukernel_f32.run_imatmul;
+    const kai_imatmul_clamp_f32_f32p_f32p_ukernel& ukernel_f32_1 =
+        get_imatmul_clamp_f32_f32p2vlx1_f32p2vlx1b_2vlx2vl_sme1_mopa();
+    indirect_matmul_methods[1].imatmul.get_m_step = ukernel_f32_1.get_m_step;
+    indirect_matmul_methods[1].imatmul.get_n_step = ukernel_f32_1.get_n_step;
+    indirect_matmul_methods[1].imatmul.get_lhs_packed_offset = ukernel_f32_1.get_lhs_packed_offset;
+    indirect_matmul_methods[1].imatmul.get_rhs_packed_offset = ukernel_f32_1.get_rhs_packed_offset;
+    indirect_matmul_methods[1].imatmul.get_dst_offset = ukernel_f32_1.get_dst_offset;
+    indirect_matmul_methods[1].imatmul.get_dst_size = ukernel_f32_1.get_dst_size;
+    indirect_matmul_methods[1].imatmul.imatmul = ukernel_f32_1.run_imatmul;
 
     return indirect_matmul_methods;
 }
 
+
 /// Test reference identification
 struct TestDataId {
     MatMulShape shape;
@@ -500,9 +627,68 @@ TEST_P(IndirectMatMulTest, Output) {
 
 ///  Test parameter listing
 INSTANTIATE_TEST_SUITE_P(
-    IndirectMatMul, IndirectMatMulTest,
+    IndirectMatMul_fp16, IndirectMatMulTest,
+    testing::Combine(
+        testing::ValuesIn(get_fp16_indirect_matmul_methods()),  //
+        testing::ValuesIn({
+            // clang-format off
+            MatMulShape{  1,    1,   1}, //
+            MatMulShape{  1,   17,   4}, //
+            MatMulShape{  1,   19,  24}, //
+            MatMulShape{  1,   32,   4}, //
+            MatMulShape{  1,   32,  32}, //
+            MatMulShape{  1,   33, 200}, //
+            MatMulShape{  1,   49,  21}, //
+            MatMulShape{  1,   64,   4}, //
+            MatMulShape{  1,   65,   4}, //
+            MatMulShape{  3,    6,   6}, //
+            MatMulShape{  3,   28,  25}, //
+            MatMulShape{  4,   16,   4}, //
+            MatMulShape{  4,   16,  27}, //
+            MatMulShape{  6,   18,  31}, //
+            MatMulShape{  6,   28,   1}, //
+            MatMulShape{  6,   29,  24}, //
+            MatMulShape{  8,   16,  16}, //
+            MatMulShape{ 16,   16,   4}, //
+            MatMulShape{ 16,   16,  16}, //
+            MatMulShape{ 20,   30,  40}, //
+            MatMulShape{ 23,    1,  43}, //
+            MatMulShape{ 32,   14,   1}, //
+            MatMulShape{ 32,   16,  27}, //
+            MatMulShape{ 32,   32,   3}, //
+            MatMulShape{ 32,   32,   4}, //
+            MatMulShape{ 33,   29,  24}, //
+            MatMulShape{ 64,   64,   3}, //
+            MatMulShape{ 64,   64,   4}, //
+            MatMulShape{ 96,   96,   3}, //
+            MatMulShape{ 96,   97,   3}, //
+            MatMulShape{ 97,   96,   3}, //
+            MatMulShape{123,   85,  45}, //
+            MatMulShape{128,  128,   3}, //
+            MatMulShape{130,  130,   6}, //
+            // clang-format on
+        }),
+        testing::ValuesIn(std::initializer_list<size_t>{1, 2, 3, 4, 8, 11, 16, 32, 33, 64, 65}),  //
+        testing::ValuesIn({
+            // clang-format off
+            //       (Start row , start col , height , width)
+            MatrixPortion(   0  , 0         , 1      , 1   ), // Full matrix.
+            MatrixPortion(   0  , 0         , 1      , 0.5 ), // Left half
+            MatrixPortion(   0  , 0         , 0.5    , 1   ), // Upper half
+            MatrixPortion(   0  , 0.5       , 1      , 0.5 ), // Right half
+            MatrixPortion( 0.5  , 0         , 0.5    , 1   ), // Bottom half
+            MatrixPortion( 0.4  , 0.4       , 0.3    , 0.3 ), // Center ninth
+            // clang-format on
+        }),
+        testing::ValuesIn(std::initializer_list<float>{0.0F, 0.1F, 0.5F})),  //
+    testing::PrintToStringParamName());
+	
+	
+///  Test parameter listing
+INSTANTIATE_TEST_SUITE_P(
+    IndirectMatMul_fp32, IndirectMatMulTest,
     testing::Combine(
-        testing::ValuesIn(get_indirect_matmul_methods()),  //
+        testing::ValuesIn(get_fp32_indirect_matmul_methods()),  //
         testing::ValuesIn({
             // clang-format off
             MatMulShape{  1,    1,   1}, //
diff --git a/test/tests/matmul_clamp_qai8_qai8p_qsi8cxp_test.cpp b/test/tests/matmul_clamp_qai8_qai8p_qsi8cxp_test.cpp
index 66191ca..67be1f2 100644
--- a/test/tests/matmul_clamp_qai8_qai8p_qsi8cxp_test.cpp
+++ b/test/tests/matmul_clamp_qai8_qai8p_qsi8cxp_test.cpp
@@ -21,10 +21,12 @@
 
 #include "kai/kai_common.h"
 #include "kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/kai_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme2_mopa.h"
+#include "kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/kai_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.h"
 #include "kai/ukernels/matmul/imatmul_clamp_qai8_qai8p_qsi8cxp/kai_imatmul_clamp_qai8_qai8p_qsi8cxp_interface.h"
 #include "kai/ukernels/matmul/matmul_clamp_qai8_qai8_qsi8cxp/kai_matmul_clamp_qai8_qai8_qsi8cxp2vlx4sb_1x16vl_sme2_dot.h"
 #include "kai/ukernels/matmul/matmul_clamp_qai8_qai8_qsi8cxp/kai_matmul_clamp_qai8_qai8_qsi8cxp_interface.h"
 #include "kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/kai_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme2_mopa.h"
+#include "kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/kai_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa.h"
 #include "kai/ukernels/matmul/matmul_clamp_qai8_qai8p_qsi8cxp/kai_matmul_clamp_qai8_qai8p_qsi8cxpsb_interface.h"
 #include "kai/ukernels/matmul/pack/kai_lhs_imatmul_pack_x8p2vlx4_x8p_sme.h"
 #include "kai/ukernels/matmul/pack/kai_lhs_pack_x8p2vlx4_x8_sme.h"
@@ -159,6 +161,29 @@ get_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme2_mopa_interface() {
     return ukernel;
 }
 
+/// Make sure that interface matches for qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa
+const kai_matmul_clamp_qai8_qai8p_qsi8cxpsb_ukernel&
+get_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa_interface() {
+    static kai_matmul_clamp_qai8_qai8p_qsi8cxpsb_ukernel ukernel;
+
+    ukernel.get_m_step = kai_get_m_step_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_n_step = kai_get_n_step_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_mr = kai_get_mr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_nr = kai_get_nr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_kr = kai_get_kr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_sr = kai_get_sr_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_lhs_packed_offset =
+        kai_get_lhs_packed_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_rhs_packed_offset =
+        kai_get_rhs_packed_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_dst_offset = kai_get_dst_offset_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_dst_size = kai_get_dst_size_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.run_matmul = kai_run_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+
+    return ukernel;
+}
+
+
 /// Make sure that interface matches for qai8_qai8_qsi8cxp2vlx4sb_1x16vl_sme2_dot
 const kai_matmul_clamp_qai8_qai8p_qsi8cxp_ukernel&
 get_matmul_clamp_qai8_qai8_qsi8cxp2vlx4sb_1x16vl_sme2_dot_interface() {
@@ -196,6 +221,24 @@ get_imatmul_clamp_qai8_qai8_qsi8cxp2vlx4sb_1x16vl_sme2_dot_interface() {
     return ukernel;
 };
 
+/// Make sure that interface matches qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa
+const kai_imatmul_clamp_qai8_qai8p_qsi8cxp_ukernel&
+get_imatmul_clamp_qai8_qai8_qsi8cxp2vlx4sb_1x16vl_sme1_dot_interface() {
+    static kai_imatmul_clamp_qai8_qai8p_qsi8cxp_ukernel ukernel;
+
+    ukernel.get_m_step = kai_get_m_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_n_step = kai_get_n_step_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_lhs_packed_offset =
+        kai_get_lhs_packed_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_rhs_packed_offset =
+        kai_get_rhs_packed_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_dst_offset = kai_get_dst_offset_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.get_dst_size = kai_get_dst_size_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+    ukernel.run_imatmul = kai_run_imatmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa;
+
+    return ukernel;
+};
+
 const RhsPackKernel& get_rhs_pack() {
     static RhsPackKernel ukernel;
 
@@ -246,12 +289,12 @@ struct IndirectMatMulVariant {
     MatMulIndirectKernel matmul;     ///< Matmul kernel interface
 };
 
-const std::array<MatMulVariant, 1>& get_gemm_variants() {
-    static std::array<MatMulVariant, 1> variants;
-    static const kai_matmul_clamp_qai8_qai8p_qsi8cxpsb_ukernel& ukernel =
+const std::array<MatMulVariant, 2>& get_gemm_variants() {
+    static std::array<MatMulVariant, 2> variants;
+    static const kai_matmul_clamp_qai8_qai8p_qsi8cxpsb_ukernel& ukernel2 =
         get_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme2_mopa_interface();
 
-    variants[0].name = "matmul_qai8_qai8p_qsi8cxp";
+    variants[0].name = "sme2_matmul_qai8_qai8p_qsi8cxp";
     variants[0].acc_pack.m = 2 * get_sme_vector_length<int32_t>();
     variants[0].acc_pack.n = 2 * get_sme_vector_length<int32_t>();
     variants[0].acc_pack.k = sizeof(int32_t) / sizeof(int8_t);
@@ -261,27 +304,53 @@ const std::array<MatMulVariant, 1>& get_gemm_variants() {
     variants[0].is_supported = cpu_has_sme2;
     variants[0].lhs_pack = get_lhs_pack();
     variants[0].rhs_pack = get_rhs_pack();
-    variants[0].matmul.get_m_step = ukernel.get_m_step;
-    variants[0].matmul.get_n_step = ukernel.get_n_step;
-    variants[0].matmul.get_mr = ukernel.get_mr;
-    variants[0].matmul.get_nr = ukernel.get_nr;
-    variants[0].matmul.get_kr = ukernel.get_kr;
-    variants[0].matmul.get_sr = ukernel.get_sr;
-    variants[0].matmul.get_packed_lhs_offset = ukernel.get_lhs_packed_offset;
-    variants[0].matmul.get_packed_rhs_offset = ukernel.get_rhs_packed_offset;
-    variants[0].matmul.get_dst_offset = ukernel.get_dst_offset;
-    variants[0].matmul.get_dst_size = ukernel.get_dst_size;
-    variants[0].matmul.matmul = ukernel.run_matmul;
+    variants[0].matmul.get_m_step = ukernel2.get_m_step;
+    variants[0].matmul.get_n_step = ukernel2.get_n_step;
+    variants[0].matmul.get_mr = ukernel2.get_mr;
+    variants[0].matmul.get_nr = ukernel2.get_nr;
+    variants[0].matmul.get_kr = ukernel2.get_kr;
+    variants[0].matmul.get_sr = ukernel2.get_sr;
+    variants[0].matmul.get_packed_lhs_offset = ukernel2.get_lhs_packed_offset;
+    variants[0].matmul.get_packed_rhs_offset = ukernel2.get_rhs_packed_offset;
+    variants[0].matmul.get_dst_offset = ukernel2.get_dst_offset;
+    variants[0].matmul.get_dst_size = ukernel2.get_dst_size;
+    variants[0].matmul.matmul = ukernel2.run_matmul;
+
+
+    static const kai_matmul_clamp_qai8_qai8p_qsi8cxpsb_ukernel& ukernel1 =
+        get_matmul_clamp_qai8_qai8p2vlx4_qsi8cxpsb2vlx4_2vlx2vl_sme1_mopa_interface();
+
+    variants[1].name = "sme1_matmul_qai8_qai8p_qsi8cxp";
+    variants[1].acc_pack.m = 2 * get_sme_vector_length<int32_t>();
+    variants[1].acc_pack.n = 2 * get_sme_vector_length<int32_t>();
+    variants[1].acc_pack.k = sizeof(int32_t) / sizeof(int8_t);
+    variants[1].acc_step.m = 2 * get_sme_vector_length<int32_t>();
+    variants[1].acc_step.n = 2 * get_sme_vector_length<int32_t>();
+    variants[1].acc_step.k = sizeof(int32_t) / sizeof(int8_t);
+    variants[1].is_supported = cpu_has_sme;
+    variants[1].lhs_pack = get_lhs_pack();
+    variants[1].rhs_pack = get_rhs_pack();
+    variants[1].matmul.get_m_step = ukernel1.get_m_step;
+    variants[1].matmul.get_n_step = ukernel1.get_n_step;
+    variants[1].matmul.get_mr = ukernel1.get_mr;
+    variants[1].matmul.get_nr = ukernel1.get_nr;
+    variants[1].matmul.get_kr = ukernel1.get_kr;
+    variants[1].matmul.get_sr = ukernel1.get_sr;
+    variants[1].matmul.get_packed_lhs_offset = ukernel1.get_lhs_packed_offset;
+    variants[1].matmul.get_packed_rhs_offset = ukernel1.get_rhs_packed_offset;
+    variants[1].matmul.get_dst_offset = ukernel1.get_dst_offset;
+    variants[1].matmul.get_dst_size = ukernel1.get_dst_size;
+    variants[1].matmul.matmul = ukernel1.run_matmul;
 
     return variants;
 }
 
-const std::array<IndirectMatMulVariant, 1>& get_indirect_gemm_variants() {
-    static std::array<IndirectMatMulVariant, 1> variants;
-    static const kai_imatmul_clamp_qai8_qai8p_qsi8cxp_ukernel& ukernel =
+const std::array<IndirectMatMulVariant, 2>& get_indirect_gemm_variants() {
+    static std::array<IndirectMatMulVariant, 2> variants;
+    static const kai_imatmul_clamp_qai8_qai8p_qsi8cxp_ukernel& ukernel2 =
         get_imatmul_clamp_qai8_qai8_qsi8cxp2vlx4sb_1x16vl_sme2_dot_interface();
 
-    variants[0].name = "indirect_matmul_qai8_qai8p_qsi8cxp";
+    variants[0].name = "sme2_indirect_matmul_qai8_qai8p_qsi8cxp";
     variants[0].acc_pack.m = 2 * get_sme_vector_length<int32_t>();
     variants[0].acc_pack.n = 2 * get_sme_vector_length<int32_t>();
     variants[0].acc_pack.k = sizeof(int32_t) / sizeof(int8_t);
@@ -302,13 +371,45 @@ const std::array<IndirectMatMulVariant, 1>& get_indirect_gemm_variants() {
     variants[0].rhs_pack.get_packed_rhs_size =
         kai_get_rhs_packed_size_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme;
     variants[0].rhs_pack.pack = kai_run_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme;
-    variants[0].matmul.get_m_step = ukernel.get_m_step;
-    variants[0].matmul.get_n_step = ukernel.get_n_step;
-    variants[0].matmul.get_packed_lhs_offset = ukernel.get_lhs_packed_offset;
-    variants[0].matmul.get_packed_rhs_offset = ukernel.get_rhs_packed_offset;
-    variants[0].matmul.get_dst_offset = ukernel.get_dst_offset;
-    variants[0].matmul.get_dst_size = ukernel.get_dst_size;
-    variants[0].matmul.imatmul = ukernel.run_imatmul;
+    variants[0].matmul.get_m_step = ukernel2.get_m_step;
+    variants[0].matmul.get_n_step = ukernel2.get_n_step;
+    variants[0].matmul.get_packed_lhs_offset = ukernel2.get_lhs_packed_offset;
+    variants[0].matmul.get_packed_rhs_offset = ukernel2.get_rhs_packed_offset;
+    variants[0].matmul.get_dst_offset = ukernel2.get_dst_offset;
+    variants[0].matmul.get_dst_size = ukernel2.get_dst_size;
+    variants[0].matmul.imatmul = ukernel2.run_imatmul;
+	
+	    static const kai_imatmul_clamp_qai8_qai8p_qsi8cxp_ukernel& ukernel1 =
+        get_imatmul_clamp_qai8_qai8_qsi8cxp2vlx4sb_1x16vl_sme1_dot_interface();
+
+    variants[1].name = "sme1_indirect_matmul_qai8_qai8p_qsi8cxp";
+    variants[1].acc_pack.m = 2 * get_sme_vector_length<int32_t>();
+    variants[1].acc_pack.n = 2 * get_sme_vector_length<int32_t>();
+    variants[1].acc_pack.k = sizeof(int32_t) / sizeof(int8_t);
+    variants[1].acc_step.m = 2 * get_sme_vector_length<int32_t>();
+    variants[1].acc_step.n = 2 * get_sme_vector_length<int32_t>();
+    variants[1].acc_step.k = sizeof(int32_t) / sizeof(int8_t);
+    variants[1].is_supported = cpu_has_sme;
+    variants[1].lhs_pack.get_m_step = kai_get_m_step_lhs_imatmul_pack_x8p2vlx4_x8p_sme;
+    variants[1].lhs_pack.get_packed_lhs_offset = kai_get_lhs_packed_offset_lhs_imatmul_pack_x8p2vlx4_x8p_sme;
+    variants[1].lhs_pack.get_packed_lhs_size = kai_get_lhs_packed_size_lhs_imatmul_pack_x8p2vlx4_x8p_sme;
+    variants[1].lhs_pack.pack = kai_run_lhs_imatmul_pack_x8p2vlx4_x8p_sme;
+    variants[1].rhs_pack.get_n_step = kai_get_n_step_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme;
+    variants[1].rhs_pack.get_rhs_offset = kai_get_rhs_offset_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme;
+    variants[1].rhs_pack.get_bias_offset = kai_get_bias_offset_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme;
+    variants[1].rhs_pack.get_scale_offset = kai_get_scale_offset_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme;
+    variants[1].rhs_pack.get_packed_rhs_offset =
+        kai_get_rhs_packed_offset_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme;
+    variants[1].rhs_pack.get_packed_rhs_size =
+        kai_get_rhs_packed_size_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme;
+    variants[1].rhs_pack.pack = kai_run_rhs_imatmul_pack_kxn_qsi8cxp2vlx4sb_qs8cx_f32_i32_sme;
+    variants[1].matmul.get_m_step = ukernel1.get_m_step;
+    variants[1].matmul.get_n_step = ukernel1.get_n_step;
+    variants[1].matmul.get_packed_lhs_offset = ukernel1.get_lhs_packed_offset;
+    variants[1].matmul.get_packed_rhs_offset = ukernel1.get_rhs_packed_offset;
+    variants[1].matmul.get_dst_offset = ukernel1.get_dst_offset;
+    variants[1].matmul.get_dst_size = ukernel1.get_dst_size;
+    variants[1].matmul.imatmul = ukernel1.run_imatmul;
 
     return variants;
 }
@@ -948,6 +1049,7 @@ static constexpr std::array shapes{
     // clang-format on
 };
 
+
 INSTANTIATE_TEST_SUITE_P(
     matmul_clamp_qai8_qai8p_qsi8cxp, MatMulQuantizedTest,
     testing::Combine(
diff --git a/test/tests/matmul_test.cpp b/test/tests/matmul_test.cpp
index f22a593..acc1059 100644
--- a/test/tests/matmul_test.cpp
+++ b/test/tests/matmul_test.cpp
@@ -40,6 +40,7 @@
 
 // matmul_clamp_f16_f16p_f16p
 #include "kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/kai_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa.h"
+#include "kai/ukernels/matmul/matmul_clamp_f16_f16p_f16p/kai_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa.h"
 #include "kai/ukernels/matmul/pack/kai_lhs_pack_x16p2vlx2_x16_sme.h"
 #include "kai/ukernels/matmul/pack/kai_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme.h"
 #include "kai/ukernels/matmul/pack/kai_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme.h"
@@ -49,6 +50,7 @@
 
 // matmul_nt_nt_fp32_fp32_fp32_2vlx2vl_sme2_mopa
 #include "kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/kai_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa.h"
+#include "kai/ukernels/matmul/matmul_clamp_f32_f32p_f32p/kai_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa.h"
 #include "kai/ukernels/matmul/pack/kai_lhs_pack_f32p2vlx1_f32_sme.h"
 #include "kai/ukernels/matmul/pack/kai_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme.h"
 #include "kai/ukernels/matmul/pack/kai_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme.h"
@@ -60,41 +62,91 @@
 
 namespace kai::test {
 
-static const std::array<MatMulMethod, 4>& get_matmul_methods() {
+static const std::array<MatMulMethod, 2>& get_matmul_methods() {
     // List of supported matrix multiplication methods.
-    static std::array<MatMulMethod, 4> matmul_methods{};
-
-    matmul_methods[0].name = "matmul_nt_nt_fp16_fp16_fp16_6x16_neon_mla";
-    matmul_methods[0].m0 = 6;
-    matmul_methods[0].n0 = 16;
+    static std::array<MatMulMethod, 2> matmul_methods{};
+
+    // matmul_methods[0].name = "matmul_nt_nt_fp16_fp16_fp16_6x16_neon_mla";
+    // matmul_methods[0].m0 = 6;
+    // matmul_methods[0].n0 = 16;
+    // matmul_methods[0].dst_format = DataFormat(DataType::FP16);
+    // matmul_methods[0].lhs_format = DataFormat(DataType::FP16);
+    // matmul_methods[0].packed_lhs_format = DataFormat(DataType::UNKNOWN);
+    // matmul_methods[0].rhs_format = DataFormat(DataType::FP16);
+    // matmul_methods[0].packed_rhs_format = DataFormat(
+        // DataType::FP16, 16, 0, DataFormat::PackFormat::BIAS_PER_ROW, DataType::FP16, DataType::UNKNOWN, 16, 1);
+    // matmul_methods[0].bias_format = DataFormat(DataType::FP16);
+    // matmul_methods[0].fn_is_supported = cpu_has_fp16;
+    // matmul_methods[0].fn_get_nr = kai_get_nr_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
+    // matmul_methods[0].fn_get_kr = kai_get_kr_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
+    // matmul_methods[0].fn_get_sr = kai_get_sr_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
+    // matmul_methods[0].fn_get_main_m_step = kai_get_m_step_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
+    // matmul_methods[0].fn_get_pack_rhs_n_step = kai_get_n_step_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
+    // matmul_methods[0].fn_get_main_n_step = kai_get_n_step_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
+    // matmul_methods[0].fn_get_lhs_offset = kai_get_lhs_offset_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
+    // matmul_methods[0].fn_get_rhs_offset = kai_get_rhs_offset_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
+    // matmul_methods[0].fn_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
+    // matmul_methods[0].fn_get_pack_rhs_packed_rhs_offset =
+        // kai_get_rhs_packed_offset_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
+    // matmul_methods[0].fn_get_main_packed_rhs_offset =
+        // kai_get_rhs_packed_offset_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
+    // matmul_methods[0].fn_pack_rhs = kai_run_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
+    // matmul_methods[0].fn_get_bias_offset = kai_get_bias_offset_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
+    // matmul_methods[0].fn_get_dst_offset = kai_get_dst_offset_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
+    // matmul_methods[0].fn_get_dst_size = kai_get_dst_size_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
+    // matmul_methods[0].fn_matmul_f16_f16_f16p = kai_run_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
+
+
+    matmul_methods[0].name = "matmul_nt_nt_f16_f16p_f16p_2vlx2vl_sme2_mopa";
+    matmul_methods[0].m0 = 2 * get_sme_vector_length<float>();
+    matmul_methods[0].n0 = 2 * get_sme_vector_length<float>();
     matmul_methods[0].dst_format = DataFormat(DataType::FP16);
     matmul_methods[0].lhs_format = DataFormat(DataType::FP16);
-    matmul_methods[0].packed_lhs_format = DataFormat(DataType::UNKNOWN);
+    matmul_methods[0].packed_lhs_format = DataFormat(DataType::FP16, 2 * get_sme_vector_length<float>(), 2);
     matmul_methods[0].rhs_format = DataFormat(DataType::FP16);
     matmul_methods[0].packed_rhs_format = DataFormat(
-        DataType::FP16, 16, 0, DataFormat::PackFormat::BIAS_PER_ROW, DataType::FP16, DataType::UNKNOWN, 16, 1);
+        DataType::FP16,                          // Output type
+        2 * get_sme_vector_length<float>(), 2,   // Block size
+        DataFormat::PackFormat::BIAS_PER_ROW,    // Data layout
+        DataType::FP16,                          // Bias format
+        DataType::UNKNOWN,                       // Scaling type
+        2 * get_sme_vector_length<float>(), 2);  // Sub-block
     matmul_methods[0].bias_format = DataFormat(DataType::FP16);
-    matmul_methods[0].fn_is_supported = cpu_has_fp16;
-    matmul_methods[0].fn_get_nr = kai_get_nr_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
-    matmul_methods[0].fn_get_kr = kai_get_kr_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
-    matmul_methods[0].fn_get_sr = kai_get_sr_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
-    matmul_methods[0].fn_get_main_m_step = kai_get_m_step_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
-    matmul_methods[0].fn_get_pack_rhs_n_step = kai_get_n_step_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
-    matmul_methods[0].fn_get_main_n_step = kai_get_n_step_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
-    matmul_methods[0].fn_get_lhs_offset = kai_get_lhs_offset_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
-    matmul_methods[0].fn_get_rhs_offset = kai_get_rhs_offset_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
-    matmul_methods[0].fn_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
-    matmul_methods[0].fn_get_pack_rhs_packed_rhs_offset =
-        kai_get_rhs_packed_offset_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
+    matmul_methods[0].fn_is_supported = cpu_has_sme2;
+    matmul_methods[0].fn_get_mr = kai_get_mr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[0].fn_get_nr = kai_get_nr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[0].fn_get_kr = kai_get_kr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[0].fn_get_sr = kai_get_sr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[0].fn_get_main_m_step = kai_get_m_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[0].fn_get_pack_rhs_n_step = kai_get_n_step_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
+    matmul_methods[0].fn_get_main_n_step = kai_get_n_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[0].fn_get_lhs_offset = kai_get_lhs_offset_lhs_pack_x16p2vlx2_x16_sme;
+    matmul_methods[0].fn_get_packed_lhs_size = kai_get_lhs_packed_size_lhs_pack_x16p2vlx2_x16_sme;
+    matmul_methods[0].fn_get_packed_lhs_offset =
+        kai_get_lhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[0].fn_pack_lhs = kai_run_lhs_pack_x16p2vlx2_x16_sme;
+    matmul_methods[0].fn_get_rhs_offset = kai_get_rhs_offset_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
+    matmul_methods[0].fn_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
+    matmul_methods[0].fn_get_pack_rhs_packed_rhs_offset = kai_get_rhs_packed_offset_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
     matmul_methods[0].fn_get_main_packed_rhs_offset =
-        kai_get_rhs_packed_offset_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
-    matmul_methods[0].fn_pack_rhs = kai_run_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
-    matmul_methods[0].fn_get_bias_offset = kai_get_bias_offset_rhs_pack_kxn_f16p16x1biasf16_f16_f16_neon;
-    matmul_methods[0].fn_get_dst_offset = kai_get_dst_offset_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
-    matmul_methods[0].fn_get_dst_size = kai_get_dst_size_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
-    matmul_methods[0].fn_matmul_f16_f16_f16p = kai_run_matmul_clamp_f16_f16_f16p16x1biasf16_6x16x8_neon_mla;
-
-    matmul_methods[1].name = "matmul_nt_nt_f16_f16p_f16p_2vlx2vl_sme2_mopa";
+        kai_get_rhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[0].fn_pack_rhs = kai_run_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
+    matmul_methods[0].fn_pack_rhs_nxk_get_n_step = kai_get_n_step_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme;
+    matmul_methods[0].fn_pack_rhs_nxk_get_rhs_offset = kai_get_rhs_offset_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme;
+    matmul_methods[0].fn_pack_rhs_nxk_get_bias_offset = kai_get_bias_offset_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme;
+    matmul_methods[0].fn_pack_rhs_nxk_get_packed_rhs_offset =
+        kai_get_rhs_packed_offset_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme;
+    matmul_methods[0].fn_pack_rhs_nxk_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme;
+    matmul_methods[0].fn_pack_rhs_nxk = kai_run_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme;
+    matmul_methods[0].fn_get_bias_offset = kai_get_bias_offset_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
+    matmul_methods[0].fn_get_dst_offset = kai_get_dst_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[0].fn_get_dst_size = kai_get_dst_size_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[0].fn_matmul_f16_f16p_f16p = kai_run_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+
+
+
+
+    matmul_methods[1].name = "matmul_nt_nt_f16_f16p_f16p_2vlx2vl_sme1_mopa";
     matmul_methods[1].m0 = 2 * get_sme_vector_length<float>();
     matmul_methods[1].n0 = 2 * get_sme_vector_length<float>();
     matmul_methods[1].dst_format = DataFormat(DataType::FP16);
@@ -109,24 +161,24 @@ static const std::array<MatMulMethod, 4>& get_matmul_methods() {
         DataType::UNKNOWN,                       // Scaling type
         2 * get_sme_vector_length<float>(), 2);  // Sub-block
     matmul_methods[1].bias_format = DataFormat(DataType::FP16);
-    matmul_methods[1].fn_is_supported = cpu_has_sme2;
-    matmul_methods[1].fn_get_mr = kai_get_mr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
-    matmul_methods[1].fn_get_nr = kai_get_nr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
-    matmul_methods[1].fn_get_kr = kai_get_kr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
-    matmul_methods[1].fn_get_sr = kai_get_sr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
-    matmul_methods[1].fn_get_main_m_step = kai_get_m_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[1].fn_is_supported = cpu_has_sme;
+    matmul_methods[1].fn_get_mr = kai_get_mr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    matmul_methods[1].fn_get_nr = kai_get_nr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    matmul_methods[1].fn_get_kr = kai_get_kr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    matmul_methods[1].fn_get_sr = kai_get_sr_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    matmul_methods[1].fn_get_main_m_step = kai_get_m_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
     matmul_methods[1].fn_get_pack_rhs_n_step = kai_get_n_step_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
-    matmul_methods[1].fn_get_main_n_step = kai_get_n_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+    matmul_methods[1].fn_get_main_n_step = kai_get_n_step_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
     matmul_methods[1].fn_get_lhs_offset = kai_get_lhs_offset_lhs_pack_x16p2vlx2_x16_sme;
     matmul_methods[1].fn_get_packed_lhs_size = kai_get_lhs_packed_size_lhs_pack_x16p2vlx2_x16_sme;
     matmul_methods[1].fn_get_packed_lhs_offset =
-        kai_get_lhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+        kai_get_lhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
     matmul_methods[1].fn_pack_lhs = kai_run_lhs_pack_x16p2vlx2_x16_sme;
     matmul_methods[1].fn_get_rhs_offset = kai_get_rhs_offset_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
     matmul_methods[1].fn_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
     matmul_methods[1].fn_get_pack_rhs_packed_rhs_offset = kai_get_rhs_packed_offset_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
     matmul_methods[1].fn_get_main_packed_rhs_offset =
-        kai_get_rhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
+        kai_get_rhs_packed_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
     matmul_methods[1].fn_pack_rhs = kai_run_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
     matmul_methods[1].fn_pack_rhs_nxk_get_n_step = kai_get_n_step_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme;
     matmul_methods[1].fn_pack_rhs_nxk_get_rhs_offset = kai_get_rhs_offset_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme;
@@ -136,87 +188,185 @@ static const std::array<MatMulMethod, 4>& get_matmul_methods() {
     matmul_methods[1].fn_pack_rhs_nxk_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme;
     matmul_methods[1].fn_pack_rhs_nxk = kai_run_rhs_pack_nxk_x16p2vlx2b_x16_x16_sme;
     matmul_methods[1].fn_get_bias_offset = kai_get_bias_offset_rhs_pack_kxn_x16p2vlx2b_x16_x16_sme;
-    matmul_methods[1].fn_get_dst_offset = kai_get_dst_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
-    matmul_methods[1].fn_get_dst_size = kai_get_dst_size_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
-    matmul_methods[1].fn_matmul_f16_f16p_f16p = kai_run_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme2_mopa;
-
-    matmul_methods[2].name = "matmul_nt_nt_fp32_fp32_fp32_6x8_neon_mla";
-    matmul_methods[2].m0 = 6;
-    matmul_methods[2].n0 = 8;
-    matmul_methods[2].dst_format = DataFormat(DataType::FP32);
-    matmul_methods[2].lhs_format = DataFormat(DataType::FP32);
-    matmul_methods[2].packed_lhs_format = DataFormat(DataType::UNKNOWN);
-    matmul_methods[2].rhs_format = DataFormat(DataType::FP32);
-    matmul_methods[2].packed_rhs_format =
-        DataFormat(DataType::FP32, 8, 0, DataFormat::PackFormat::BIAS_PER_ROW, DataType::FP32, DataType::UNKNOWN, 8, 1);
-    matmul_methods[2].bias_format = DataFormat(DataType::FP32);
-    matmul_methods[2].fn_is_supported = cpu_has_advsimd;
-    matmul_methods[2].fn_get_nr = kai_get_nr_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
-    matmul_methods[2].fn_get_kr = kai_get_kr_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
-    matmul_methods[2].fn_get_sr = kai_get_sr_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
-    matmul_methods[2].fn_get_main_m_step = kai_get_m_step_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
-    matmul_methods[2].fn_get_pack_rhs_n_step = kai_get_n_step_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
-    matmul_methods[2].fn_get_main_n_step = kai_get_n_step_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
-    matmul_methods[2].fn_get_lhs_offset = kai_get_lhs_offset_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
-    matmul_methods[2].fn_get_rhs_offset = kai_get_rhs_offset_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
-    matmul_methods[2].fn_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
-    matmul_methods[2].fn_get_pack_rhs_packed_rhs_offset =
-        kai_get_rhs_packed_offset_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
-    matmul_methods[2].fn_get_main_packed_rhs_offset =
-        kai_get_rhs_packed_offset_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
-    matmul_methods[2].fn_pack_rhs = kai_run_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
-    matmul_methods[2].fn_get_bias_offset = kai_get_bias_offset_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
-    matmul_methods[2].fn_get_dst_offset = kai_get_dst_offset_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
-    matmul_methods[2].fn_get_dst_size = kai_get_dst_size_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
-    matmul_methods[2].fn_matmul_f32_f32_f32p = kai_run_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
-
-    matmul_methods[3].name = "matmul_nt_nt_fp32_fp32_fp32_2vlx2vl_sme2_mopa";
-    matmul_methods[3].m0 = 2 * get_sme_vector_length<float>();
-    matmul_methods[3].n0 = 2 * get_sme_vector_length<float>();
-    matmul_methods[3].dst_format = DataFormat(DataType::FP32);
-    matmul_methods[3].lhs_format = DataFormat(DataType::FP32);
-    matmul_methods[3].packed_lhs_format = DataFormat(DataType::FP32, 2 * get_sme_vector_length<float>(), 1);
-    matmul_methods[3].rhs_format = DataFormat(DataType::FP32);
-    matmul_methods[3].packed_rhs_format = DataFormat(
+    matmul_methods[1].fn_get_dst_offset = kai_get_dst_offset_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    matmul_methods[1].fn_get_dst_size = kai_get_dst_size_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+    matmul_methods[1].fn_matmul_f16_f16p_f16p = kai_run_matmul_clamp_f16_f16p2vlx2_f16p2vlx2_2vlx2vl_sme1_mopa;
+
+    // matmul_methods[2].name = "matmul_nt_nt_fp32_fp32_fp32_6x8_neon_mla";
+    // matmul_methods[2].m0 = 6;
+    // matmul_methods[2].n0 = 8;
+    // matmul_methods[2].dst_format = DataFormat(DataType::FP32);
+    // matmul_methods[2].lhs_format = DataFormat(DataType::FP32);
+    // matmul_methods[2].packed_lhs_format = DataFormat(DataType::UNKNOWN);
+    // matmul_methods[2].rhs_format = DataFormat(DataType::FP32);
+    // matmul_methods[2].packed_rhs_format =
+        // DataFormat(DataType::FP32, 8, 0, DataFormat::PackFormat::BIAS_PER_ROW, DataType::FP32, DataType::UNKNOWN, 8, 1);
+    // matmul_methods[2].bias_format = DataFormat(DataType::FP32);
+    // matmul_methods[2].fn_is_supported = cpu_has_advsimd;
+    // matmul_methods[2].fn_get_nr = kai_get_nr_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
+    // matmul_methods[2].fn_get_kr = kai_get_kr_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
+    // matmul_methods[2].fn_get_sr = kai_get_sr_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
+    // matmul_methods[2].fn_get_main_m_step = kai_get_m_step_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
+    // matmul_methods[2].fn_get_pack_rhs_n_step = kai_get_n_step_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
+    // matmul_methods[2].fn_get_main_n_step = kai_get_n_step_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
+    // matmul_methods[2].fn_get_lhs_offset = kai_get_lhs_offset_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
+    // matmul_methods[2].fn_get_rhs_offset = kai_get_rhs_offset_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
+    // matmul_methods[2].fn_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
+    // matmul_methods[2].fn_get_pack_rhs_packed_rhs_offset =
+        // kai_get_rhs_packed_offset_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
+    // matmul_methods[2].fn_get_main_packed_rhs_offset =
+        // kai_get_rhs_packed_offset_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
+    // matmul_methods[2].fn_pack_rhs = kai_run_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
+    // matmul_methods[2].fn_get_bias_offset = kai_get_bias_offset_rhs_pack_kxn_f32p8x1biasf32_f32_f32_neon;
+    // matmul_methods[2].fn_get_dst_offset = kai_get_dst_offset_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
+    // matmul_methods[2].fn_get_dst_size = kai_get_dst_size_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
+    // matmul_methods[2].fn_matmul_f32_f32_f32p = kai_run_matmul_clamp_f32_f32_f32p8x1biasf32_6x8x4_neon_mla;
+
+    // matmul_methods[3].name = "matmul_nt_nt_fp32_fp32_fp32_2vlx2vl_sme2_mopa";
+    // matmul_methods[3].m0 = 2 * get_sme_vector_length<float>();
+    // matmul_methods[3].n0 = 2 * get_sme_vector_length<float>();
+    // matmul_methods[3].dst_format = DataFormat(DataType::FP32);
+    // matmul_methods[3].lhs_format = DataFormat(DataType::FP32);
+    // matmul_methods[3].packed_lhs_format = DataFormat(DataType::FP32, 2 * get_sme_vector_length<float>(), 1);
+    // matmul_methods[3].rhs_format = DataFormat(DataType::FP32);
+    // matmul_methods[3].packed_rhs_format = DataFormat(
+        // DataType::FP32, 2 * get_sme_vector_length<float>(), 0, DataFormat::PackFormat::BIAS_PER_ROW, DataType::FP32,
+        // DataType::UNKNOWN, 2 * get_sme_vector_length<float>(), 1);
+    // matmul_methods[3].bias_format = DataFormat(DataType::FP32);
+    // matmul_methods[3].fn_is_supported = cpu_has_sme2;
+    // matmul_methods[3].fn_get_mr = kai_get_mr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    // matmul_methods[3].fn_get_nr = kai_get_nr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    // matmul_methods[3].fn_get_kr = kai_get_kr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    // matmul_methods[3].fn_get_sr = kai_get_sr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    // matmul_methods[3].fn_get_main_m_step = kai_get_m_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    // matmul_methods[3].fn_get_pack_rhs_n_step = kai_get_n_step_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_get_main_n_step = kai_get_n_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    // matmul_methods[3].fn_get_lhs_offset = kai_get_lhs_offset_lhs_pack_f32p2vlx1_f32_sme;
+    // matmul_methods[3].fn_get_packed_lhs_size = kai_get_lhs_packed_size_lhs_pack_f32p2vlx1_f32_sme;
+    // matmul_methods[3].fn_get_packed_lhs_offset =
+        // kai_get_lhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    // matmul_methods[3].fn_pack_lhs = kai_run_lhs_pack_f32p2vlx1_f32_sme;
+    // matmul_methods[3].fn_get_rhs_offset = kai_get_rhs_offset_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_get_pack_rhs_packed_rhs_offset =
+        // kai_get_rhs_packed_offset_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_get_main_packed_rhs_offset =
+        // kai_get_rhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    // matmul_methods[3].fn_pack_rhs = kai_run_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_pack_rhs_nxk_get_n_step = kai_get_n_step_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_pack_rhs_nxk_get_rhs_offset = kai_get_rhs_offset_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_pack_rhs_nxk_get_bias_offset = kai_get_bias_offset_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_pack_rhs_nxk_get_packed_rhs_offset =
+        // kai_get_rhs_packed_offset_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_pack_rhs_nxk_get_packed_rhs_size =
+        // kai_get_rhs_packed_size_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_pack_rhs_nxk = kai_run_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_get_bias_offset = kai_get_bias_offset_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    // matmul_methods[3].fn_get_dst_offset = kai_get_dst_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    // matmul_methods[3].fn_get_dst_size = kai_get_dst_size_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    // matmul_methods[3].fn_matmul_f32_f32p_f32p = kai_run_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+
+    return matmul_methods;
+}
+
+static const std::array<MatMulMethod, 2>& get_fp32_matmul_methods() {
+    // List of supported matrix multiplication methods.
+    static std::array<MatMulMethod, 2> matmul_methods{};
+
+
+    matmul_methods[0].name = "matmul_nt_nt_fp32_fp32_fp32_2vlx2vl_sme2_mopa";
+    matmul_methods[0].m0 = 2 * get_sme_vector_length<float>();
+    matmul_methods[0].n0 = 2 * get_sme_vector_length<float>();
+    matmul_methods[0].dst_format = DataFormat(DataType::FP32);
+    matmul_methods[0].lhs_format = DataFormat(DataType::FP32);
+    matmul_methods[0].packed_lhs_format = DataFormat(DataType::FP32, 2 * get_sme_vector_length<float>(), 1);
+    matmul_methods[0].rhs_format = DataFormat(DataType::FP32);
+    matmul_methods[0].packed_rhs_format = DataFormat(
         DataType::FP32, 2 * get_sme_vector_length<float>(), 0, DataFormat::PackFormat::BIAS_PER_ROW, DataType::FP32,
         DataType::UNKNOWN, 2 * get_sme_vector_length<float>(), 1);
-    matmul_methods[3].bias_format = DataFormat(DataType::FP32);
-    matmul_methods[3].fn_is_supported = cpu_has_sme2;
-    matmul_methods[3].fn_get_mr = kai_get_mr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
-    matmul_methods[3].fn_get_nr = kai_get_nr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
-    matmul_methods[3].fn_get_kr = kai_get_kr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
-    matmul_methods[3].fn_get_sr = kai_get_sr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
-    matmul_methods[3].fn_get_main_m_step = kai_get_m_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
-    matmul_methods[3].fn_get_pack_rhs_n_step = kai_get_n_step_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_get_main_n_step = kai_get_n_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
-    matmul_methods[3].fn_get_lhs_offset = kai_get_lhs_offset_lhs_pack_f32p2vlx1_f32_sme;
-    matmul_methods[3].fn_get_packed_lhs_size = kai_get_lhs_packed_size_lhs_pack_f32p2vlx1_f32_sme;
-    matmul_methods[3].fn_get_packed_lhs_offset =
+    matmul_methods[0].bias_format = DataFormat(DataType::FP32);
+    matmul_methods[0].fn_is_supported = cpu_has_sme2;
+    matmul_methods[0].fn_get_mr = kai_get_mr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    matmul_methods[0].fn_get_nr = kai_get_nr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    matmul_methods[0].fn_get_kr = kai_get_kr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    matmul_methods[0].fn_get_sr = kai_get_sr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    matmul_methods[0].fn_get_main_m_step = kai_get_m_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    matmul_methods[0].fn_get_pack_rhs_n_step = kai_get_n_step_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[0].fn_get_main_n_step = kai_get_n_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    matmul_methods[0].fn_get_lhs_offset = kai_get_lhs_offset_lhs_pack_f32p2vlx1_f32_sme;
+    matmul_methods[0].fn_get_packed_lhs_size = kai_get_lhs_packed_size_lhs_pack_f32p2vlx1_f32_sme;
+    matmul_methods[0].fn_get_packed_lhs_offset =
         kai_get_lhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
-    matmul_methods[3].fn_pack_lhs = kai_run_lhs_pack_f32p2vlx1_f32_sme;
-    matmul_methods[3].fn_get_rhs_offset = kai_get_rhs_offset_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_get_pack_rhs_packed_rhs_offset =
+    matmul_methods[0].fn_pack_lhs = kai_run_lhs_pack_f32p2vlx1_f32_sme;
+    matmul_methods[0].fn_get_rhs_offset = kai_get_rhs_offset_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[0].fn_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[0].fn_get_pack_rhs_packed_rhs_offset =
         kai_get_rhs_packed_offset_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_get_main_packed_rhs_offset =
+    matmul_methods[0].fn_get_main_packed_rhs_offset =
         kai_get_rhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
-    matmul_methods[3].fn_pack_rhs = kai_run_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_pack_rhs_nxk_get_n_step = kai_get_n_step_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_pack_rhs_nxk_get_rhs_offset = kai_get_rhs_offset_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_pack_rhs_nxk_get_bias_offset = kai_get_bias_offset_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_pack_rhs_nxk_get_packed_rhs_offset =
+    matmul_methods[0].fn_pack_rhs = kai_run_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[0].fn_pack_rhs_nxk_get_n_step = kai_get_n_step_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[0].fn_pack_rhs_nxk_get_rhs_offset = kai_get_rhs_offset_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[0].fn_pack_rhs_nxk_get_bias_offset = kai_get_bias_offset_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[0].fn_pack_rhs_nxk_get_packed_rhs_offset =
+        kai_get_rhs_packed_offset_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[0].fn_pack_rhs_nxk_get_packed_rhs_size =
+        kai_get_rhs_packed_size_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[0].fn_pack_rhs_nxk = kai_run_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[0].fn_get_bias_offset = kai_get_bias_offset_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[0].fn_get_dst_offset = kai_get_dst_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    matmul_methods[0].fn_get_dst_size = kai_get_dst_size_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    matmul_methods[0].fn_matmul_f32_f32p_f32p = kai_run_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+
+
+
+
+    matmul_methods[1].name = "matmul_nt_nt_fp32_fp32_fp32_2vlx2vl_sme1_mopa";
+    matmul_methods[1].m0 = 2 * get_sme_vector_length<float>();
+    matmul_methods[1].n0 = 2 * get_sme_vector_length<float>();
+    matmul_methods[1].dst_format = DataFormat(DataType::FP32);
+    matmul_methods[1].lhs_format = DataFormat(DataType::FP32);
+    matmul_methods[1].packed_lhs_format = DataFormat(DataType::FP32, 2 * get_sme_vector_length<float>(), 1);
+    matmul_methods[1].rhs_format = DataFormat(DataType::FP32);
+    matmul_methods[1].packed_rhs_format = DataFormat(
+        DataType::FP32, 2 * get_sme_vector_length<float>(), 0, DataFormat::PackFormat::BIAS_PER_ROW, DataType::FP32,
+        DataType::UNKNOWN, 2 * get_sme_vector_length<float>(), 1);
+    matmul_methods[1].bias_format = DataFormat(DataType::FP32);
+    matmul_methods[1].fn_is_supported = cpu_has_sme;
+    matmul_methods[1].fn_get_mr = kai_get_mr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa;
+    matmul_methods[1].fn_get_nr = kai_get_nr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa;
+    matmul_methods[1].fn_get_kr = kai_get_kr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa;
+    matmul_methods[1].fn_get_sr = kai_get_sr_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa;
+    matmul_methods[1].fn_get_main_m_step = kai_get_m_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa;
+    matmul_methods[1].fn_get_pack_rhs_n_step = kai_get_n_step_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[1].fn_get_main_n_step = kai_get_n_step_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa;
+    matmul_methods[1].fn_get_lhs_offset = kai_get_lhs_offset_lhs_pack_f32p2vlx1_f32_sme;
+    matmul_methods[1].fn_get_packed_lhs_size = kai_get_lhs_packed_size_lhs_pack_f32p2vlx1_f32_sme;
+    matmul_methods[1].fn_get_packed_lhs_offset =
+        kai_get_lhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa;
+    matmul_methods[1].fn_pack_lhs = kai_run_lhs_pack_f32p2vlx1_f32_sme;
+    matmul_methods[1].fn_get_rhs_offset = kai_get_rhs_offset_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[1].fn_get_packed_rhs_size = kai_get_rhs_packed_size_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[1].fn_get_pack_rhs_packed_rhs_offset =
+        kai_get_rhs_packed_offset_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[1].fn_get_main_packed_rhs_offset =
+        kai_get_rhs_packed_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa;
+    matmul_methods[1].fn_pack_rhs = kai_run_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[1].fn_pack_rhs_nxk_get_n_step = kai_get_n_step_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[1].fn_pack_rhs_nxk_get_rhs_offset = kai_get_rhs_offset_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[1].fn_pack_rhs_nxk_get_bias_offset = kai_get_bias_offset_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[1].fn_pack_rhs_nxk_get_packed_rhs_offset =
         kai_get_rhs_packed_offset_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_pack_rhs_nxk_get_packed_rhs_size =
+    matmul_methods[1].fn_pack_rhs_nxk_get_packed_rhs_size =
         kai_get_rhs_packed_size_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_pack_rhs_nxk = kai_run_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_get_bias_offset = kai_get_bias_offset_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
-    matmul_methods[3].fn_get_dst_offset = kai_get_dst_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
-    matmul_methods[3].fn_get_dst_size = kai_get_dst_size_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
-    matmul_methods[3].fn_matmul_f32_f32p_f32p = kai_run_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme2_mopa;
+    matmul_methods[1].fn_pack_rhs_nxk = kai_run_rhs_pack_nxk_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[1].fn_get_bias_offset = kai_get_bias_offset_rhs_pack_kxn_f32p2vlx1biasf32_f32_f32_sme;
+    matmul_methods[1].fn_get_dst_offset = kai_get_dst_offset_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa;
+    matmul_methods[1].fn_get_dst_size = kai_get_dst_size_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa;
+    matmul_methods[1].fn_matmul_f32_f32p_f32p = kai_run_matmul_clamp_f32_f32p2vlx1_f32p2vlx1biasf32_sme1_mopa;
 
     return matmul_methods;
 }
-
 static const std::array<MatMulMethod, 1>& get_vecmul_methods() {
     // List of supported vector by matrix multiplication methods
     static std::array<MatMulMethod, 1> vecmul_methods{};
@@ -687,7 +837,7 @@ TEST_P(MatMulTest, Output) {
 }
 
 INSTANTIATE_TEST_SUITE_P(
-    MatMul, MatMulTest,
+    MatMul_fp16, MatMulTest,
     testing::Combine(
         testing::ValuesIn(get_matmul_methods()),
         testing::Values(
@@ -705,6 +855,26 @@ INSTANTIATE_TEST_SUITE_P(
             )),
     testing::PrintToStringParamName());
 
+
+INSTANTIATE_TEST_SUITE_P(
+    MatMul_fp32, MatMulTest,
+    testing::Combine(
+        testing::ValuesIn(get_fp32_matmul_methods()),
+        testing::Values(
+            MatMulShape{1, 16, 16},   //
+            MatMulShape{20, 1, 20},   //
+            MatMulShape{6, 16, 32},   //
+            MatMulShape{12, 32, 17},  //
+            MatMulShape{13, 33, 23},  //
+            MatMulShape{87, 93, 56}   //
+            ),
+        testing::Values(
+            MatrixPortion(0, 0, 1, 1),        // Full matrix.
+            MatrixPortion(0, 0, 0.25, 0.25),  // Top-left corner.
+            MatrixPortion(0.75, 0.75, 1, 1)   // Bottom-right corner.
+            )),
+    testing::PrintToStringParamName());
+	
 INSTANTIATE_TEST_SUITE_P(
     VecMul, MatMulTest,
     testing::Combine(
